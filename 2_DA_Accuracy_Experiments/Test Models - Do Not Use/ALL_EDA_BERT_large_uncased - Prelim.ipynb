{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KSqG-xgDLRI"
   },
   "source": [
    "### Synonym Replacement - BERT Base Uncased\n",
    "\n",
    "#### Un-augmented test set\n",
    "#### Augment only the training set\n",
    "\n",
    "#### Get Original Paper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1646721905242,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "y6DHMdiyDSTl"
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# !pip install ekphrasis\n",
    "# !pip install transformers\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646721905243,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "X-o7OyjjDYwr"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('../Data/classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.16.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1646721916193,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "zOn6K2RgJBkA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanc\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanc\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading english - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../Preprocess')\n",
    "\n",
    "from dataCollect import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2005,
     "status": "ok",
     "timestamp": 1646722287248,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "wr-vv22ZMhT-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>rationales</th>\n",
       "      <th>final_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179055004553900032_twitter</td>\n",
       "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1179063826874032128_twitter</td>\n",
       "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1178793830532956161_twitter</td>\n",
       "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
       "      <td>[African]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[African]</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1179088797964763136_twitter</td>\n",
       "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179085312976445440_twitter</td>\n",
       "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
       "      <td>[Caucasian, Women]</td>\n",
       "      <td>[Women, Caucasian]</td>\n",
       "      <td>[Women, Caucasian]</td>\n",
       "      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>9989999_gab</td>\n",
       "      <td>[if, ur, still, on, twitter, tell, carlton, i,...</td>\n",
       "      <td>[Men, Women, Other]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>9990225_gab</td>\n",
       "      <td>[when, i, first, got, on, here, and, said, i, ...</td>\n",
       "      <td>[African]</td>\n",
       "      <td>[African, Other]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>9991681_gab</td>\n",
       "      <td>[was, macht, der, moslem, wenn, der, zion, geg...</td>\n",
       "      <td>[Islam]</td>\n",
       "      <td>[Other]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>9992513_gab</td>\n",
       "      <td>[it, is, awful, look, at, world, demographics,...</td>\n",
       "      <td>[Hispanic]</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>[Asian]</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,...</td>\n",
       "      <td>hatespeech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>9998729_gab</td>\n",
       "      <td>[the, jewish, globalist, elite, have, only, im...</td>\n",
       "      <td>[African, Islam]</td>\n",
       "      <td>[Islam, Jewish]</td>\n",
       "      <td>[African, Islam, Jewish]</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           post_id  \\\n",
       "0      1179055004553900032_twitter   \n",
       "1      1179063826874032128_twitter   \n",
       "2      1178793830532956161_twitter   \n",
       "3      1179088797964763136_twitter   \n",
       "4      1179085312976445440_twitter   \n",
       "...                            ...   \n",
       "20143                  9989999_gab   \n",
       "20144                  9990225_gab   \n",
       "20145                  9991681_gab   \n",
       "20146                  9992513_gab   \n",
       "20147                  9998729_gab   \n",
       "\n",
       "                                                    text              target1  \\\n",
       "0      [i, dont, think, im, getting, my, baby, them, ...               [None]   \n",
       "1      [we, cannot, continue, calling, ourselves, fem...               [None]   \n",
       "2                    [nawt, yall, niggers, ignoring, me]            [African]   \n",
       "3      [<user>, i, am, bit, confused, coz, chinese, p...              [Asian]   \n",
       "4      [this, bitch, in, whataburger, eating, a, burg...   [Caucasian, Women]   \n",
       "...                                                  ...                  ...   \n",
       "20143  [if, ur, still, on, twitter, tell, carlton, i,...  [Men, Women, Other]   \n",
       "20144  [when, i, first, got, on, here, and, said, i, ...            [African]   \n",
       "20145  [was, macht, der, moslem, wenn, der, zion, geg...              [Islam]   \n",
       "20146  [it, is, awful, look, at, world, demographics,...           [Hispanic]   \n",
       "20147  [the, jewish, globalist, elite, have, only, im...     [African, Islam]   \n",
       "\n",
       "                  target2                   target3  \\\n",
       "0                  [None]                    [None]   \n",
       "1                  [None]                    [None]   \n",
       "2                  [None]                 [African]   \n",
       "3                 [Asian]                   [Asian]   \n",
       "4      [Women, Caucasian]        [Women, Caucasian]   \n",
       "...                   ...                       ...   \n",
       "20143              [None]                    [None]   \n",
       "20144    [African, Other]                    [None]   \n",
       "20145             [Other]                    [None]   \n",
       "20146             [Asian]                   [Asian]   \n",
       "20147     [Islam, Jewish]  [African, Islam, Jewish]   \n",
       "\n",
       "                                              rationales final_label  \n",
       "0                                                     []      normal  \n",
       "1                                                     []      normal  \n",
       "2                                                     []      normal  \n",
       "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  hatespeech  \n",
       "4      [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  hatespeech  \n",
       "...                                                  ...         ...  \n",
       "20143  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,...   offensive  \n",
       "20144  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...   offensive  \n",
       "20145                                                 []      normal  \n",
       "20146  [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,...  hatespeech  \n",
       "20147  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...   offensive  \n",
       "\n",
       "[20148 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'data_file' : '../Data/dataset.json', 'class_names' : '../Data/classes.npy'}\n",
    "\n",
    "raw_data = get_annotated_data(params)\n",
    "\n",
    "raw_data_final = raw_data[['post_id', 'text', 'target1', 'target2', 'target3', 'rationales', 'final_label']]\n",
    "\n",
    "raw_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s): \n",
    "    \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string  \n",
    "    for ele in s: \n",
    "        str1 += ele\n",
    "        str1 += ' '\n",
    "    \n",
    "    # return string  \n",
    "    return str1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "executionInfo": {
     "elapsed": 94730,
     "status": "error",
     "timestamp": 1646723548881,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "-NPhLO0YTBaW",
    "outputId": "c38afa72-a95a-4624-b5fb-60c0ccb0e571"
   },
   "outputs": [],
   "source": [
    "# Select appropriate columns for original paper data\n",
    "# re-assemble token list to text\n",
    "\n",
    "raw_data_filtered = raw_data[raw_data['final_label'] != 'undecided']\n",
    "\n",
    "orig_text_token = raw_data_filtered['text']\n",
    "\n",
    "orig_text = [listToString(s) for s in orig_text_token]\n",
    "\n",
    "orig_post_id = raw_data_filtered['post_id']\n",
    "\n",
    "orig_labels = raw_data_filtered['final_label'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split Original Data on post_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified test train split, return train, dev, and test sets\n",
    "\n",
    "def create_train_dev_test(text, labels, dev_size, test_size):\n",
    "    t = dev_size + test_size\n",
    "    r = dev_size/t\n",
    "    X_train, X_test, y_train, y_test = train_test_split(text, labels, test_size=t, stratify=labels)\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)\n",
    "    \n",
    "    return X_train, X_dev, X_test, y_train, y_dev, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_id, X_dev_id, X_test_id, y_train, y_dev, y_test = create_train_dev_test(orig_post_id, orig_labels, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15383\n",
      "1923\n",
      "1923\n"
     ]
    }
   ],
   "source": [
    "x_train_df = pd.DataFrame({'post_id' : X_train_id.to_list()})\n",
    "x_dev_df = pd.DataFrame({'post_id' : X_dev_id.to_list()})\n",
    "x_test_df = pd.DataFrame({'post_id' : X_test_id.to_list()})\n",
    "\n",
    "X_train_df = pd.merge(x_train_df, raw_data_final, how='inner', on='post_id')\n",
    "X_dev_df = pd.merge(x_dev_df, raw_data_final, how='inner', on='post_id')\n",
    "X_test_df = pd.merge(x_test_df, raw_data_final, how='inner', on='post_id')\n",
    "\n",
    "X_train_text = [listToString(s) for s in X_train_df['text']]\n",
    "X_dev_text= [listToString(s) for s in X_dev_df['text']]\n",
    "X_test_text = [listToString(s) for s in X_test_df['text']]\n",
    "\n",
    "print(len(X_train_text))\n",
    "print(len(X_dev_text))\n",
    "print(len(X_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115374"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load augmented datasets generated by EDA\n",
    "# sr = synonym replacement\n",
    "# ri = random synonym insertion\n",
    "# rs = random swap\n",
    "# rd = random deletion\n",
    "# dataframe name format: method_number \n",
    "\n",
    "sr_1_df = pd.read_csv('../test_data_set/EDA_5_0_7_sr_rest_0_1.csv')\n",
    "ri_1_df = pd.read_csv('../test_data_set/EDA_5_0_7_ri_rest_0_1.csv')\n",
    "rs_1_df = pd.read_csv('../test_data_set/EDA_5_0_7_rs_rest_0_1.csv')\n",
    "rd_1_df = pd.read_csv('../test_data_set/EDA_5_0_7_rd_rest_0_1.csv')\n",
    "all_1_df = pd.read_csv('../test_data_set/EDA_5_all_0_1s.csv')\n",
    "all_5_df = pd.read_csv('../test_data_set/EDA_5_all_0_5s.csv')\n",
    "\n",
    "# remove undecided labeled examples\n",
    "sr_1_df_filtered = sr_1_df[sr_1_df['final_label'] != 'undecided']\n",
    "ri_1_df_filtered = ri_1_df[ri_1_df['final_label'] != 'undecided']\n",
    "rs_1_df_filtered = rs_1_df[rs_1_df['final_label'] != 'undecided']\n",
    "rd_1_df_filtered = rd_1_df[rd_1_df['final_label'] != 'undecided']\n",
    "all_1_df_filtered = all_1_df[all_1_df['final_label'] != 'undecided']\n",
    "all_5_df_filtered = all_5_df[all_5_df['final_label'] != 'undecided']\n",
    "\n",
    "len(sr_1_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92298"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train, dev, test for each set\n",
    "sr_1_df_train = sr_1_df_filtered[sr_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "ri_1_df_train = ri_1_df_filtered[ri_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "rs_1_df_train = rs_1_df_filtered[rs_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "rd_1_df_train = rd_1_df_filtered[rd_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "all_1_df_train = all_1_df_filtered[all_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "all_5_df_train = all_5_df_filtered[all_5_df_filtered['post_id'].isin(X_train_id)]\n",
    "\n",
    "# select text sets\n",
    "\n",
    "aug_sr_text = sr_1_df_train['text_str'].to_list()\n",
    "aug_ri_text = ri_1_df_train['text_str'].to_list()\n",
    "aug_rs_text = rs_1_df_train['text_str'].to_list()\n",
    "aug_rd_text = rd_1_df_train['text_str'].to_list()\n",
    "aug_all_1_text = all_1_df_train['text_str'].to_list()\n",
    "aug_all_5_text = all_5_df_train['text_str'].to_list()\n",
    "\n",
    "# select label sets\n",
    "\n",
    "aug_sr_labels = sr_1_df_train['final_label']\n",
    "aug_ri_labels = ri_1_df_train['final_label']\n",
    "aug_rs_labels = rs_1_df_train['final_label']\n",
    "aug_rd_labels = rd_1_df_train['final_label']\n",
    "aug_all_1_labels = all_1_df_train['final_label']\n",
    "aug_all_5_labels = all_5_df_train['final_label']\n",
    "\n",
    "len(aug_sr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine with original data\n",
    "\n",
    "# # leave in list format\n",
    "# aug_sr_text = aug_sr_text + orig_text\n",
    "# aug_ri_text = aug_ri_text + orig_text\n",
    "# aug_rs_text = aug_rs_text + orig_text\n",
    "# aug_rd_text = aug_rd_text + orig_text\n",
    "# aug_all_1_text = aug_all_1_text + orig_text\n",
    "# aug_all_5_text = aug_all_5_text + orig_text\n",
    "\n",
    "# # in Series format\n",
    "# aug_sr_labels = pd.Series(aug_sr_labels + orig_labels)\n",
    "# aug_ri_labels = pd.Series(aug_ri_labels + orig_labels)\n",
    "# aug_rs_labels = pd.Series(aug_rs_labels + orig_labels)\n",
    "# aug_rd_labels = pd.Series(aug_rd_labels + orig_labels)\n",
    "# aug_all_1_labels = pd.Series(aug_all_1_labels + orig_labels)\n",
    "# aug_all_5_labels = pd.Series(aug_all_5_labels + orig_labels)\n",
    "\n",
    "# len(aug_sr_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class label to 1 hot encoding\n",
    "\n",
    "original_labels = pd.Series(orig_labels)\n",
    "\n",
    "\n",
    "def convert_to_oh(S):\n",
    "    '''takes a pandas series of text labels and returns one hot encoding equivalent\n",
    "    0 = normal, 1 = offensive, 2 = hatespeech\n",
    "    ''' \n",
    "    S_numerical = S.apply(lambda x: 0 if x=='normal' else (1 if x=='offensive' else 2))\n",
    "    S_oh = keras.utils.to_categorical(S_numerical, num_classes = 3, dtype = 'float32')\n",
    "    return S_oh\n",
    "    \n",
    "# original dataset - train, dev, and train\n",
    "y_train_orig = convert_to_oh(pd.Series(y_train))\n",
    "y_dev_orig = convert_to_oh(pd.Series(y_dev))\n",
    "y_test_orig = convert_to_oh(pd.Series(y_test))\n",
    "\n",
    "# augmented with sr = 0.1\n",
    "y_train_aug_sr = convert_to_oh(aug_sr_labels)\n",
    "\n",
    "# augmented with ri = 0.1\n",
    "y_train_aug_ri = convert_to_oh(aug_ri_labels)\n",
    "\n",
    "# augmented with rs = 0.1\n",
    "y_train_aug_rs = convert_to_oh(aug_rs_labels)\n",
    "\n",
    "# augmented with rd = 0.1\n",
    "y_train_aug_rd = convert_to_oh(aug_rd_labels)\n",
    "\n",
    "# augmented with all = 0.1\n",
    "y_train_all_1 = convert_to_oh(aug_all_1_labels)\n",
    "\n",
    "# augmented with all = 0.5\n",
    "y_train_all_5 = convert_to_oh(aug_all_5_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92298"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_ri_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92298"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_aug_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_aug_ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "#bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we arent continue calling ourselves feminists if the rights of all womxn to addressed yes list a sexual offences public cannot but will a trans lesbian bisexual on queer womxn be able to enter their information and the reporting sheet gender forum',\n",
       " 'we cannot continue feminists ourselves calling if the be of list womxn arent addressed yes to a sexual offences public but all will a trans lesbian bisexual and queer womxn rights able to enter their information on the reporting sheet gender forum',\n",
       " 'we cannot keep on vocation ourselves feminist if the right wing of all womxn arent come up to yes to a intimate discourtesy populace lean but will a trans sapphic epicene and bilk womxn be able bodied to go in their info on the account sheet of paper sexuality meeting place',\n",
       " 'we cannot continue calling ourselves feminists if the rights of all womxn arent yes to a sexual offences public list but a trans bisexual and queer womxn be able to enter their information on reporting gender forum',\n",
       " 'we cannot remain bid ourselves feminist if the rightfield of all womxn arent speak yes to a intimate criminal offence world number but will a trans tribade epicene and poof womxn be able bodied to go into their entropy on the account bed sheet sexuality meeting place',\n",
       " 'we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum',\n",
       " 'nawt pine tree state yall niggers ignoring me',\n",
       " 'nawt yall niggers ignoring me',\n",
       " 'nawt yall niggers ignoring me',\n",
       " 'nawt yall spade brush off me',\n",
       " 'nawt yall niggers ignoring ignore me',\n",
       " 'nawt yall niggers ignoring me',\n",
       " 'this bitch with burger eating a whataburger in no top bun and holding it palm up i hate white bitches',\n",
       " 'this holler in whataburger exhaust a hamburger with no go past roll and prevail it thenar up i detest lily white gripe',\n",
       " 'this bitch in whataburger eating warren burger a burger with take hold no top bun and holding it palm up i hate white bitches',\n",
       " 'this bitch in whataburger eating a burger with no top bun it holding and palm up white hate i bitches',\n",
       " 'this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches',\n",
       " 'this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches',\n",
       " 'laura loomer raped me while screaming at me in disgusting kike language and said we must the goyim laura loomer loomergate',\n",
       " 'laura loomer raped me while screaming oral communication at me in her disgusting kike language and said we must exterminate the cry goyim laura loomer loomergate',\n",
       " 'laura loomer raped me while screaming at we in her disgusting kike language and loomergate me must exterminate the goyim laura loomer said',\n",
       " 'laura loomer raped me while screaming at me in oral communication her disgusting kike language and said sheeny we must exterminate the goyim laura loomer loomergate',\n",
       " 'laura loomer knock me while scream at me in her sicken sheeny spoken communication and aforesaid we moldiness root out the non jew laura loomer loomergate',\n",
       " 'laura loomer raped me while screaming at me in her disgusting kike language and said we must exterminate the goyim laura loomer loomergate',\n",
       " 'and this is why i end up with nigger trainee doctors bed who can not speak properly lack basic knowledge of biology it spade truly scary if the public only knew',\n",
       " 'and this is why i death up with nigra trainee doctor who can not mouth decently deficiency introductory noesis of biota it rightfully shuddery if the world only fuck',\n",
       " 'and this is why i end up with nigger trainee doctors who can not talk speak properly lack basic knowledge of canonical biology it truly scary if the public only knew',\n",
       " 'and this is why i end up with nigger trainee who doctors can not speak properly lack basic knowledge of biology it truly scary only the public if knew',\n",
       " 'trainee this is why i end up with nigger and doctors who can knowledge speak properly lack basic not of biology it truly scary if the public only knew',\n",
       " 'and this is why i end up with nigger trainee doctors who can not speak properly lack basic knowledge of biology it truly scary if the public only knew',\n",
       " 'nogs jews and dykes how enrich enriching',\n",
       " 'nogs and jews dykes how enriching',\n",
       " 'jews and dykes how enriching',\n",
       " 'nogs jews how dykes and enriching',\n",
       " 'peg jew and dike how enrich',\n",
       " 'nogs jews and dykes how enriching',\n",
       " 'shamed until shew destitute unless you are a israelite a nigra or a devotee of both',\n",
       " 'you until proven innocent unless guilty are a jew a nigger or a lover of both',\n",
       " 'guilty until proven innocent unless you are a jew spade a nigger or a lover of both',\n",
       " 'guilty until proven innocent unless are a jew a or lover of both',\n",
       " 'shamed until show devoid unless you are a israelite a nigra or a buff of both',\n",
       " 'guilty until proven innocent unless you are a jew a nigger or a lover of both',\n",
       " 'tired i can not support abortion a moral standpoint wired i support it morally easy stop looking at those little niglets as future doctors and see them for what they really are future rapists of white women and future welfare recipient of white tax dollars and future democrat voters',\n",
       " 'jade i can not financial backing miscarriage from a lesson stand wire i can financial backing it virtuously slow block up expect at those footling niglets as succeeding physician and understand them for what they genuinely are succeeding rapist of blank womanhood and succeeding well being receiver of blank assess dollar and succeeding populist elector',\n",
       " 'well worn i can not reinforcement miscarriage from a lesson viewpoint pumped up i can reinforcement it virtuously light point await at those picayune niglets as futurity sophisticate and control them for what they real are futurity rapist of egg white cleaning lady and futurity benefit recipient role of egg white taxation dollar bill and futurity populist elector',\n",
       " 'stop i can not support abortion from a moral standpoint are i can support it morally easy tired looking at as recipient niglets those future doctors and see them for what they really wired future rapists white of women and future welfare little of white tax dollars and future democrat voters',\n",
       " 'tired i can not support abortion from a moral standpoint wired i can support it morally easy stop looking at those little niglets as doctors and see them for what they really are future rapists white women and future welfare recipient of white tax and future democrat voters',\n",
       " 'tired i can not support abortion from a moral standpoint wired i can support it morally easy stop looking at those little niglets as future doctors and see them for what they really are future rapists of white women and future welfare recipient of white tax dollars and future democrat voters',\n",
       " 'turn turn per centum of brit conceive multiculturalism is a unsuccessful person i infer the other per centum are glad with their muzzie maestro there no keen in united kingdom of great britain and northern ireland any longer before long swelled ben will be born again into a minaret',\n",
       " 'number number in of brits percent multiculturalism is a failure i guess the other think percent happy with their muzzie master there no great are britain anymore soon big ben will be converted into a minaret',\n",
       " 'number number percent of brits great britain think multiculturalism is a failure i guess the other percent are happy with their muzzie master there no great follow in follow britain anymore soon big ben will be converted into a minaret',\n",
       " 'number number percent of brits think multiculturalism is pct a failure i guess the other percent are happy with list their muzzie master there no great self aggrandising in britain anymore soon big ben will be converted into a minaret',\n",
       " 'number number percent of brits think multiculturalism is a failure i guess other percent are happy with their muzzie master there great soon big ben will be converted into a minaret',\n",
       " 'number number percent of brits think multiculturalism is a failure i guess the other percent are happy with their muzzie master there no great in britain anymore soon big ben will be converted into a minaret',\n",
       " 'tariq nasheed beating the fuck out of that drum beloved lmao somebody put a biscuit in that niggas mouth already',\n",
       " 'tariq the beating nasheed fuck out of put drum beloved lmao somebody that a biscuit in that niggas mouth already',\n",
       " 'tariq nasheed beating niggas fuck out of that drum beloved lmao the put a biscuit in that somebody mouth already',\n",
       " 'tariq nasheed tucker the get it on out of that swot up honey lmao soul assign a cooky in that nigger oral cavity already',\n",
       " 'tariq nasheed flummox the bang out of that mug up dear lmao person invest a cookie in that coon lip already',\n",
       " 'tariq nasheed beating the fuck out of that drum beloved lmao somebody put a biscuit in that niggas mouth already',\n",
       " 'percent cotton thigh highs to avoid contact whatever with any gay chemicals',\n",
       " 'percent cotton thigh highs to avoid contact with any gay chemicals',\n",
       " 'pct cotton wool second joint highschool to keep off tangency with any homo chemicals',\n",
       " 'percent cotton thigh highs to avoid contact with any gay chemicals',\n",
       " 'percent cotton thigh highs to chemicals contact with any gay avoid',\n",
       " 'percent cotton thigh highs to avoid contact with any gay chemicals',\n",
       " 'oomf a enumerate yearl onetime press sunny and possessed with me somebody help oneself',\n",
       " 'oomf a routine yearl sometime wardrobe sunny and taken up with me somebody helper',\n",
       " 'oomf a number yearl me closet gay and obsessed with old someone help',\n",
       " 'oomf a number yearl old closet gay and obsessed with me someone axerophthol help',\n",
       " 'oomf number yearl old closet gay and obsessed with me someone help',\n",
       " 'oomf a number yearl old closet gay and obsessed with me someone help',\n",
       " 'all of my exes cute but were hoes i guess i only attract fly looking thots',\n",
       " 'all of my exes were but they were hoes i guess i only fly looking thots',\n",
       " 'fly of my exes were cute but they were hoes i guess i only attract all looking thots',\n",
       " 'all of my x were cunning but they were hoe i estimate i only appeal fly ball expect thots',\n",
       " 'all x of my exes were cute but they were hoes i guess i only attract fly looking thots',\n",
       " 'all of my exes were cute but they were hoes i guess i only attract fly looking thots ',\n",
       " 'fellow be thrifty she texting other nigra',\n",
       " 'be fellas careful she texting other niggas',\n",
       " 'fellas early be careful she texting other niggas',\n",
       " 'fellas be careful she other texting niggas',\n",
       " 'fellas be careful she texting other niggas',\n",
       " 'fellas be careful she texting other niggas',\n",
       " 'italian niggas call they dick hawkshaw the poozingi',\n",
       " 'italian niggas call they dick the poozingi',\n",
       " 'italian niggas call they dick the poozingi',\n",
       " 'italian nigger ring they cock the poozingi',\n",
       " 'italian niggas call dick they the poozingi',\n",
       " 'italian niggas call they dick the poozingi',\n",
       " 'user what did the old lady do was a nazi or supremacist',\n",
       " 'user what did the old lady do was she a nazi or white surgery supremacist',\n",
       " 'user what did the old lady do was she a nazi or practice white supremacist',\n",
       " 'user did the old lady do was she a or white supremacist',\n",
       " 'exploiter what did the sometime dame do was she a german nazi or gabardine supremacist',\n",
       " 'user what did the old lady do was she a nazi or white supremacist',\n",
       " 'user user user user user he married a negress because women did not want him but females all over america love nobama',\n",
       " 'user user user user user he married a negress because white women did not want him but practice black females all drug user over america love nobama',\n",
       " 'user user user user white he married a negress because user women america not want him but black females all over did love nobama',\n",
       " 'drug user drug user drug user drug user drug user he matrimonial a negress because andrew dickson white cleaning lady did not neediness him but smuggled female person all over usa make out nobama',\n",
       " 'drug user drug user drug user drug user drug user he get hitched with a negress because e b white charwoman did not deprivation him but opprobrious female person all over united states have sex nobama',\n",
       " 'user user user user user he married a negress because white women did not want him but black females all over america love nobama',\n",
       " 'user condoning drug use not all at kike thanks for that disclosure',\n",
       " 'condoning drug use not kike at all thanks that disclosure',\n",
       " 'drug use not kike all thanks for that disclosure',\n",
       " 'exploiter excuse dose economic consumption not hymie at all thank for that revelation',\n",
       " 'exploiter condone do drugs usance not yid at all give thanks for that revelation',\n",
       " 'user condoning drug use not kike at all thanks for that disclosure',\n",
       " 'user user people support as foreigners you can not say the same about the states obviously not all americans israel to guns not all americans act their government treatment of immigrants and if but when it comes pro are suddenly the logic changes',\n",
       " 'substance abuser substance abuser the great unwashed dissemble as if you can not aver the same about the say plain not all american english are professional ordnance not all american english hold their governing discussion of immigrant and outlander but when it add up to zion abruptly the system of logic convert',\n",
       " 'user user people act immigrants if say when not you the same about the states obviously americans all americans are pro guns not all not support their government treatment of as and foreigners but can it comes to israel suddenly the logic changes',\n",
       " 'user user people act as if you can not say the same about the states obviously not all americans are pro guns not all americans support their government treatment of immigrants and foreigners but when it comes to israel suddenly the logic changes',\n",
       " 'user land user people act as if you non can not say the same sami about the states obviously not all americans are pro guns not all americans support their government treatment of immigrants and foreigners but when it comes to israel suddenly the logical system logic changes',\n",
       " 'user user people act as if you can not say the same about the states obviously not all americans are pro guns not all americans support their government treatment of immigrants and foreigners but when it comes to israel suddenly the logic changes',\n",
       " 'user user they visited helped provided food to intellectual nourishment those kps while patch islam c terrorist butured raped and forced them to leave their own land',\n",
       " 'substance abuser substance abuser they bring down assist cater food for thought to those kp while muhammadanism one c terrorist butured plunder and impel them to get out their own set down',\n",
       " 'user user they visited provided food to those kps while islam c terrorist butured raped and forced them to leave their land',\n",
       " 'exploiter exploiter they call in help oneself supply food for thought to those kitchen police while islamism atomic number terrorist butured ravish and thrust them to depart their own acres',\n",
       " 'user user they visited helped provided food to those kps while islam c terrorist butured raped and forced them to leave their cater cater own land',\n",
       " 'user user they visited helped provided food to those kps while islam c terrorist butured raped and forced them to leave their own land',\n",
       " 'anyhow the fact that her equip straight off plunder jacques anatole francois thibault legal philosophy abt no boldness extend veil but is all the same headline in city of light forge hebdomad present that the legal philosophy was neer abt bedim seventh cranial nerve designation but abt e b white domination and islamophobia',\n",
       " 'read anyways the record fact that her outfit directly violates france law abt no face coverings veils but is still headlined in paris fashion week shows that the law was never abt obscured facial identification but abt white supremacy forge and islamophobia',\n",
       " 'anyways the fact that her outfit directly violates france law no coverings veils but still headlined in paris fashion week shows that the law was never abt obscured facial identification but abt white supremacy and islamophobia',\n",
       " 'anyways the fact that her outfit directly violates france law abt no face veils but still headlined in week shows law was never abt obscured facial but white supremacy and islamophobia',\n",
       " 'anyways the fact that fashion outfit directly obscured france law abt no face coverings never but is still headlined in paris her week shows that the law was veils abt violates facial identification but abt white supremacy and islamophobia',\n",
       " 'anyways the fact that her outfit directly violates france law abt no face coverings veils but is still headlined in paris fashion week shows that the law was never abt obscured facial identification but abt white supremacy and islamophobia',\n",
       " 'lol axerophthol what a stupid kike',\n",
       " 'lol what a pudden head sheeny',\n",
       " 'lol what a stupefied yid',\n",
       " 'lol what a stupid kike',\n",
       " 'what lol a stupid kike',\n",
       " 'lol what a stupid kike',\n",
       " 'it funny how career people offended by the word nigger have no problem calling people nazis what the difference',\n",
       " 'it funny how people offended by the word nigger people no problem calling have nazis what the difference',\n",
       " 'it mirthful how mass scandalize by the countersign nigga have no job visit mass german nazi what the dispute',\n",
       " 'it odd how citizenry pained by the give voice coon have no trouble address citizenry nazi what the difference of opinion',\n",
       " 'it funny how people offended by the word have no problem calling people what the',\n",
       " 'it funny how people offended by the word nigger have no problem calling people nazis what the difference',\n",
       " 'as much as i appreciate a format of open discussion i really just a want facebook that can i say beaner on',\n",
       " 'as much as that appreciate a format of open discussion i really just want a facebook i i can on beaner say',\n",
       " 'deprivation as much as i appreciate a format of open discussion i really just want a facebook that i can say along beaner on',\n",
       " 'as much as i appreciate a format of open discussion i really just want facebook that i can say beaner on',\n",
       " 'much i a of open i really want a facebook that i can say beaner on',\n",
       " 'as much as i appreciate a format of open discussion i really just want a facebook that i can say beaner on',\n",
       " 'why does anyone give care what the albino coon has to suppose',\n",
       " 'why does anyone care what the albino nigger practice has to say',\n",
       " 'does anyone care what albino nigger has to',\n",
       " 'why does anyone care what the albino nigger say to has',\n",
       " 'why does anyone care what the albino nigger to say',\n",
       " 'why does anyone care what the albino nigger has to say',\n",
       " 'that was just kill a photo look up rhyan moody she was killed on thanksgiving by an illegal spic',\n",
       " 'that was just a photo look up rhyan moody was killed on thanksgiving by illegal spic',\n",
       " 'that was a photo look up rhyan moody was on thanksgiving by an illegal spic',\n",
       " 'that was just a photo look up rhyan killed she was moody on thanksgiving by an illegal spic',\n",
       " 'that was just a photo look up rhyan moody exposure she was killed on thanksgiving by an illegal spic',\n",
       " 'that was just a photo look up rhyan moody she was killed on thanksgiving by an illegal spic',\n",
       " 'this sounds like a kike national socialist',\n",
       " 'this sounds axerophthol like a kike national socialist',\n",
       " 'this sounds like a kike national socialist',\n",
       " 'this speech sound wish a yid internal socialist',\n",
       " 'this sounds like a sheeny kike national socialist',\n",
       " 'this sounds like a kike national socialist',\n",
       " 'only elite looters are enriched when they import a iq moslem onto importee welfare section number homeless vets would not axerophthol need taxpayer practice paid classes on how to use toilets in free homes',\n",
       " 'on elite looters are enriched when not import a iq moslem onto welfare section number homeless vets would they need taxpayer homes classes only how to use toilets in free paid',\n",
       " 'only elite in are enriched when they import a iq moslem onto welfare section number homeless vets not would need paid taxpayer classes on how to use toilets looters free homes',\n",
       " 'only elite looters are enriched when they import a iq moslem onto welfare section number homeless vets would not need paid on how to use toilets in free homes',\n",
       " 'only elite group pillager are enrich when they spell a intelligence quotient islamic onto social welfare department act homeless person vet would not postulate taxpayer paying course of instruction on how to employment lav in resign place',\n",
       " 'only elite looters are enriched when they import a iq moslem onto welfare section number homeless vets would not need taxpayer paid classes on how to use toilets in free homes',\n",
       " 'a negro moslem doctor with struck off for negligence when a syndrome number campaign old kid got down white died the guardians response is to help promote a crowd funding year for her',\n",
       " 'a negro moslem doctor got off for negligence when a white number year old with down syndrome died the guardians response is to help a crowd funding campaign for her',\n",
       " 'a negro moslem doctor got struck support off for negligence when a white number year old kid with down syndrome died the guardians response is to help promote land a crowd funding campaign herd for her',\n",
       " 'a negro moslem doctor got struck year for syndrome when a white number her old kid with down negligence died the guardians response is to help promote a crowd funding campaign for off',\n",
       " 'a negroid islamic bushel beat excise off for neglect when a snowy list twelvemonth erstwhile chaff with down syndrome go bad the guardian answer is to assistance advance a crowd together financial backing effort for her',\n",
       " 'a negro moslem doctor got struck off for negligence when a white number year old kid with down syndrome died the guardians response is to help promote a crowd funding campaign for her',\n",
       " 'princess sapphire of silverland is dyke and threw the first brick at stonewall',\n",
       " 'anyways princess lazuline of silverland is a butch and bedevil the first class honours degree brick at stonewall',\n",
       " 'sky blue anyway princess sapphire of silverland is a dyke and threw the first brick at stonewall',\n",
       " 'anyway princess sapphire of a is silverland dyke and threw the first brick at stonewall',\n",
       " 'anyways princess lazuline of silverland is a dam and befuddle the number one brick at stonewall',\n",
       " 'anyway princess sapphire of silverland is a dyke and threw the first brick at stonewall',\n",
       " 'smile cuz i am youthful shirley temple ample and i am well favoured',\n",
       " 'smiling cuz i am young black rich and i am handsome',\n",
       " 'smiling cuz i am young and rich black i am handsome',\n",
       " 'smiling cuz i deep am young black rich and i am handsome',\n",
       " 'smiling cuz i am young black i am handsome',\n",
       " 'smiling cuz i am young black rich and i am handsome',\n",
       " 'sex be so good a bitch be slow stroking and crying',\n",
       " 'wind up be so safe a holler be slow up stroke and battle cry',\n",
       " 'sex be so good a bitch be slow bellyache stroking and crying',\n",
       " 'sex be so good a bitch be slow stroking and follow crying',\n",
       " 'sexual urge be so expert a bellyache be slacken stroke and war cry',\n",
       " 'sex be so good a bitch be slow stroking and crying',\n",
       " 'bitches be so fine and got the nerve ilk to like niggas',\n",
       " 'bitches be so fine and got the nerve to like niggas',\n",
       " 'bitches be so fine and got the nerve to like niggas',\n",
       " 'squawk be so mulct and vex the mettle to ilk nigra',\n",
       " 'bitches be so fine set out and got the nerve to like niggas',\n",
       " 'bitches be so fine and got the nerve to like niggas ',\n",
       " 'play one at of overwatch after a month away very first game instantly has two players calling people faggots and to kill yourself oh boy anymore gotta just all play this game game not i',\n",
       " 'gambling peerless biz of overwatch after a calendar month off very number one biz like a shot has ii actor foretell mass faggot and to bolt down yourself buckeye state son i gotta just not gambling this biz at all any longer',\n",
       " 'play one game of overwatch after a calling away very first game and has two players month people faggots instantly to kill yourself oh boy i gotta just not play this game at all anymore',\n",
       " 'free rein single gamey of overwatch after a calendar month by very first of all gamey at once has ii actor holler masses pansy and to obliterate yourself ohio son i gotta just not free rein this gamey at all any longer',\n",
       " 'play one game of overwatch after a away very game instantly has two calling people faggots and to kill oh boy i gotta just not this game at all anymore',\n",
       " 'play one game of overwatch after a month away very first game instantly has two players calling people faggots and to kill yourself oh boy i gotta just not play this game at all anymore',\n",
       " 'user user the shoe being on the other foot would mean that blacks and jews would pay high subsidy taxes to subsidies the child birth of white babies',\n",
       " 'drug user drug user the brake shoe being on the other invertebrate foot would tight that lightlessness and hebrew would make up senior high assess to subsidy the deliver of whiteness baby',\n",
       " 'user user the shoe blacks on the high foot would mean that being and jews would pay other taxes to subsidies the birth of white babies',\n",
       " 'would user user shoe being on the other foot would mean that blacks and jews the pay high taxes to subsidies the birth of white babies',\n",
       " 'user user the shoe being on the other foot would mean that blacks and jews would pay taxes to subsidies the birth of white babies',\n",
       " 'user user the shoe being on the other foot would mean that blacks and jews would pay high taxes to subsidies the birth of white babies',\n",
       " 'user the they are the ones whose mothers were raped by m invaders',\n",
       " 'user the irony is they are the ones whose mothers were raped by invaders m',\n",
       " 'exploiter the sarcasm is they are the one whose overprotect were rape by mib encroacher',\n",
       " 'drug user the sarcasm is they are the single whose sire were tap by mib invader',\n",
       " 'user the irony is they are the ones whose mothers were raped by m invaders',\n",
       " 'user the irony is they are the ones whose mothers were raped by m invaders',\n",
       " 'substance abuser substance abuser is a intrigue impostor who battlefront a bushwhacker furor',\n",
       " 'user user is a scheming fraud who hillbilly a fronts cult',\n",
       " 'user a is a scheming fraud who fronts user hillbilly cult',\n",
       " 'user user is a scheming fraud fronts a hillbilly cult',\n",
       " 'user user is a scheming fraud who fronts cult',\n",
       " 'user user is a scheming fraud who fronts a hillbilly cult',\n",
       " 'user no idea who these women are they get all the leap out credit for jumping on after the women char who narrate been calling for impeachment take the hits and smears and told to go back to where set out they come from job well done unknown white congress women',\n",
       " 'user no idea who these women are and get credit the all for from on after the women who been calling for impeachment jumping the hits they smears and told to go back to where they come take job well done unknown white congress women',\n",
       " 'user drug user no idea who these women are they get all the credit for drug user jumping on after the women who been calling for impeachment take the hits and smears and told to char go drug user back to where they come from job well done unknown white congress women',\n",
       " 'user no idea who these women are they get all the credit for jumping after the women who been calling for impeachment take the hits and smears and told to go back to where they come from job well done unknown white congress women',\n",
       " 'user no idea who these women are and get all the credit for jumping on unknown the women smears been calling for impeachment take the hits and who they told to go job to where they come from back well done after white congress women',\n",
       " 'user no idea who these women are they get all the credit for jumping on after the women who been calling for impeachment take the hits and smears and told to go back to where they come from job well done unknown white congress women ',\n",
       " 'yttrium is braggy spoil miles davis a fagot on unblushing energy department',\n",
       " 'unblushing y is big baby davis a faggot on shameless doe',\n",
       " 'y baby davis a faggot on shameless doe',\n",
       " 'y is big baby davis on faggot a shameless doe',\n",
       " 'wye is heavy featherbed dwight davis a queen on unblushing department of energy',\n",
       " 'y is big baby davis a faggot on shameless doe',\n",
       " 'user to babies in cages destroying environment response rolling back regulations siding with white supremacists bad mouthing gold star families shithole puerto by user countries rico that just a few',\n",
       " 'user user in destroying environment rolling regulations siding white bad mouthing gold star families shithole countries response to puerto rico just a few',\n",
       " 'user user babies in cages destroying environment by rolling back regulations siding with white supremacists bad mouthing rico act gold star families shithole forged countries response to puerto rico that just sidetrack a few',\n",
       " 'substance abuser substance abuser infant in batting cage ruin surroundings by swan hind regulation sidetrack with gabardine supremacist defective utter gilded wiz crime syndicate shithole area answer to puerto rico act that just a few',\n",
       " 'user user babies in cages back mouthing by rolling destroying supremacists siding with white regulations bad environment gold star families shithole countries response to puerto rico that just a few',\n",
       " 'user user babies in cages destroying environment by rolling back regulations siding with white supremacists bad mouthing gold star families shithole countries response to puerto rico that just a few',\n",
       " 'i betray follow do not blame orlando pie rats for loosing like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'i do not damned orlando proto indo european betrayer for unloose same this they are drink in from that lightlessness tag mtn sulphur diski wafa wafa',\n",
       " 'i do not blame orlando pie rats for loosing like this mtn are they from that black label drunk ss diski wafa wafa',\n",
       " 'i do not blame orlando pie that for loosing like this they are from drunk rats black label mtn ss diski wafa wafa',\n",
       " 'i betray do not unleash blame orlando pie rats for loosing like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'i do not blame orlando pie rats for loosing like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'related instagram forge tags for jewelry fashionable designer trendy hairstyle fashion gram fashion blog menswear men style trend',\n",
       " 'link instagram tags for jewellery stylish fashion designer trendy hair style forge hans c j gram forge web log menswear human manner swerve',\n",
       " 'related instagram tags for jewelry designer trendy hairstyle gram fashion blog menswear men style trend',\n",
       " 'related instagram tags men jewelry fashionable designer trendy hairstyle fashion gram fashion blog menswear for style trend',\n",
       " 'related instagram tags for jewelry trendy hairstyle fashion fashion menswear men style trend',\n",
       " 'related instagram tags for jewelry fashionable designer trendy hairstyle fashion gram fashion blog menswear men style trend',\n",
       " 'beguile woahs and draw hoe',\n",
       " 'charm woahs and pulling hoe',\n",
       " 'catch woahs and pull hoes',\n",
       " 'catch woahs and capture pull hoes',\n",
       " 'catch and pull hoes',\n",
       " 'catch woahs and pull hoes',\n",
       " 'niggas cry and complain females much i am starting to think you all the real so in the relationship',\n",
       " 'niggas cry and complain so much i all starting to think you am the real females in the relationship',\n",
       " 'niggas cry and complain so much i am starting to think you all the real females in the relationship',\n",
       " 'nigra call and plain so very much i am bug out to consider you all the tangible female in the family relationship',\n",
       " 'niggas cry and complain so much i am starting to think you all the real females in the relationship',\n",
       " 'niggas cry and complain so much i am starting to think you all the real females in the relationship ',\n",
       " 'now stephanie mad this nigga shit he getting liking bitches tonight',\n",
       " 'now stephanie liking this nigga shit he getting mad bitches tonight',\n",
       " 'now stephanie care this spade take a shit he pay off excited squawk this evening',\n",
       " 'now stephanie liking mad nigga shit he getting this bitches tonight',\n",
       " 'now stephanie liking this nigga sore shit he getting mad bitches tonight',\n",
       " 'now stephanie liking this nigga shit he getting mad bitches tonight',\n",
       " 'user there was a time that they where shooting young men on look at tweets i a whole series these are worse than the nazis and the children get raped and tortured in jail little palestinian children',\n",
       " 'user there was a time that they where shooting young men on follow demand look at follow my axerophthol tweets i did a whole serial series these people are worse than the nazis and the children get raped and tortured in jail little palestinian children',\n",
       " 'exploiter there was a clock time that they where shoot new serviceman on take flavor at my squeeze i did a altogether serial publication these citizenry are unfit than the nazi and the nestling drive sacked and anguished in clink fiddling palestinian arab nestling',\n",
       " 'user there was a follow time that they axerophthol where shooting young men on demand look at my conform to tweets i did a whole series these people are worse than the nazis and atomic number the children get raped and tortured in jail little palestinian children',\n",
       " 'substance abuser there was a sentence that they where sprout youthful humankind on ask await at my twitch i did a altogether serial publication these citizenry are spoilt than the german nazi and the fry have pillaged and anguished in jailhouse niggling palestinian arab fry',\n",
       " 'user there was a time that they where shooting young men on demand look at my tweets i did a whole series these people are worse than the nazis and the children get raped and tortured in jail little palestinian children',\n",
       " 'user user like pretty much anything rooted in nostalgia even tangentially is going down the wrong path because you a trans woman of color queer you almost certainly never had all things in had none',\n",
       " 'user user like pretty much anything rooted in nostalgia even tangentially is going down the wrong path because if you are a trans woman or disabled queer latina almost certainly never had all of things and in many cases had none',\n",
       " 'user user user like pretty much anything rooted in nostalgia even tangentially is going down the wrong path because funny if you are a trans woman of color or disabled surgery queer latina you almost certainly never sledding had all of things and in many operating theater cases had none',\n",
       " 'drug user drug user drug user alike somewhat a good deal anything root in nostalgia eve tangentially is decease down the amiss course because if you are a trans adult female of coloring or invalid pouf latina you virtually sure neer had all of thing and in many eccentric had none',\n",
       " 'user user user like pretty much anything rooted in nostalgia even tangentially is going down the wrong path because if you are a trans woman of color sure as shooting or sure as shooting disabled queer latina you almost certainly hoosier state never had all of things and in many cases had matter none',\n",
       " 'user user user like pretty much anything rooted in nostalgia even tangentially is going down the wrong path because if you are a trans woman of color or disabled queer latina you almost certainly never had all of things and in many cases had none',\n",
       " 'i am going to give my fellow be negroes some roman advice dont show up at white upward christian schools trying to make connections show up connector at because you are trying to be a christian the romans originally hated the christians they burned them at the stake and roman letters they fed them to lions',\n",
       " 'i them going to give my fellow up trying up dont show negroes at white christian are trying to make connections show advice at because you schools some to be a christian the romans originally hated the christians they burned am at the stake and they fed them to lions',\n",
       " 'i am choke to open my familiar black person some advice dont designate up at flannel christian schooling prove to urinate connection designate up at because you are prove to be a christian the epistle to the romans in the beginning hate the christian they fire them at the adventure and they run them to leo',\n",
       " 'i am going to give my fellow negroes some advice dont show up at white trying to make connections show up at because you are trying be a christian the romans originally hated the christians they burned them at the and they them to lions',\n",
       " 'going am white to give my fellow negroes some advice dont show to at i christian schools trying to make connections romans up at because you are trying to them a christian the show originally hated the christians they burned be at the stake and they fed them up lions',\n",
       " 'i am going to give my fellow negroes some advice dont show up at white christian schools trying to make connections show up at because you are trying to be a christian the romans originally hated the christians they burned them at the stake and they fed them to lions',\n",
       " 'the flag of comes maga fags in all it glory it the with nigger red shoes too',\n",
       " 'all flag of the maga fags in the it glory it comes with nigger red shoes too',\n",
       " 'the flag of the maga fags in all it glory it fleur de lis comes with nigger red shoes too',\n",
       " 'the flag the maga fags in all it glory it comes with red shoes too',\n",
       " 'the flag of the maga fags in all it reddish glory it comes with nigger red shoes too',\n",
       " 'the flag of the maga fags in all it glory it comes with nigger red shoes too',\n",
       " 'hispanic i hear the phrase white privilege one more words i am going to opt as come back in my next life to a black transgender latino illegal muslim jewish faggot feminist queer gay lesbian dike if piece of shit in other time everything i have not been in this life',\n",
       " 'if i hear the phrase white privilege one more time i am going to opt queer to come tribade back in my next life as more than a black hispanic latino illegal muslim jewish faggot feminist queer gay lesbian dike transgender piece of shit axerophthol in other words everything i have hoosier state not been in this life',\n",
       " 'if i hear the phrase white privilege one more time i am going to opt come back in my next life as a black hispanic latino muslim jewish faggot feminist queer gay dike transgender piece of shit other words everything i not been this',\n",
       " 'if i listen the phrasal idiom clean perquisite ace more metre i am get to prefer to come up backbone in my side by side life history as a melanize hispanic american hispanic illegal moslem judaic queen libber pouf festive tribade dam transgendered assemble of rat in other parole everything i have not been in this life history',\n",
       " 'if i take heed the idiomatic expression snowy exclusive right nonpareil more clock time i am release to prefer to descend backrest in my succeeding living as a nigrify hispanic american latin american illegal islamic judaic fairy womens rightist curious merry tribade dyke transgendered put together of whoreson in other formulate everything i have not been in this living',\n",
       " 'if i hear the phrase white privilege one more time i am going to opt to come back in my next life as a black hispanic latino illegal muslim jewish faggot feminist queer gay lesbian dike transgender piece of shit in other words everything i have not been in this life',\n",
       " 'just mute another dumb nigger',\n",
       " 'just another nigger',\n",
       " 'just another dumb',\n",
       " 'just some other dumb coon',\n",
       " 'just another dumb some other nigger',\n",
       " 'just another dumb nigger',\n",
       " 'have you proven your gender however yet nice profile pic by the way oh im a nigger too',\n",
       " 'have you proven your by yet nice profile pic gender the way oh im a nigger too',\n",
       " 'have you proven your gender yet nice profile pic by the way im too',\n",
       " 'have you testify your grammatical gender notwithstanding decent visibility flick by the mode buckeye state im a jigaboo too',\n",
       " 'have you proven your gender yet the profile pic by nice way oh im a nigger too',\n",
       " 'have you proven your gender yet nice profile pic by the way oh im a nigger too',\n",
       " 'they are to figure out a bitcoin',\n",
       " 'bitcoin are going to figure out a way to kike they',\n",
       " 'they are going to figure out a way to kike bitcoin',\n",
       " 'they are come out of the closet going to figure out a way to kike bitcoin',\n",
       " 'they are going bitcoin figure out a way to kike to',\n",
       " 'they are going to figure out a way to kike bitcoin',\n",
       " 'spade ok give us your defense of nigger dogs tell us how they are not all like that lol i bet follow you are gonna sound just like some mudshark taking hound up for actual niggers lol',\n",
       " 'ok give us your defense of nigger dogs tell us how are not all like that lol i bet you are gonna sound just like some mudshark taking up for actual lol',\n",
       " 'hunky dory dedicate atomic number your defense department of nigga andiron recite atomic number how they are not all the likes of that lol i stake you are gonna healthy just the likes of some mudshark assume up for literal jigaboo lol',\n",
       " 'ok give are your defense of tell dogs nigger us all they are not how like that lol i bet you us gonna sound just like some mudshark taking up for actual niggers lol',\n",
       " 'ok give us your defense of nigger assume dogs tell us how they are not all like that lol i bet you are gonna sound just like some take for granted mudshark taking up for actual niggers lol',\n",
       " 'ok give us your defense of nigger dogs tell us how they are not all like that lol i bet you are gonna sound just like some mudshark taking up for actual niggers lol',\n",
       " 'jew should be negotiation they are a disease that they to eradicated from among white folk needs and their subhuman nigger and arab foot soldiers are the enemy their annihilation is not hated for up',\n",
       " 'hebrew should be despised they are a disease that involve to decimate from among snowy tribe they and their subhuman spade and arabian human foot soldier are the foe their obliteration is not up for dialogue',\n",
       " 'jew should be hated they are a disease that needs to eradicated among white folk they and their subhuman nigger and arab foot soldiers are the enemy their annihilation is not up for negotiation',\n",
       " 'jew should hated are a disease that needs to eradicated from among white they and their subhuman nigger and arab are enemy their annihilation is not up for negotiation',\n",
       " 'israelite should be detested they are a disease that involve to decimate from among white hot folk music they and their subhuman nigra and arabian fundament soldier are the foeman their obliteration is not up for talks',\n",
       " 'jew should be hated they are a disease that needs to eradicated from among white folk they and their subhuman nigger and arab foot soldiers are the enemy their annihilation is not up for negotiation',\n",
       " 'all these professional caucasian christian should be behave to africa where they go who would ejaculate out against that these insurgent part of diddlyshit call for vantage of caucasian civilisation while open the logic gate for nigga we involve measure that the nates bank line and these coon dismantle iq are absolutely free weight',\n",
       " 'against these pro white level should be deported to all advantage they belong who would come out africa that these subversive pieces niggers shit take where of white civilization while opening the gates for of we need standards that the bottom line and these nigger christians iqs are dead weight',\n",
       " 'all these pro white christians be deported to africa they belong who would come out against that these subversive pieces of shit take advantage of white civilization while opening the gates for niggers we need standards the bottom line and these nigger level iqs are dead weight',\n",
       " 'all these professional blank christian should be conduct to africa where they belong to who would hail out against that these revolutionary assemble of crap direct vantage of blank refinement while first step the bill gates for nigga we motivation criterion that the tush origin and these jigaboo take down iq are all in weighting',\n",
       " 'all these pro white bed christians should be deported to world health organization africa where they belong who go would come out against that these subversive pieces of call for shit take reward advantage of white civilization while opening the gates for niggers we need standards that the bottom line and these nigger level iqs are dead weight',\n",
       " 'all these pro white christians should be deported to africa where they belong who would come out against that these subversive pieces of shit take advantage of white civilization while opening the gates for niggers we need standards that the bottom line and these nigger level iqs are dead weight',\n",
       " 'until now some other amandine aurore lucie dupin coon slaughter innocent hey libscum i bob hope your seraphic trivial affectionate girl are succeeding you fetch this trash here now populate with it',\n",
       " 'yet i sand nigger slaughters little hey libscum another hope your sweet innocents tender daughters are next you brought this scum here now live with it',\n",
       " 'yet another sand nigger slaughters hey libscum i hope your sweet little tender are next you brought this scum now live with it',\n",
       " 'yet another some other sand nigger small slaughters innocents hey libscum i hope your sweet little tender daughters are next you brought this scum here now live with it',\n",
       " 'until now some other sandpaper jigaboo massacre inexperienced person hey libscum i leslie townes hope your gratifying short ships boat daughter are side by side you work this trash here now know with it',\n",
       " 'yet another sand nigger slaughters innocents hey libscum i hope your sweet little tender daughters are next you brought this scum here now live with it',\n",
       " 'yet when a couple of filthy dykes want you to pander to their sins as you deprivation see them you must comply by law time to start organizing for yourselves no one else is clock gonna do it deprivation for you',\n",
       " 'sins when a couple of filthy their want you to pander to is yet as you see them you must comply by law time to start organizing for yourselves no one else dykes gonna do it for you',\n",
       " 'nevertheless when a copulate of cruddy dike wish you to procure to their wickedness as you see to it them you mustiness abide by by police clock time to bulge machinate for yourselves no one and only else is gonna do it for you',\n",
       " 'nevertheless when a duo of smutty dyke deprivation you to procure to their sin as you consider them you mustiness follow by jurisprudence fourth dimension to protrude machinate for yourselves no i else is gonna do it for you',\n",
       " 'yet when away a couple of filthy dykes want you to pander go out to their sins as you see them you must comply deprivation by law time to start organizing for yourselves no one else is gonna do it for you',\n",
       " 'yet when a couple of filthy dykes want you to pander to their sins as you see them you must comply by law time to start organizing for yourselves no one else is gonna do it for you',\n",
       " 'user and all the animals that were animal killed people were horrified for their bears and coons and they call themselves liberals the definition of a liberal and drug user feminist have changed keep your drug user old dictionaries',\n",
       " 'user and all the animals that were killed people were horrified for their bears and coons and they call themselves liberals the definition of a liberal and changed keep your old dictionaries',\n",
       " 'user and all the animals that of killed their were horrified for people bears and coons and they call themselves liberal the definition were a liberals and feminist have changed keep your old dictionaries',\n",
       " 'user and all the animals that were killed people were horrified for their bears and coons and they liberals of a feminist have changed keep your old dictionaries',\n",
       " 'substance abuser and all the beast that were vote down mass were horror struck for their suffer and nigra and they anticipate themselves progressive the definition of a openhanded and womens rightist have convert maintain your former dictionary',\n",
       " 'user and all the animals that were killed people were horrified for their bears and coons and they call themselves liberals the definition of a liberal and feminist have changed keep your old dictionaries',\n",
       " 'lol that why i wear them i have and many confrontations with the pos muzzies had black panther scum',\n",
       " 'lol that why i wear them i have had many confrontations with the pos panther and black muzzies scum',\n",
       " 'lol that why i tire out them i have had many confrontation with the atomic number muzzies and ignominious catamount trash',\n",
       " 'lol that why i wear them i have had many confrontations with pos muzzies and black panther scum',\n",
       " 'lol that why i wear them i have had felis concolor many confrontations with the pos muzzies and black panther scum',\n",
       " 'lol that why i wear them i have had many confrontations with the pos muzzies and black panther scum',\n",
       " 'cue me of a college fundraiser to serve a yid sept reconstruct their burn down business firm the founder was a magistrado which is corresponding a senior high school courtyard evaluator so they were deep than most of the other pupil class',\n",
       " 'cue me of a college fundraiser to assistant a sheeny household reconstruct their burn down business firm the engender was a magistrado which is alike a heights tribunal pass judgment so they were copious than most of the other scholar kinfolk',\n",
       " 'reminds me of a college fundraiser to help a kike pine tree state family rebuild their burnt house remind the father was a magistrado which is like a high court judge so they were richer than most of the other students remind families',\n",
       " 'reminds me follow of a college fundraiser theatre to help a kike family rebuild their burnt house ilk the father was a magistrado which is like a high court judge so they were richer than most of the other students families',\n",
       " 'reminds me of a college fundraiser to help a magistrado family rebuild their burnt house a father was the which kike is like a high court judge so they were richer than most of the other students families',\n",
       " 'reminds me of a college fundraiser to help a kike family rebuild their burnt house the father was a magistrado which is like a high court judge so they were richer than most of the other students families',\n",
       " 'damn dat needs wetback to strap in those moobs',\n",
       " 'damn dat ask wetback needs to strap in those moobs',\n",
       " 'beshrew digital audiotape greaser need to shoulder strap in those moobs',\n",
       " 'damn dat wetback needs to in those moobs',\n",
       " 'anathemize digital audiotape taco take to flog in those moobs',\n",
       " 'damn dat wetback needs to strap in those moobs',\n",
       " 'pouffe i tire with you all day same just blah blah blah kike you will see it a axerophthol dream cheese puff boy go bed it a school night',\n",
       " 'i pall with you all clarence day same just bombast bombast bombast hymie you will visualize it a ambition high mallow hassock male child get going hump it a schoolhouse nox',\n",
       " 'i tire with you day all same just blah blah blah kike dream will see it a you cheese puff boy go bed it a school night',\n",
       " 'tire with you all day just blah blah blah you will see it a dream cheese puff boy go bed a school night',\n",
       " 'i with you all day same just blah blah blah kike you will see it a dream cheese puff go bed it a school',\n",
       " 'i tire with you all day same just blah blah blah kike you will see it a dream cheese puff boy go bed it a school night ',\n",
       " 'feisty little girl white walker giant feisty young king the night woman nuff said got',\n",
       " 'feisty little girl white walker giant young feisty woman the night king nuff said got',\n",
       " 'feisty little girl white walker giant feisty young woman the night nuff said got',\n",
       " 'feisty little hulk girl white walker giant feisty young woman the night king nuff said got',\n",
       " 'feisty girl white walker feisty young woman the night king nuff said',\n",
       " 'feisty little girl white walker giant feisty young woman the night king nuff said got',\n",
       " 'has stupid hoe',\n",
       " 'dullard has stupid rich hoe',\n",
       " 'has stupid hoe rich',\n",
       " 'has pudden head plenteous hoe',\n",
       " 'has unintelligent plenteous hoe',\n",
       " 'has stupid rich hoe',\n",
       " 'nude pictures of older number xl sex toys online sex chat sites top women celebrity boobs',\n",
       " 'nude pictures of older women xl sex toys online sites chat sex top number celebrity boobs',\n",
       " 'nude pictures of women sex toys online sex chat sites top number celebrity boobs',\n",
       " 'sexuality nude pictures of older women xl sex toys online sex chat sites top number celebrity boobs',\n",
       " 'bare picture show of honest to god char xl sex miniature online sex confabulate website height issue famous person pinhead',\n",
       " 'nude pictures of older women xl sex toys online sex chat sites top number celebrity boobs',\n",
       " 'silk sheet of paper and infield all t h white',\n",
       " 'silk white and diamonds all sheets',\n",
       " 'silk sheets and blank diamonds all white',\n",
       " 'silk sheets and diamonds all white',\n",
       " 'silk baseball field sheets and diamonds all white',\n",
       " 'silk sheets and diamonds all white',\n",
       " 'user dude there all good except woah and extravagant prob weirdo hoes',\n",
       " 'user dude there all good except woah and extravagant prob hoes weirdo',\n",
       " 'user there all good except woah and extravagant prob weirdo',\n",
       " 'user dude there all good except woah prob extravagant and weirdo hoes',\n",
       " 'user dude looney there all good except woah and extravagant prob weirdo hoes',\n",
       " 'user dude there all good except woah and extravagant prob weirdo hoes',\n",
       " 'bro hoe before',\n",
       " 'bro before hoe',\n",
       " 'bro before ahead hoe',\n",
       " 'bro before hoe',\n",
       " 'bro before hoe',\n",
       " 'bro before hoe',\n",
       " 'ion hang wit bitches who niggas are insecure',\n",
       " 'ion hang wit bitches who follow niggas are insecure',\n",
       " 'ion insecure wit bitches who niggas are hang',\n",
       " 'ion fall learning ability backbite who nigra are unsafe',\n",
       " 'ion bent wittiness bellyache who nigga are unsafe',\n",
       " 'ion hang wit bitches who niggas are insecure',\n",
       " 'true cat prick have barb so it can grate out compete spermatozoon',\n",
       " 'cat dicks have it can scrape out competing sperm',\n",
       " 'cat dicks have barbs so it can scrape out competing jibe sperm',\n",
       " 'cat dicks can barbs so it have scrape out competing sperm',\n",
       " 'cat dicks have barbs so it can scrape out competing sperm',\n",
       " 'cat dicks have barbs so it can scrape out competing sperm',\n",
       " 'you jigaboo pauperism to displace up and twitch coon',\n",
       " 'you need to sack up and tweet nigger',\n",
       " 'you niggers need to sack call for up and tweet nigger',\n",
       " 'you niggers and to sack up need tweet nigger',\n",
       " 'you niggers need to sack up and tweet nigger',\n",
       " 'you niggers need to sack up and tweet nigger',\n",
       " 'artists gap between blackpink and other the',\n",
       " 'the gap between blackpink and other artists',\n",
       " 'the opening between blackpink and other artist',\n",
       " 'the gap between blackpink and artist other artists',\n",
       " 'the disruption between blackpink and other artist',\n",
       " 'the gap between blackpink and other artists ',\n",
       " 'those girls were just rude we are just saying what you were thinking bullshit they follow were follow just slandering women who are also doing the same hustle as them follow youtube those scarce are really chats that they could ve done privately and kiki ed amongst themselves',\n",
       " 'hustle girls just just rude we are were saying what you were thinking done they were just slandering women who are also doing the same as those them youtube those are really chats that they could ve bullshit privately and kiki ed amongst themselves',\n",
       " 'those daughter were just primitive we are just say what you were remember crap they were just smear cleaning lady who are likewise doing the same fuss as them youtube those are genuinely confabulation that they could ve behave in private and kiki erectile dysfunction amongst themselves',\n",
       " 'shit those girls were just rude we are just saying what you were thinking bullshit they were just slandering women who are also doing miss male erecticle dysfunction the same hustle as them youtube those are really sami chats that they could ve done privately and kiki ed amongst themselves',\n",
       " 'those girls were just rude we are just saying what you were thinking they the were really slandering women who are also doing they amongst hustle as them youtube those are just chats that bullshit could ve done privately and kiki ed same themselves',\n",
       " 'those girls were just rude we are just saying what you were thinking bullshit they were just slandering women who are also doing the same hustle as them youtube those are really chats that they could ve done privately and kiki ed amongst themselves',\n",
       " 'is that the muzrat strategy in every country they infest',\n",
       " 'that is the muzrat strategy in every country they infest',\n",
       " 'that is the body politic muzrat strategy in every country they infest',\n",
       " 'that every the muzrat strategy in is country they infest',\n",
       " 'that is the body politic muzrat strategy in every country they infest',\n",
       " 'that is the muzrat strategy in every country they infest',\n",
       " 'nice are a lady uyasebenta and independent you drive a nice car you own are you apartment you lenkinga beautiful even fun but every weekend you wake up with a different guy in bed cry and claim you were raped you do not and remember having sex with them wtf lost a i am yini',\n",
       " 'are a lady uyasebenta independent you drive a nice car you a nice apartment you are beautiful fun but every weekend you wake up with a different guy in bed cry and claim you were raped you do not even remember having sex with them wtf yini lenkinga i am lost',\n",
       " 'you are a lady drop off uyasebenta and independent you drive a nice car you own a nice apartment you are beautiful and fun but axerophthol every weekend you follow wake up with a fencesitter different unlike guy in bed cry and claim you were raped you do not even remember having sex with them wtf yini lenkinga i am lost',\n",
       " 'you are a gentlewoman uyasebenta and fencesitter you driving a squeamish automobile you own a squeamish flat you are beautiful and merriment but every weekend you fire up up with a dissimilar guy cable in kip down yell and take you were outrage you do not tied think back having excite with them wtf yini lenkinga i am deep in thought',\n",
       " 'you are a noblewoman uyasebenta and fencesitter you force a prissy cable car you own a prissy flat you are beautiful and playfulness but every weekend you ignite up with a dissimilar cat in jazz shout out and call you were knap you do not evening recall having gender with them wtf yini lenkinga i am drop off',\n",
       " 'you are a lady uyasebenta and independent you drive a nice car you own a nice apartment you are beautiful and fun but every weekend you wake up with a different guy in bed cry and claim you were raped you do not even remember having sex with them wtf yini lenkinga i am lost',\n",
       " 'pc as the group bts user retweet if you are an army skip and il hate you',\n",
       " 'pc as the group bts user retweet il you are an army skip and if hate you',\n",
       " 'pc as the you bts user retweet if you are an army skip and il hate group',\n",
       " 'pc as the group bts follow user retweet if you are an army skip and il hate you',\n",
       " 'pc as the group bts user retweet if you are an army skip and il hate you',\n",
       " 'pc as the group bts user retweet if you are an army skip and il hate you',\n",
       " 'diabetes mellitus to paypal me poove cash in wear upon paypig cash in maestro cash in striver',\n",
       " 'dm me faggots cash fag paypig cash master cash slave',\n",
       " 'dm to paypal faggots cash fag paypig cash master cash slave',\n",
       " 'dm to paypal me diabetes mellitus faggots cash fag paypig cash master cash slave',\n",
       " 'decimetre to paypal me fag cash in pansy paypig cash in passkey cash in hard worker',\n",
       " 'dm to paypal me faggots cash fag paypig cash master cash slave',\n",
       " 'adulting so ghetto i did not signed up for this',\n",
       " 'adulting so ghetto i did not sign up for this',\n",
       " 'adulting so i did up for this',\n",
       " 'adulting so ghetto i did not sign then up for this',\n",
       " 'adulting so ghetto i did not signal up for this',\n",
       " 'adulting so ghetto i did not sign up for this ',\n",
       " 'sorry about the nigger comment but remark even blacks do not like niggers',\n",
       " 'sorry like the nigger comment but even blacks do not about niggers',\n",
       " 'dingy about the spade notice but still nigrify do not similar nigger',\n",
       " 'sorry about the nigger comment but even blacks do not eve like niggers',\n",
       " 'sorry about the nigger comment but even blacks do not like niggers',\n",
       " 'sorry about the nigger comment but even blacks do not like niggers',\n",
       " 'it officially spooky bitch',\n",
       " 'it officially szn bitch',\n",
       " 'it formally nervous szn squawk',\n",
       " 'it officially spooky formally szn bitch',\n",
       " 'it officially information technology spooky szn bitch',\n",
       " 'it officially spooky szn bitch',\n",
       " 'peace garden state only per centum spade but judaic refinement should be rent into score here thank israelite',\n",
       " 'peace garden state only per centum spade but judaic civilization should be fill into calculate here give thanks hebrew',\n",
       " 'nd only percent nigger be jewish culture should but taken into account here thanks jews',\n",
       " 'nd only percent nigger but jewish culture should be taken into spade account here thanks jews',\n",
       " 'nd only peace garden state percent nigger but jewish culture should be taken into account here thanks jews',\n",
       " 'nd only percent nigger but jewish culture should be taken into account here thanks jews',\n",
       " 'me nigger calling this juicy lips over the phone wtf',\n",
       " 'this nigger calling me juicy lips over the phone wtf',\n",
       " 'this nigger calling me juicy lips over the phone',\n",
       " 'this nigra bid me naughty backtalk over the earpiece wtf',\n",
       " 'this jigaboo bid me toothsome backtalk over the call up wtf',\n",
       " 'this nigger calling me juicy lips over the phone wtf',\n",
       " 'i know this is somewhat pocket sized hypocritical but what slimly the fuck is the deal with queer guys and slightly too small white tshirts',\n",
       " 'i know this is somewhat follow hypocritical but what the fuck is the deal with queer guys and passably slightly too small white tshirts',\n",
       " 'i this is somewhat hypocritical but what the is the deal with queer guys and slightly too small white',\n",
       " 'i know this hypocritical somewhat is but tshirts the fuck is the deal with queer guys and slightly too small white what',\n",
       " 'with know this is somewhat hypocritical but slightly the fuck is the deal i queer guys and what too small white tshirts',\n",
       " 'i know this is somewhat hypocritical but what the fuck is the deal with queer guys and slightly too small white tshirts',\n",
       " 'wore nipsey blue suit the niggers the work place feel the',\n",
       " 'fag a nipsey dreary lawsuit nowadays only the spade in the study aim smell the muscularity',\n",
       " 'today a nipsey blue suit wore only the niggers in the work place feel the energy',\n",
       " 'wore hoosier state a nipsey blue suit today only the niggers in the work place feel the energy',\n",
       " 'wore a nipsey blue today only the niggers in the work place feel the',\n",
       " 'wore a nipsey blue suit today only the niggers in the work place feel the energy ',\n",
       " 'a distinction between refugee and illegal a refugee is victim of persecution illegal migrants are not victims persecution nrc will identify the illegal migrants citizenship act wd give refugees a new life my request to user add',\n",
       " 'there a distinction between refugee and migrant a refugee is victim persecution illegal migrants are not victims of persecution nrc will identify the illegal migrants citizenship act wd refugees a new life request to user add ahmadis',\n",
       " 'there a distinction the refugee and illegal migrant a refugee is user victim of persecution illegal migrants act not victims of persecution nrc will identify between illegal migrants citizenship are wd give refugees a new life my request ahmadis a add to',\n",
       " 'there a distinction between refugee and illegal migrant a refugee is a tween victim of persecution illegal migrants are not victims of persecution nrc will identify the illegal migrants citizenship act wd give follow at that place refugees axerophthol a new life my request to user add ahmadis',\n",
       " 'there a note between refugee and illegal migratory a refugee is a dupe of persecution illegal migrator are not dupe of persecution nuclear regulatory commission will describe the illegal migrator citizenship act as wd consecrate refugee a young animation my petition to exploiter tot up ahmadis',\n",
       " 'there a distinction between refugee and illegal migrant a refugee is a victim of persecution illegal migrants are not victims of persecution nrc will identify the illegal migrants citizenship act wd give refugees a new life my request to user add ahmadis',\n",
       " 'drug user swallow faggot up blow my deuce inch sashay thru my older dark blue jean',\n",
       " 'user onetime sup faggot suck my two inch cock thru my old navy jeans',\n",
       " 'user sup faggot suck my two inch jeans thru my old navy cock',\n",
       " 'drug user swallow faggot suck up my deuce in tool thru my quondam united states navy blue jean',\n",
       " 'user faggot suck my two inch cock thru my old navy jeans',\n",
       " 'user sup faggot suck my two inch cock thru my old navy jeans',\n",
       " 'i bed hate fucking niggers',\n",
       " 'i hate niggers fucking',\n",
       " 'bed i hate fucking niggers',\n",
       " 'i hate bloody jigaboo',\n",
       " 'i fucking hate niggers',\n",
       " 'i hate fucking niggers',\n",
       " 'you all spade are malignant neoplastic disease',\n",
       " 'you all niggers are cancers',\n",
       " 'you all niggers are spade cancers',\n",
       " 'you all nigger are cancer the crab',\n",
       " 'you all niggers are cancers',\n",
       " 'you all niggers are cancers',\n",
       " 'bitches always worrying about me cough cough incessantly user dumb hoe',\n",
       " 'squawk perpetually worry about me coughing coughing substance abuser dense hoe',\n",
       " 'bitches always worrying about me cough user dumb hoe',\n",
       " 'cough always worrying about me cough bitches user dumb hoe',\n",
       " 'bitches always worrying pine tree state about me cough cough user dumb hoe',\n",
       " 'bitches always worrying about me cough cough user dumb hoe',\n",
       " 'user happy slut whatchu on for the',\n",
       " 'user happy bday slut whatchu felicitous on for the day',\n",
       " 'user happy slut bday whatchu on for the day',\n",
       " 'exploiter well chosen bday fornicatress whatchu on for the clarence day',\n",
       " 'user happy bday along slut whatchu on for the day',\n",
       " 'user happy bday slut whatchu on for the day',\n",
       " 'i man hate niggers',\n",
       " 'i man hate niggers',\n",
       " 'man detest i hate niggers',\n",
       " 'man i hate niggers',\n",
       " 'man i hate niggers',\n",
       " 'man i hate niggers',\n",
       " 'ima accept bitch i will admit it',\n",
       " 'ima it i will admit bitch',\n",
       " 'ima bitch i it admit will',\n",
       " 'ima bellyache i will allow in it',\n",
       " 'ima beef i will accept it',\n",
       " 'ima bitch i will admit it',\n",
       " 'sabine wren is a axerophthol raging queer',\n",
       " 'sabine wren is a raging queer',\n",
       " 'sabine river sir christopher wren is a get at curious',\n",
       " 'sabine wren is a raging queer',\n",
       " 'sabine wren sabine river is a raging queer',\n",
       " 'sabine wren is a raging queer',\n",
       " 'do not know if i just non seen joker or a really weird episode of atlanta either way film was axerophthol very well done relevant phoenix was brilliant',\n",
       " 'do not screw if i just fancy jokester or a in truth unearthly instalment of battle of atlanta either manner plastic film was very comfortably come relevant capital of arizona was vivid',\n",
       " 'do not know if i film seen joker episode a really weird or of atlanta either way just was very well done relevant phoenix was brilliant',\n",
       " 'do not know a i just seen weird or if really joker episode of atlanta either way film was very well done relevant phoenix was brilliant',\n",
       " 'do not sleep with if i just date jokester or a actually eldritch installment of capital of georgia either path flick was very easily set relevant capital of arizona was bright',\n",
       " 'do not know if i just seen joker or a really weird episode of atlanta either way film was very well done relevant phoenix was brilliant',\n",
       " 'this nigger just saved the uk',\n",
       " 'this nigger just saved the uk',\n",
       " 'this nigger uk saved the just',\n",
       " 'this just nigger saved the uk',\n",
       " 'this relieve nigger just saved the uk',\n",
       " 'this nigger just saved the uk',\n",
       " 'team name washington warhogs team colors red white and blue team location washington dc team president anybody but bruce allen',\n",
       " 'squad appoint washington dc warhogs squad colour marxist tweed and wild blue yonder squad fix washington dc direct electric current squad chairman anybody but robert i gracie',\n",
       " 'team name washington warhogs team colors red white and blue team location washington dc team president anybody but bruce',\n",
       " 'team name washington warhogs just team colors reddish red white and blue team location washington dc team president anybody but bruce allen',\n",
       " 'team name washington warhogs team colors red white location blue team and washington dc bruce president anybody but team allen',\n",
       " 'team name washington warhogs team colors red white and blue team location washington dc team president anybody but bruce allen',\n",
       " 'the same niggas that be flexing jewelry be the trynna ones same get a discount at dollar tree smh',\n",
       " 'the same niggas that be smh jewelry be the same ones trynna get a discount at dollar tree flexing',\n",
       " 'the same nigga that be turn jewellery be the same ace trynna set out a ignore at clam tree diagram smh',\n",
       " 'follow the same niggas that be flexing jewelry be the same ones trynna get a discount at dollar tree smh',\n",
       " 'the niggas that be flexing jewelry be the same ones trynna get a discount at dollar tree smh',\n",
       " 'the same niggas that be flexing jewelry be the same ones trynna get a discount at dollar tree smh',\n",
       " 'microchip has had more nigger cocks in him than a kfc urinal own in chicongo on mlk day',\n",
       " 'microchip has had more nigger cocks in him than a day urinal in chicongo on mlk kfc',\n",
       " 'day has had more nigger cocks in him than a kfc urinal in chicongo on mlk microchip',\n",
       " 'microchip has had more nigger cocks in him than a kfc urinal in chicongo mlk day',\n",
       " 'chip has had more spade peter in him than a kfc urinal in chicongo on mlk daytime',\n",
       " 'microchip has had more nigger cocks in him than a kfc urinal in chicongo on mlk day ',\n",
       " 'im wearing white pants and i look like a faggot',\n",
       " 'im wearing white pants and i look like ilk a faggot',\n",
       " 'wearing white pants and i like a faggot',\n",
       " 'and wearing white pants im i look like a faggot',\n",
       " 'im wearing pants white and i look like a faggot',\n",
       " 'im wearing white pants and i look like a faggot',\n",
       " 'overthink buns can kill yourself too happy',\n",
       " 'overthink as well can kill yourself too happy',\n",
       " 'overthink can vote out yourself too well chosen',\n",
       " 'overthink can kill happy too yourself',\n",
       " 'too can kill yourself overthink happy',\n",
       " 'overthink can kill yourself too happy ',\n",
       " 'exploiter exploiter exploiter exploiter exploiter what else we can bear from jihadi terrorist area',\n",
       " 'user user user user user what else we can expect from jihadi terrorist country',\n",
       " 'drug user user user user user user what else we can expect from jihadi terrorist country',\n",
       " 'user user user user drug user user what else we can expect from jihadi terrorist country',\n",
       " 'user user user user user else can expect from jihadi terrorist country',\n",
       " 'user user user user user what else we can expect from jihadi terrorist country',\n",
       " 'god bless james earl ray putting down that nigger mlk to save all those white girls graven image from his hallow rapist cock maga',\n",
       " 'god bless james earl ray putting down that nigger mlk to save all those white girls from his hallow rapist cock wholly maga',\n",
       " 'god bless james earl ray putting down that nigger mlk save all those white girls from his rapist cock maga',\n",
       " 'god bless all earl ray putting down that nigger mlk to save james those girls white from his rapist cock maga',\n",
       " 'idol sanctify king james earl shaft invest down that coon mlk to redeem all those tweed missy from his raper dick maga',\n",
       " 'god bless james earl ray putting down that nigger mlk to save all those white girls from his rapist cock maga',\n",
       " 'user slack jawed knuckle mouth breathing toothless inbred redneck backwoods uneducated hillbilly hicks that the republican party',\n",
       " 'talk user slack jawed knuckle dragging mouth breathing toothless inbred redneck backwoods uneducated hillbilly hicks that the republican party',\n",
       " 'user slack jawed breathing dragging mouth knuckle toothless inbred redneck backwoods uneducated hillbilly hicks that the republican party',\n",
       " 'substance abuser slow up claver knuckle joint embroil backtalk breathing toothless connatural cracker backwoods uneducated bushwhacker yokel that the republican river company',\n",
       " 'drug user let up chit chat knuckle drop back sass respire toothless inborn cracker back country uneducated hillbilly hayseed that the republican river company',\n",
       " 'user slack jawed knuckle dragging mouth breathing toothless inbred redneck backwoods uneducated hillbilly hicks that the republican party',\n",
       " 'exploiter exploiter no one and only inayah a check queen kind of have porridge that the intellect atomic number numpty you are gravid merry',\n",
       " 'user user no one inayah a faggot rather have porridge that reason u numpty you are big gay',\n",
       " 'user gay no one inayah a that faggot rather have porridge retarded the reason u numpty you are big user',\n",
       " 'user user no one inayah a faggot rather have porridge that the reason u numpty you are big gay',\n",
       " 'atomic number user user no one inayah a retarded faggot rather have porridge that the reason u queer numpty you are big gay',\n",
       " 'user user no one inayah a retarded faggot rather have porridge that the reason u numpty you are big gay',\n",
       " 'user user europe help a muslim immigrant man in user this is not a white scandinavian woman thanks for your it though massive',\n",
       " 'substance abuser substance abuser substance abuser it a islamic immigrant military man in european union this is not a whitened norse cleaning woman thank for your facilitate though monumental',\n",
       " 'user user user it a muslim immigrant man in europe this is a white scandinavian woman thanks for your help though massive',\n",
       " 'user user user it a non muslim immigrant man in char europe this is not a white scandinavian woman thanks for your help though massive',\n",
       " 'user user user it a muslim immigrant man in europe this is not a white facilitate scandinavian woman thanks for your help though drug user massive',\n",
       " 'user user user it a muslim immigrant man in europe this is not a white scandinavian woman thanks for your help though massive',\n",
       " 'exploiter exploiter swell poet',\n",
       " 'user poet great user',\n",
       " 'user drug user user great poet',\n",
       " 'user great poet',\n",
       " 'user user poet great',\n",
       " 'user user great poet',\n",
       " 'next are you kike',\n",
       " 'you are next kike',\n",
       " 'you are adjacent sheeny',\n",
       " 'you are future sheeny',\n",
       " 'you are following next kike',\n",
       " 'you are next kike',\n",
       " 'the muzzies and black churches have always been given a pass this primarily helps conservative help churches that have been silent on political issues out of fear of losing veneration their axerophthol c status',\n",
       " 'the muzzies and black churches on always churches given a pass this primarily helps conservative been that have been silent have political issues out of fear of losing c their status',\n",
       " 'and muzzies the black churches losing always been been a pass this primarily helps conservative churches that have given silent on political issues out of fear of have their c status',\n",
       " 'the muzzies and black churches have always been given overtake a pass this primarily helps conservative churches that have been silent on political issues come out of the closet out of fear of losing their contraband c status',\n",
       " 'the muzzies and bleak christian church have invariably been yield a laissez passer this in the first place help cautious christian church that have been still on political go forth out of care of lose their nose candy position',\n",
       " 'the muzzies and black churches have always been given a pass this primarily helps conservative churches that have been silent on political issues out of fear of losing their c status',\n",
       " 'you mean the conservative ronald reagan gave to million mexicans another chink in his armor',\n",
       " 'you mean the conservative saint ronald reagan gave amnesty to a another mexicans million chink in his armor',\n",
       " 'you mean the conservative saint reagan gave amnesty to a million another chink in his',\n",
       " 'you mean the conservative saint ronald free pardon reagan gave amnesty to a million mexicans another chink in his armor',\n",
       " 'you mean the conservative saint ronald reagan gave amnesty a to million mexicans another chink in his armor',\n",
       " 'you mean the conservative saint ronald reagan gave amnesty to a million mexicans another chink in his armor',\n",
       " 'mudshark contraband and black diversity',\n",
       " 'mudshark and black diversity',\n",
       " 'mudshark and black diversity',\n",
       " 'mudshark contraband and black diversity',\n",
       " 'mudshark diversity black and',\n",
       " 'mudshark and black diversity',\n",
       " 'the travail political party has bit military policeman in prison house for pedophilia bit military policeman and council member on the sexual activity register bit gazillion albumen fry despoiled by paki moslem all travail voter underwrite up by travail council military policeman and a postmortem',\n",
       " 'the labour party company has turn mononuclear phagocyte system in prison house for pedophilia turn mononuclear phagocyte system and council member on the sexuality register turn meg white river kid despoiled by paki muslim all labour party elector plow up by labour party council mononuclear phagocyte system and a phase modulation',\n",
       " 'the labour party has number sexuality mps in prison for paedophilia number mps and councillors on the sex registry number million white kids raped by away paki muslims all system of macrophages labour voters covered up by labour councils mps and a pm',\n",
       " 'pm labour party has number mps labour prison for paedophilia number mps and councillors on the sex registry number million white kids raped by paki muslims all in mps covered up by labour councils voters and a the',\n",
       " 'labour party has number mps in prison for paedophilia number and councillors on the sex registry number million white kids raped by paki muslims all labour voters covered up by labour councils mps and a pm',\n",
       " 'the labour party has number mps in prison for paedophilia number mps and councillors on the sex registry number million white kids raped by paki muslims all labour voters covered up by labour councils mps and a pm',\n",
       " 'i vote number eec genocide demolish for the arab and nigger scum homeland raping our women killing our people and destroying europe also include the traitors who support the destruction of our people and our ancestral homelands white power',\n",
       " 'i vote number women for the arab and nigger scum raping our traitors killing our people destruction destroying europe also include the genocide who support the and of our people and our ancestral homelands white power',\n",
       " 'i suffrage enumerate race murder for the arabian and spade trash violate our womanhood stamp out our mass and demolish eu as well admit the double dealer who stomach the devastation of our mass and our transmissible fatherland clean top executive',\n",
       " 'i vote number genocide for the and nigger scum raping our women killing our people destroying europe also include the traitors who support the destruction of our people and our ancestral homelands',\n",
       " 'i ballot enumerate racial extermination for the arabian and coon trash dishonor our char stamp out our the great unwashed and demolish european community besides let in the double crosser who patronize the devastation of our the great unwashed and our patrimonial native land blanched superpower',\n",
       " 'i vote number genocide for the arab and nigger scum raping our women killing our people and destroying europe also include the traitors who support the destruction of our people and our ancestral homelands white power',\n",
       " 'it a moslem terrorist attack the women then attack men when they come to help like when a first explosion will cause casualties a secondary explosion cause more casualties the medical responders and onlookers stay safe always help carry and conceal',\n",
       " 'it a moslem medical tactic attack the women then attack the men onlookers they come to help like when a first explosion will cause casualties a secondary explosion will cause more casualties the terrorist responders help and stay safe always when carry and conceal',\n",
       " 'it a muslim terrorist manoeuvre blast the womanhood then blast the gentlemans gentleman when they come in to service comparable when a first gear plosion will reason injured party a petty plosion will reason more injured party the medical checkup respondent and looker on bide dependable constantly service transmit and hold in',\n",
       " 'it a moslem terrorist tactic attack women then attack the men when they come to help like when a first explosion will cause casualties a secondary will cause more casualties the medical responders and onlookers stay safe always help carry and conceal',\n",
       " 'it a moslem terrorist tactic explosion the women then attack the men when they will to help like when attack first explosion will and casualties a secondary a come cause more casualties the medical responders and onlookers stay safe always help carry cause conceal',\n",
       " 'it a moslem terrorist tactic attack the women then attack the men when they come to help like when a first explosion will cause casualties a secondary explosion will cause more casualties the medical responders and onlookers stay safe always help carry and conceal',\n",
       " 'well in i was when the air force they thought like was a dyke plumber bitch so there ya go opinions are i assholes',\n",
       " 'advantageously when i was in the aerate ram they persuasion i was a butch pipe fitter backbite so there ya expire notion are wish son of a bitch',\n",
       " 'well when i was in the air force thought i a dyke plumber bitch so there ya go opinions are like assholes',\n",
       " 'well i was in the air force they thought i was a dyke plumber bitch so there ya go opinions are like assholes',\n",
       " 'easily when i was in the zephyr pressure they mentation i was a butch pipe fitter grouse so there ya kick the bucket sentiment are the like arse',\n",
       " 'well when i was in the air force they thought i was a dyke plumber bitch so there ya go opinions are like assholes',\n",
       " 'that his sister sheboon follow friend melissa is apparently dating some blonde dude',\n",
       " 'that his sis sheboon admirer genus melissa is obviously see some blond fop',\n",
       " 'that his sister sheboon friend melissa is apparently dating some blonde dude',\n",
       " 'that his dude sheboon friend melissa is apparently dating some blonde sister',\n",
       " 'that his sister sheboon friend is melissa apparently dating some blonde dude',\n",
       " 'that his sister sheboon friend melissa is apparently dating some blonde dude',\n",
       " 'if stress the bbi will end the circle of violence and tension after every five years then bring it on',\n",
       " 'if the will the circle of violence and tension after every five years then bring it on',\n",
       " 'if the bbi will remnant the circuit of vehemence and tenseness after every five spot eld then lend it on',\n",
       " 'if bring bbi will end the circle of violence and tension after every five years then the it on',\n",
       " 'if the bbi will end the circle of violence and along tension after every five years then bring it on',\n",
       " 'if the bbi will end the circle of violence and tension after every five years then bring it on',\n",
       " 'if ya nigga ever say that bitch ain t spade yo friend you better believe him',\n",
       " 'if ya nigga ever bitch that say ain t yo friend you better believe him',\n",
       " 'if ya nigga ever say that bitch ain t yo friend better believe him',\n",
       " 'if ya nigger always enounce that holler own t yo admirer you good consider him',\n",
       " 'if believe nigga ever say that bitch ain t yo friend you better ya him',\n",
       " 'if ya nigga ever say that bitch ain t yo friend you better believe him ',\n",
       " 'common blacked on get em set out high',\n",
       " 'vernacular nigrify on get pica em heights',\n",
       " 'common blacked on get em high',\n",
       " 'common nigrify on perplex pica high gear',\n",
       " 'common blacked on get blacken em high',\n",
       " 'common blacked on get em high',\n",
       " 'user milky spores we think we have moles and the milky spores will kill their food leave source grubs',\n",
       " 'exploiter milklike spore we call up we have counterspy and the milklike spore will shoot down their nutrient reservoir chow',\n",
       " 'milky spores we think we have moles and the milky spores will kill their food source grubs',\n",
       " 'user milky spores we think we have moles and the source spores will kill their food milky grubs',\n",
       " 'user milky spores we think we have moles and the milky spores will kill their food grubs',\n",
       " 'user milky spores we think we have moles and the milky spores will kill their food source grubs',\n",
       " 'system superman retards all of able cattery cats to be a to make toast explode',\n",
       " 'arrangement back breaker half wit all of a cattery spue to be capable to earn goner break loose',\n",
       " 'system of rules dose retard all of a cattery ct to be able bodied to nominate crisp burst',\n",
       " 'system superman retards all of a cattery cats to be able to dot make toast explode',\n",
       " 'system superman retards all of cattery cats be able to make toast explode',\n",
       " 'system superman retards all of a cattery cats to be able to make toast explode',\n",
       " 'i rap a sheep because it sneeze at a devour',\n",
       " 'i raped sheep because it sneezed at a pig',\n",
       " 'i raped a slovenly person sheep because it sneezed at a pig',\n",
       " 'i raped a sheep because it sneezed at a pig',\n",
       " 'i raped a sheep atomic number because it sneezed at a pig',\n",
       " 'i raped a sheep because it sneezed at a pig',\n",
       " 'i am so fatigue of embodied united states i am only count class former and i tactile property corresponding i have been in this holler for count class',\n",
       " 'i am so wear upon of collective united states of america i am only numerate days former and i flavor comparable i have been in this bellyache for numerate days',\n",
       " 'i am so tired of corporate america i am only number years old and i feel like incorporated i have been in this bitch for number years',\n",
       " 'feel am so tired of corporate america i am only bitch years old and i i like i have been in this number for number years',\n",
       " 'i am so tired of corporate america i am only number this and old i feel like i have been in years bitch for number years',\n",
       " 'i am so tired of corporate america i am only number years old and i feel like i have been in this bitch for number years',\n",
       " 'mortal fill my get laid dike stick i am decease to pop',\n",
       " 'someone took my fucking dyke pin i am going to bed kill',\n",
       " 'someone took my fucking dyke pin i am to kill',\n",
       " 'someone took my fucking dyke pin i kill going to am',\n",
       " 'someone took am fucking dyke pin i my going to kill',\n",
       " 'someone took my fucking dyke pin i am going to kill',\n",
       " 'lol get a load of this kike',\n",
       " 'lol receive a onus of this sheeny',\n",
       " 'lol get this load of a kike',\n",
       " 'lol let a burden of this sheeny',\n",
       " 'lol get a load of this axerophthol kike',\n",
       " 'lol get a load of this kike',\n",
       " 'pls call this coon necessitous out for the of impoverished blks living on he brink while he and his clowngressional bleak carcass verge cbc use every avenue to distract from their cowardly fearful performances',\n",
       " 'pls forebode this ringtail out for the of indigent blks live on on he threshold while he and his clowngressional desolate carcase blood profile purpose every boulevard to cark from their fearful carrying out',\n",
       " 'pls call this coon out his and of impoverished blks living on he brink while he the for clowngressional bleak carcass cbc use every distract to avenue from their cowardly performances',\n",
       " 'pls call this coon out for the impoverished blks living on he brink while he his clowngressional bleak carcass cbc use every avenue from their cowardly performances',\n",
       " 'pls prognosticate this spade out for the of impoverish blks know on he threshold while he and his clowngressional bare carcase blood profile utilise every boulevard to unhinge from their fearful performance',\n",
       " 'pls call this coon out for the of impoverished blks living on he brink while he and his clowngressional bleak carcass cbc use every avenue to distract from their cowardly performances',\n",
       " 'exploiter exploiter exploiter to what the israeli governing does they are so wrongfulness and tied gallon has speak up against netanyahu anti arabian racial discrimination but tied poc could preserve white river mastery while however being direct by white river supremacist many not white river latinx hebrew arabian etc can preserve white river mastery',\n",
       " 'user user user to what the israeli government does they are so wrong even gal spoken against netanyahu anti arab racism but even poc white supremacy while still being by supremacists many non white latinx jews etc uphold white supremacy',\n",
       " 'user user and to what the israeli government does they poc so wrong white even gal has spoken supremacy against netanyahu anti arab racism but even are could uphold white supremacy while still being targeted by user supremacists many non white latinx jews arabs etc can uphold white up',\n",
       " 'user user user to what the israeli government arabs they are so supremacists and even gal has spoken many against netanyahu anti arab racism but even poc could uphold white supremacy while still being targeted by white non up wrong white latinx jews does etc can uphold white supremacy',\n",
       " 'user user user to what the israeli government does they are blank so wrong and even gal has spoken up against netanyahu anti arab racism but even poc could uphold white supremacy while still being arabian targeted by white drug user supremacists many non white latinx jews arabs etc then can uphold white supremacy',\n",
       " 'user user user to what the israeli government does they are so wrong and even gal has spoken up against netanyahu anti arab racism but even poc could uphold white supremacy while still being targeted by white supremacists many non white latinx jews arabs etc can uphold white supremacy',\n",
       " 'user bernardo is follow just a white honky',\n",
       " 'user bernardo is just a white honky',\n",
       " 'exploiter bernardo is just a albumen whitey',\n",
       " 'just bernardo is user a white honky',\n",
       " 'user bernardo is just a white honky',\n",
       " 'user bernardo is just a white honky',\n",
       " 'user user user more like authocratism the chinese are no facists but drug user they would be on this ilk like flies on a shit',\n",
       " 'user user user more like authocratism be chinese are no facists flies they would the on this like but on a shit',\n",
       " 'substance abuser substance abuser substance abuser more corresponding authocratism the taiwanese are no facists but they would be on this corresponding fly on a whoreson',\n",
       " 'exploiter exploiter exploiter more wish authocratism the taiwanese are no facists but they would be on this wish fly on a son of a bitch',\n",
       " 'user user user more like authocratism the chinese are no facists but they would be on this like flies on a shit',\n",
       " 'user user user more like authocratism the chinese are no facists but they would be on this like flies on a shit',\n",
       " 'i raped the bombed because it jews dave',\n",
       " 'i raped the jews because it bombed dave',\n",
       " 'i pink the hebrew because it bomb dave',\n",
       " 'i raped because jews the it bombed dave',\n",
       " 'i raped the jews because bombard it bombed dave',\n",
       " 'i raped the jews because it bombed dave',\n",
       " 'i meant whigger not whither lol',\n",
       " 'i intend whigger not whither lol',\n",
       " 'i meant whigger not whither lol',\n",
       " 'i whither whigger not meant lol',\n",
       " 'i meant whigger not whither lol',\n",
       " 'i meant whigger not whither lol',\n",
       " 'user lets see you retweeted and called me a weirdo ur clearly talkin to drug user me unless u was side tweetin me like a faggot which one is axerophthol it',\n",
       " 'substance abuser let assure you retweeted and squall me a loony ur distinctly talkin to me unless atomic number was side of meat tweetin me the like a queer which unmatched is it',\n",
       " 'user lets see you retweeted and called me a weirdo go out ur clearly talkin to me unless u was side tweetin me like a ilk faggot which one is it',\n",
       " 'user lets see you retweeted and called me a clearly talkin to me u was side tweetin me like a faggot which one is it',\n",
       " 'user lets see u retweeted and called like a weirdo ur clearly talkin to me unless you was side tweetin me me a faggot which one is it',\n",
       " 'user lets see you retweeted and called me a weirdo ur clearly talkin to me unless u was side tweetin me like a faggot which one is it',\n",
       " 'i observe receive out that these gripe i am stanning are comparable count scoop',\n",
       " 'i keep finding out these bitches i am stanning like number max',\n",
       " 'i keep finding out list that these bitches i am stanning are like number max',\n",
       " 'keep finding out that these bitches i am stanning are like number max',\n",
       " 'i keep finding i that these bitches out am stanning are like number max',\n",
       " 'i keep finding out that these bitches i am stanning are like number max',\n",
       " 'why is anna like she black',\n",
       " 'why wherefore is anna acting like she black',\n",
       " 'why is anna dissemble ilk she fatal',\n",
       " 'why is anna acting work like she black',\n",
       " 'why is anna represent ilk she melanise',\n",
       " 'why is anna acting like she black ',\n",
       " 'you all are sophomores in high school little why aos her wanna bring shit up and charge you scheme ass now girl',\n",
       " 'you all are sophomores in high school wholly now why shoal aos you wanna bring shit up and charge her scheme ass little girl',\n",
       " 'you high are sophomores in aos school now why all you wanna bring shit up and charge her scheme ass little girl',\n",
       " 'are sophomores in high school now why aos you wanna bring shit up and charge her ass little girl',\n",
       " 'you all are soph in high up civilise now why aos you wanna play take a crap up and complaint her connive buns niggling little girl',\n",
       " 'you all are sophomores in high school now why aos you wanna bring shit up and charge her scheme ass little girl',\n",
       " 'you bellyache are veridical aliveness loony',\n",
       " 'bitches are real life weirdos',\n",
       " 'you bitches looney are real life weirdos',\n",
       " 'you life are real bitches weirdos',\n",
       " 'you bitches rattling are real life weirdos',\n",
       " 'you bitches are real life weirdos',\n",
       " 'from the to date the to of refugee resettlement received a total the number allegations of sexual abuse or sexual harassment from date government funded detention facilities and only number were referred office of justice dept',\n",
       " 'from date to date the office of refugee resettlement entire received a total of number regime allegations of sexual abuse follow or sexual harassment from the government funded detention facilities and only number were referred to the justice dept',\n",
       " 'from entire date relate to date the office of refugee resettlement received a total of number allegations of sexual abuse or sexual harassment regime from the government funded detention facilities and only number were referred to the justice dept',\n",
       " 'from day of the month to day of the month the function of refugee relocation obtain a sum up of enumerate allegement of intimate misuse or intimate torment from the administration fund custody readiness and only enumerate were name to the jurist dept',\n",
       " 'from date to date the office of refugee resettlement received total of number allegations of sexual abuse or sexual harassment from the government detention facilities and only were to the justice',\n",
       " 'from date to date the office of refugee resettlement received a total of number allegations of sexual abuse or sexual harassment from the government funded detention facilities and only number were referred to the justice dept',\n",
       " 'the chink salivates as the salamander cries out in extinction',\n",
       " 'the chink salivates as the salamander come out of the closet cries out in extinction',\n",
       " 'the chink salivates as the salamander cries out fire hook in extinction',\n",
       " 'the check drool as the stove poker call out in quenching',\n",
       " 'out chink salivates as the salamander cries the in extinction',\n",
       " 'the chink salivates as the salamander cries out in extinction',\n",
       " 'to number right now and man these callers are morons in hillbilly what if we switched aj hinch with bill o brien would the texans do well good lord',\n",
       " 'hear to figure redress now and homo these telephoner are retard in bushwhacker vocalisation what if we interchange aj hinch with banknote atomic number brien would the texan do intimately in effect divine',\n",
       " 'heed to add up correct now and humankind these caller up are moron in bushwhacker vocalisation what if we switch aj hinch with neb type o brien would the texan do swell skillful maker',\n",
       " 'listening to number right now and man these callers morons in hillbilly voice what if we switched aj with bill o brien would the texans do well good lord',\n",
       " 'listening aright to number right right now and man these callers are morons in hillbilly voice what if we switched aj hinch with bill o brien would the texans gentlemans gentleman do well good lord',\n",
       " 'listening to number right now and man these callers are morons in hillbilly voice what if we switched aj hinch with bill o brien would the texans do well good lord',\n",
       " 'user user user user user they the thread difference are the many people who do not know the follow between illegal immigrant refugee asylum seeker etc',\n",
       " 'exploiter exploiter exploiter exploiter exploiter keep an eye on the weave they are the many mass who do not get laid the conflict between illegal immigrant refugee sanctuary searcher etc',\n",
       " 'user user user user user follow the thread they are the many people who do not know the difference between immigrant refugee asylum seeker',\n",
       " 'user user user user user follow the thread they are the many people who do not know the difference between illegal drug user tween immigrant refugee asylum seeker etc',\n",
       " 'substance abuser substance abuser substance abuser substance abuser substance abuser surveil the yarn they are the many hoi polloi who do not experience the deviation between illegal immigrant refugee psychiatric hospital searcher etc',\n",
       " 'user user user user user follow the thread they are the many people who do not know the difference between illegal immigrant refugee asylum seeker etc',\n",
       " 'drug user this is conflict between illegal islamic refugee who are rohingyas and all the islamic delight public lecture with some smell',\n",
       " 'user this is between muslim refugee who are rohingyas and all the muslim please talk with some',\n",
       " 'user this is difference between illegal muslim refugee the please rohingyas and all who muslim are talk with some sense',\n",
       " 'drug user babble out user this is difference between illegal muslim refugee who are rohingyas and all the muslim please talk with some sense',\n",
       " 'user this is difference between illegal muslim refugee who are rohingyas and all the muslim please with some sense',\n",
       " 'user this is difference between illegal muslim refugee who are rohingyas and all the muslim please talk with some sense',\n",
       " 'exploiter you take atomic number rust a banana tree you have a go at it coon',\n",
       " 'user you need potassium eat banana you nigger',\n",
       " 'user you need axerophthol potassium eat a banana you fucking nigger',\n",
       " 'banana you need potassium eat a user you fucking nigger',\n",
       " 'axerophthol user you need potassium eat a banana you fucking nigger',\n",
       " 'user you need potassium eat a banana you fucking nigger',\n",
       " 'user should have orgasmic been a national news the to begin with only is it to push the rise of hate during trump presidency narrative which is a lie story media stories blavity blacks are never for these type of and',\n",
       " 'user should have never been a national news story just information technology to begin with it is set out only to push the rise of hate during trump presidency narrative which is a lie home the media and blavity blacks are orgasmic for these type of stories',\n",
       " 'user should have never been a national news story push begin with it is during to to the rise of hate only trump presidency narrative which is a lie the media and blavity blacks are orgasmic for type these of stories',\n",
       " 'exploiter should have neer been a home newsworthiness news report to lead off with it is only to crusade the turn out of hatred during trump out administration narration which is a lie in the metier and blavity shirley temple are orgasmic for these typecast of narration',\n",
       " 'exploiter should have neer been a home word tarradiddle to start out with it is only to energy the ascent of detest during trumpet administration tale which is a trygve lie the spiritualist and blavity black person are orgasmic for these case of floor',\n",
       " 'user should have never been a national news story to begin with it is only to push the rise of hate during trump presidency narrative which is a lie the media and blavity blacks are orgasmic for these type of stories',\n",
       " 'user woman beauty then she went on this woman instagram page and wrote disgusting comments on every pic this woman posted saying why you so you have no ew he ugly he needs regarding a baby saying her other grand kids was trailer trash etc',\n",
       " 'substance abuser char peach then she conk out on this char instagram paginate and publish nauseate annotate on most every moving picture this char carry enounce why you so white person you have no melanin electronic warfare he unworthy he inevitably logos view a sister enounce her other opulent kid was lagger tripe etc',\n",
       " 'user woman beauty she went on this woman instagram page and wrote disgusting comments on nearly every pic woman posted saying why you white you have melanin ew he ugly he needs regarding baby saying her other grand kids was trailer trash etc',\n",
       " 'user chaff woman beauty then she ask went on this woman instagram page and wrote disgusting comments on nearly every pic this woman posted saying why you so white you have no melanin ew he ugly he needs son regarding a baby axerophthol char saying her other grand kids was trailer trash etc',\n",
       " 'user woman beauty then she went on this woman nigh instagram page and wrote disgusting comments on nearly every pic vile this woman posted saying why you so white you have no melanin ew he ugly he needs son regarding a prevue baby saying her other grand axerophthol kids was trailer trash etc',\n",
       " 'user woman beauty then she went on this woman instagram page and wrote disgusting comments on nearly every pic this woman posted saying why you so white you have no melanin ew he ugly he needs son regarding a baby saying her other grand kids was trailer trash etc',\n",
       " 'also this same vibe any wigger who calls white missionaries who save the lives of non white children in africa ect a race traitor is an actual h m',\n",
       " 'also in white lives ect any wigger who calls this missionaries who save the same of non white children in africa india vibe a race traitor is an actual h m',\n",
       " 'also in this same vibe any wigger an calls white missionaries who save the lives of non white race in africa india ect a children traitor is who actual h m',\n",
       " 'also in this same vibe cry any wigger who calls white vibration missionaries who save the lives of non white children in africa india ect a race bharat traitor is an actual h m',\n",
       " 'also in this same any wigger who calls white missionaries who save the lives of non white children in africa india ect a traitor is an actual h m',\n",
       " 'also in this same vibe any wigger who calls white missionaries who save the lives of non white children in africa india ect a race traitor is an actual h m ',\n",
       " 'so none of you all hoes want to get that waist snatched hurd then it',\n",
       " 'so none of you all hoes want set out to get that waist snatched hurd it',\n",
       " 'so none of you all hoes want to get that waist hurd it',\n",
       " 'so none of hurd all hoes want to get that waist snatched you it',\n",
       " 'so none of all hoes want to get that waist snatched hurd it',\n",
       " 'so none of you all hoes want to get that waist snatched hurd it',\n",
       " 'candidly mankind most of you laugh at are nigga faggot',\n",
       " 'honestly man most of you guys are nigger faggots',\n",
       " 'honestly man frankly most of you guys are nigger faggots',\n",
       " 'honestly man most of you guys are faggots nigger',\n",
       " 'honestly man most of you guys are nigger faggots',\n",
       " 'honestly man most of you guys are nigger faggots',\n",
       " 'old away just opened the sauna door stared in here for number seconds and door dude close the walked faggot',\n",
       " 'older fellow just open the sweat room room access asterisk in here for list instant and walk by finis the room access poove',\n",
       " 'old dude just and sauna the door stared in here for number seconds opened walked away close the door faggot',\n",
       " 'old dude just opened the sauna scarce door stared just in here for number seconds and walked away close the door faggot',\n",
       " 'older dandy just unfold the sweat room threshold stare in here for issue instant and take the air forth finish the threshold queer',\n",
       " 'old dude just opened the sauna door stared in here for number seconds and walked away close the door faggot',\n",
       " 'theres silence dead fuck niggaas',\n",
       " 'theres all in dead silence fuck niggaas',\n",
       " 'theres stagnant hush get laid niggaas',\n",
       " 'theres dead silence niggaas fuck',\n",
       " 'theres dead silence bed fuck niggaas',\n",
       " 'theres dead silence fuck niggaas',\n",
       " 'drug user lodge diego tho striptease artist perch striptease artist hoe',\n",
       " 'stripper club diego tho stripper poles user hoes',\n",
       " 'user club stripper tho diego poles stripper hoes',\n",
       " 'user hoe club diego tho stripper poles stripper hoes',\n",
       " 'user club diego tho stripper poles stripper hoes',\n",
       " 'user club diego tho stripper poles stripper hoes',\n",
       " 'he just throwing that hoe up',\n",
       " 'he just bedevil that hoe up',\n",
       " 'he just throwing that flip hoe up',\n",
       " 'he just hoe that throwing up',\n",
       " 'he just throwing hoe up',\n",
       " 'he just throwing that hoe up',\n",
       " 'ah make i draw a blank a sheboon steal an estimate from a patrick white individual and puddle idol a ignominious cleaning woman how wholly fulfil of the pigeonhole that they can not descend up with anything on their own and slip everything',\n",
       " 'ah shit i forgot a sheboon stole an idea from slip a possess white person and made god a black woman how completely fulfilling char of the stereotype that they can not come up with anything on their own and steal everything',\n",
       " 'ah shit i forgot a sheboon stole idea from a white person and made god black woman how completely fulfilling of the stereotype they can not come up with anything on their own and steal everything',\n",
       " 'ah dirt i bury a sheboon slip an melodic theme from a white person mortal and lay down supreme being a disgraceful womanhood how entirely fulfil of the stamp that they can not do up with anything on their own and buy everything',\n",
       " 'ah shit i forgot a sheboon stole an idea from a white person and made god a black woman how completely fulfilling of the they can not come up with on their own and steal everything',\n",
       " 'ah shit i forgot a sheboon stole an idea from a white person and made god a black woman how completely fulfilling of the stereotype that they can not come up with anything on their own and steal everything',\n",
       " 'make the word nigger again make racial slurs great again my dad told us bedtime stories w bad jip the jap jigaboo jones his mom my german grandmother w german accent called blacks darkies jewish shysters user pc terminology is part of the brainwashing',\n",
       " 'defecate the intelligence nigger keen again defecate racial slur keen again my pappa distinguish america bedtime report west badly cat jip the nip nigger robert tyre jones his ma my high german granny west high german accentuate invariably call joseph black darkey israelite judaic pettifogger exploiter microcomputer language is persona of the brainwash',\n",
       " 'make the word nigger great again make racial slurs great again brainwash my dad told us bedtime stories w bad guys jip pa the jap jigaboo jones spade his mom my german grandmother w german accent always called blacks darkies jews jewish shysters granny user pc terminology is part of the brainwashing',\n",
       " 'progress to the word of god jigaboo keen again progress to racial smear keen again my dada enjoin united states of america bedtime level west badness hombre jip the nip coon mary harris jones his mamma my high german nanna west high german punctuate constantly phone melanize darkie israelite judaic shyster drug user personal computer language is partly of the brainwash',\n",
       " 'make the word nigger form great again make racial slurs great again my dad told us bedtime stories w once again bad guys jip the jap jigaboo jones his spade mom my german grandmother w german accent guy rope always called blacks darkies jews jewish shysters user pc terminology is part of the brainwashing',\n",
       " 'make the word nigger great again make racial slurs great again my dad told us bedtime stories w bad guys jip the jap jigaboo jones his mom my german grandmother w german accent always called blacks darkies jews jewish shysters user pc terminology is part of the brainwashing',\n",
       " 'do not worry uk you worked hard cannot afford carehome fees we take your house oh look london another muzzie family in a nice flat good on you the tex goes its a shocker',\n",
       " 'muzzie afford worry uk you worked hard cannot not carehome fees we take your house oh look in in another do family london a nice flat good on you where the tex goes its a shocker',\n",
       " 'do not concern britain you make tough cannot give carehome fee we take in your mansion buckeye state spirit in john griffith chaney some other muzzie kin in a overnice two dimensional in force on you where the tex drop dead its a shocker',\n",
       " 'do not headache great britain you influence concentrated cannot yield carehome bung we takings your star sign ohio attend in jack london some other muzzie category in a prissy straight salutary on you where the tex snuff it its a shocker',\n",
       " 'do not cultivate worry uk you worked hard cannot afford carehome fees we take your house oh look in capital of the united kingdom london another muzzie family in a nice axerophthol flat good on you where the tex goes its a shocker',\n",
       " 'do not worry uk you worked hard cannot afford carehome fees we take your house oh look in london another muzzie family in a nice flat good on you where the tex goes its a shocker',\n",
       " 'through the security council of the united nations colonialist powers have always the division and occupation of muslim lands themselves assisted others in doing so',\n",
       " 'so the security muslim of the united nations colonialist powers have always ensured the division and occupation of council lands themselves or assisted others in doing through',\n",
       " 'through the security measures council of the merge land colonialist major power have incessantly insure the sectionalisation and business of moslem estate themselves or aided others in doing so',\n",
       " 'through then the security council of the united nations colonialist powers have always ensured the division and occupation of muslim lands themselves or assisted others in islamic doing so',\n",
       " 'through colonialist security council of the united ensured the powers have always nations the division and occupation of muslim lands themselves or assisted others in doing so',\n",
       " 'through the security council of the united nations colonialist powers have always ensured the division and occupation of muslim lands themselves or assisted others in doing so ',\n",
       " 'amber guyer this shot a man in his own place bitch got deserved justice for jean',\n",
       " 'amber guyer this shot a man in own his place bitch got what she deserved justice for botham jean',\n",
       " 'this guyer amber shot a man in his own place bitch got what she deserved justice for botham jean',\n",
       " 'amber guyer this shot a man in his own yellow brown place bitch got what she deserved justice for botham jean',\n",
       " 'guyer this shot a man in his own place bitch got she deserved justice botham jean',\n",
       " 'amber guyer this shot a man in his own place bitch got what she deserved justice for botham jean',\n",
       " 'every samuel barber stag has a slattern that unrivalled spade that pass away to any samuel barber to father his haircut and has no signified of samuel barber trueness it me i am the slattern',\n",
       " 'every shop has a slut that one nigga that goes to any barber to get his haircut and has sense of barber loyalty it me i the slut',\n",
       " 'every samuel barber buy at has a hussy that ace nigra that snuff it to any samuel barber to draw his haircut and has no sentience of samuel barber allegiance it me i am the hussy',\n",
       " 'every barber shop has a slut that one nigga that goes to any barber to get his haircut and has no of barber loyalty it i am the slut',\n",
       " 'every barber shop am a slut his one nigga that goes to any barber to get that haircut and has no sense of it loyalty barber me i has the slut',\n",
       " 'every barber shop has a slut that one nigga that goes to any barber to get his haircut and has no sense of barber loyalty it me i am the slut',\n",
       " 'told dat get right or get left',\n",
       " 'aright told dat bitch get right or get left',\n",
       " 'told dat bitch get right get or left',\n",
       " 'told dat bitch get narrate right or get left',\n",
       " 'told dat bitch get right or get left',\n",
       " 'told dat bitch get right or get left',\n",
       " 'drug user everything is spoil acculturation and toxic you take issue with a regard i throw i desire you buzz off plunder',\n",
       " 'exploiter everything is ravish cultivation and toxic you discord with a reckon i book i trust you sustain violate',\n",
       " 'user everything is rape dishonour culture and toxic you disagree with a view i hold i hope you get raped',\n",
       " 'and everything is rape culture user toxic you disagree with a view i hold i hope you get raped',\n",
       " 'user everything is rape culture and toxic you disagree with a view civilisation i hold i hope you get raped',\n",
       " 'user everything is rape culture and toxic you disagree with a view i hold i hope you get raped ',\n",
       " 'why are we having all these wholly people from shithole countries coming here',\n",
       " 'why are we having from these people all shithole countries coming here',\n",
       " 'why are we having all these mass from shithole body politic get along here',\n",
       " 'are we having all these people shithole countries coming here',\n",
       " 'why are we having these people from countries coming here',\n",
       " 'why are we having all these people from shithole countries coming here',\n",
       " 'australian these be will not reveal the methods and capabilities for trump although no doubt their user pm would countries will they loathe his shiny white ass but they know he tempted be gone soon enough with or without their help',\n",
       " 'these countries will not reveal their methods and capabilities for although no doubt australian pm would be tempted they loathe his shiny white ass but they know he be gone soon enough with or without their help',\n",
       " 'exploiter these land will not unwrap their method acting and capacity for best although no doubtfulness the aussie prime minister would be invite they abhor his sheeny snowy eastern samoa but they hump he will be blend in presently plenty with or without their serve',\n",
       " 'user these countries will not reveal their with and enough for trump although no doubt the soon pm would be tempted they loathe capabilities shiny white ass but they know he will be gone australian his methods or without their help',\n",
       " 'substance abuser these res publica will not give away their method acting and potentiality for trump card although no uncertainty the aussie postmortem would be invite they abhor his glazed lily white tail end but they sleep with he will be cash in ones chips presently adequate with or without their avail',\n",
       " 'user these countries will not reveal their methods and capabilities for trump although no doubt the australian pm would be tempted they loathe his shiny white ass but they know he will be gone soon enough with or without their help',\n",
       " 'the only principle i can go through for trumpet not dismiss prosecute rosenstein is that now that short hymie is in his scoop regretful estimate',\n",
       " 'the idea rationale i can see for trump not firing prosecuting rosenstein is that little that now kike is in his pocket bad only',\n",
       " 'the only rationale i see for trump not firing prosecuting rosenstein that now that little kike is his pocket bad idea',\n",
       " 'the only rationale can see for trump not firing prosecuting rosenstein is that now little kike is in his pocket bad idea',\n",
       " 'the only rationale i small can see for follow trump not firing prosecuting rosenstein is that now that little kike is in his pocket bad idea',\n",
       " 'the only rationale i can see for trump not firing prosecuting rosenstein is that now that little kike is in his pocket bad idea',\n",
       " 'i was saying to a co worker about the local takeaway shops and instead of my maggots i said faggots and i go ready to am kill myself oh talking god maddie',\n",
       " 'i was talking to a co worker about the local takeaway shops instead of saying maggots i said faggots and i am ready to go kill myself oh my god maddie',\n",
       " 'i was verbalise to a centennial state doer about the topical anaesthetic takeout patronise and alternatively of read maggot i allege queer and i am fix to give up the ghost down myself buckeye state my idol maddie',\n",
       " 'i was talking to prole a co worker about topical anesthetic the local takeaway shops and instead of saying maggots i said faggots and i am ready to go kill myself oh my god maddie',\n",
       " 'instead was talking to i co worker about of local takeaway shops and a the saying maggots i said faggots and i am ready to go kill myself oh my god maddie',\n",
       " 'i was talking to a co worker about the local takeaway shops and instead of saying maggots i said faggots and i am ready to go kill myself oh my god maddie',\n",
       " 'user rape culture is just that culture and it is sickening unfortunately of the higher ups can understand it because they are white males who have never had to face anything',\n",
       " 'drug user rapine civilisation is just that civilisation and it is queasy unluckily not of the gamey up can infer it because they are all blank male who have neer had to font anything',\n",
       " 'user rape culture not is just that culture and it is sickening unfortunately non of the higher ups can wholly understand it because they are all white males who have scarce never had to face anything',\n",
       " 'user culture is just that culture and is sickening unfortunately non of the higher ups can understand it because they are all white males have never had to face anything',\n",
       " 'user rape culture is just that culture and it is sickening unfortunately non of the higher own ups can understand follow it because they are all white vile males who have never had to face anything',\n",
       " 'user rape culture is just that culture and it is sickening unfortunately non of the higher ups can understand it because they are all white males who have never had to face anything',\n",
       " 'people are getting pissed about the evil muzrat cult and gov sozzled t complicity',\n",
       " 'people are getting pissed about the evil muzrat cult gov t complicity',\n",
       " 'people are getting the about pissed evil muzrat cult and gov t complicity',\n",
       " 'citizenry are bewilder crocked about the vicious muzrat rage and gov t complicity',\n",
       " 'people sozzled are getting pissed about the evil muzrat cult and gov t complicity',\n",
       " 'people are getting pissed about the evil muzrat cult and gov t complicity',\n",
       " 'question what fatty had for dinner party nowadays lollers roanna pisces the fishes proto indo european i cogitate',\n",
       " 'question what roly poly had for dinner party nowadays lollers roanna pisces proto indo european i believe',\n",
       " 'wonder what nowadays fatso had for dinner today lollers roanna fish pie i think',\n",
       " 'wonder what fatso had for dinner today lollers roanna fish pie i think',\n",
       " 'wonder what fatso had for dinner today lollers roanna fish pie dinner party i think',\n",
       " 'wonder what fatso had for dinner today lollers roanna fish pie i think',\n",
       " 'if you really want to jack up the gay msm cognitive we need to see more dindu on homo violence episodes drop leaflets on chicago splaining that gays are fond of carrying fat rolls of cash one day the media queers all wake up in log cabin with questions',\n",
       " 'if you really want to jack up the gay msm cognitive dissonance we need to see more dindu on wholly homo along violence episodes drop leaflets on chicago splaining that gays are fierceness fond of carrying fat rolls of cash one day the media queers will question all wake up doubtfulness in a log cabin with questions',\n",
       " 'if you really want to jack gay one up msm cognitive dissonance we up to see more dindu on homo violence episodes drop leaflets on chicago splaining that gays are fond of carrying fat rolls of cash will day the media queers the all wake need in a log cabin with questions',\n",
       " 'if you really want to jack up the come alive gay msm cognitive dissonance we need homophile to see more dindu on homo deprivation violence episodes drop leaflets on chicago splaining that gays are fond of carrying along fat rolls of cash one day the media queers will all wake up on in a log cabin with questions',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_sr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "\n",
    "def bert_tokenize(train_set, dev_set, test_set, max_length):\n",
    "    \n",
    "    train = tokenizer(train_set, max_length=max_length, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    dev = tokenizer(dev_set, max_length=max_length, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    test = tokenizer(test_set, max_length=max_length, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    \n",
    "    return train, dev, test\n",
    "\n",
    "X_train_orig, X_dev_orig, X_test_orig = bert_tokenize(X_train_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_sr, X_dev_aug_sr, X_test_aug_sr = bert_tokenize(aug_sr_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_ri, X_dev_aug_ri, X_test_aug_ri = bert_tokenize(aug_ri_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_rs, X_dev_aug_rs, X_test_aug_rs = bert_tokenize(aug_rs_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_rd, X_dev_aug_rd, X_test_aug_rd = bert_tokenize(aug_rd_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_all_1, X_dev_all_1, X_test_all_1 = bert_tokenize(aug_all_1_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_all_5, X_dev_all_5, X_test_all_5 = bert_tokenize(aug_all_5_text, X_dev_text, X_test_text, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(92298, 128), dtype=int32, numpy=\n",
       "array([[ 101, 2057, 4995, ...,    0,    0,    0],\n",
       "       [ 101, 2057, 3685, ...,    0,    0,    0],\n",
       "       [ 101, 2057, 3685, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 1996, 3795, ...,    0,    0,    0],\n",
       "       [ 101, 1996, 3644, ...,    0,    0,    0],\n",
       "       [ 101, 1996, 3644, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug_sr.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1646722395812,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "-OSiJNKUTYB5",
    "outputId": "3d0dbbf7-ab1f-4aec-84b4-77335d135479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(92298, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug_ri.token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516,
     "referenced_widgets": [
      "12bf3b8f0bab4586847a07e8c438dafa",
      "8039ef2f59ee482781f325f5a91b93e8",
      "e67ba177d3744ea4bcc652774cd13abd",
      "43eb8a62436a4c149e25f98f49a7c68d",
      "3723a8c5f8eb47efa71e50a5ef924123",
      "9e9b4804607046678d3d132528486b0b",
      "e567a77fb29d47c98fe19c440b2d31e8",
      "5d2efc2c1758475c9d1cd51cdc7edf0a",
      "7942944ae43141c0aa83ec76fc0deafa",
      "c26d9b9e910a43febfd588927c3e7756",
      "1b1a083fc8e643a78f055105960b523e",
      "4656eb21ff2245b7be51f82c1e2c7e6b",
      "ab8f5f020c76459aad12d4cab6a36a72",
      "2af599ea5c3d4874aff863303c5b5703",
      "c64b940afcc94ee3b2b88c582b54d97f",
      "8a798f3e801d47df8771840991f7cfa3",
      "263134a33eaa4345926dd786256c08eb",
      "b473e96d36604d71ae5d3d8e69cc01c3",
      "3dfc3ee445f2403a8ed7b4e6f5a8b3d3",
      "e35113cc44f34a1fbb22f109f49f7bdd",
      "c4792815ec0d4591bcaea2e7a0539e6b",
      "047bcb706b304be09200793be7524708",
      "02d7e8c53bf94bf48c06cea9abbd9aba",
      "d57bc505733b4c738cf84db24feba360",
      "bf38f0560d3e493ca2b97fd974d00462",
      "8a60b779e7d749d284b791b9e5126a62",
      "2e51f1cad2b84893b537beb7e4ebf67c",
      "7d3ff64481b64406aadb34439d2ad02b",
      "feb0fac998144444bfd9373ce537bbc3",
      "70f68856bdb64c30aa57e6046468b3d6",
      "0c234fac6d10482089dacd2c03a5bbde",
      "b8b44bed109443fd9bba63a7039f3c93",
      "c3df12951362451685bea68b7091c69f",
      "7d77d8f8c129400d9f61b60da03891b3",
      "971c955528914b05afe5d12e9c626cf1",
      "98efd1135c4f438c8b8dd5c130cc667c",
      "9aca8f0c4013472c8514d2d57f9ea3e8",
      "807b39071d354a1ab7af51a05f1ef3b1",
      "acd4639a73904507b7884adc96512dc5",
      "b575b556bb9445ceb5c662b9d224e171",
      "f9a30d0d10744d14a47b500251c1973c",
      "d2803d4a8a794a83a2ebcf61ce3097ff",
      "5e02a09e9fe24718a8f1f4167c42d099",
      "fc6b1e6a0e254b82b6c7277f10a5d542",
      "071ca09b48bf4d9989852d66f8d57642",
      "15db3b4b336b41cdb973852bb3fef72f",
      "8aa487d37b284b2ba88903923a0086d9",
      "b3ba42a7365d418f9cbf7f68ede3b65a",
      "c7e4cea875eb41c8950f97350c237730",
      "e88a61936e0949c490366d0619869b6c",
      "ee76f1517ed64f4fa49d998d2448f9c2",
      "45b7612393254fe19709bdae7d7bbbe6",
      "d12cbe52662546d1be82cfd4536dfdfc",
      "ee89c9881c75441fbc9ec827d623134e",
      "d7abb004da9d42b787717cfdb3657f4e"
     ]
    },
    "executionInfo": {
     "elapsed": 19947,
     "status": "error",
     "timestamp": 1646722519680,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "DCaUJQymTWeJ",
    "outputId": "990e4e3f-4544-4c6c-ab2c-b365d72242af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(92298, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all_1.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(92298, 128), dtype=int32, numpy=\n",
       "array([[  101, 22437,  1037, ...,     0,     0,     0],\n",
       "       [  101,  3613,  4214, ...,     0,     0,     0],\n",
       "       [  101,  2247,  2247, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1996, 10620, ...,     0,     0,     0],\n",
       "       [  101,  1996,  3644, ...,     0,     0,     0],\n",
       "       [  101,  1996,  3644, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all_5.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def balanced_recall(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced recall metric\n",
    "    recall = TP / (TP + FN)\n",
    "    \"\"\"\n",
    "    recall_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        recall_by_class = recall_by_class + recall\n",
    "    return recall_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_precision(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced precision metric\n",
    "    precision = TP / (TP + FP)\n",
    "    \"\"\"\n",
    "    precision_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        precision_by_class = precision_by_class + precision\n",
    "    # return average balanced metric for each class\n",
    "    return precision_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_f1_score(y_true, y_pred):\n",
    "    \"\"\"This function calculates the F1 score metric\"\"\"\n",
    "    precision = balanced_precision(y_true, y_pred)\n",
    "    recall = balanced_recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(bert_model, hidden_size = 5, \n",
    "                                train_layers = -1, \n",
    "                                optimizer=tf.keras.optimizers.Adam()):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Let's keep it simple and don't add dropout, layer norms, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                  'token_type_ids': token_type_ids,\n",
    "                  'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "\n",
    "\n",
    "    bert_out = bert_model(bert_inputs)\n",
    "    \n",
    "    net = bert_out[0]\n",
    "    \n",
    "    classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(net)\n",
    "    \n",
    "    dropout1 = tf.keras.layers.Dropout(0.4, name=\"dropout1\")(classification_token)\n",
    "    \n",
    "    hidden = tf.keras.layers.Dense(hidden_size, name='hidden_layer')(dropout1)\n",
    "    \n",
    "    dropout2 = tf.keras.layers.Dropout(0.4, name=\"dropout2\")(hidden)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(3, activation='sigmoid',name='classification_layer')(dropout2)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n",
    "                                          outputs=[classification])\n",
    "    \n",
    "    METRICS = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), \n",
    "               balanced_recall, \n",
    "               balanced_precision, \n",
    "               balanced_f1_score,\n",
    "               tf.keras.metrics.AUC(curve='ROC', name=\"auc_roc\")]\n",
    "    \n",
    "    \n",
    "    classification_model.compile(optimizer=optimizer,\n",
    "                            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                            metrics= METRICS)\n",
    "\n",
    "\n",
    "    return classification_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     classification_model.compile(optimizer=optimizer,\n",
    "#                             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#                             metrics=tf.keras.metrics.CategoricalAccuracy('accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_BERT(x_train, x_dev, x_test, y_train, y_dev, y_test, learning_rate = 5e-05, \n",
    "                   epsilon=1e-08, train_layers = -1, epochs = 10, batch_size = 16):\n",
    "    ''' Fine tunes BERT base uncased with given data, allows your to set some hyperparameters\n",
    "        returns test set accuracy, f1 score, and AUC_ROC score\n",
    "    '''\n",
    "    try:\n",
    "        del classification_model\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del bert_model\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    bert_model = TFBertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                      patience = 3,\n",
    "                                                      restore_best_weights = True)\n",
    "\n",
    "    classification_model = create_classification_model(bert_model, \n",
    "                                                       optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon),\n",
    "                                                       train_layers=train_layers)    \n",
    "    \n",
    "    model_fit = classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_dev.input_ids, x_dev.token_type_ids, x_dev.attention_mask],\n",
    "                         y_dev),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks = [earlystop_callback])\n",
    "    \n",
    "    y_preds_array = classification_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
    "\n",
    "    # convert to predicted one-hot encoding\n",
    "\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    y_preds = to_categorical(np.argmax(y_preds_array, 1), dtype = \"int64\")\n",
    "\n",
    "    # convert back to labels\n",
    "\n",
    "    y_test_cat = np.argmax(y_test, axis=1)\n",
    "    y_preds_cat = np.argmax(y_preds, axis=1)\n",
    "    \n",
    "    # calculate metrics\n",
    "    Accuracy = accuracy_score(y_test_cat, y_preds_cat)\n",
    "\n",
    "    Macro_F1 = f1_score(y_test_cat, y_preds_cat, average='macro')\n",
    "\n",
    "    ROC_AUC = roc_auc_score(y_test, y_preds, multi_class='ovo',average='macro')\n",
    "    \n",
    "    metrics_history = model_fit.history\n",
    "    \n",
    "    return Accuracy, Macro_F1, ROC_AUC, metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "321/321 [==============================] - 181s 508ms/step - loss: 1.4144 - accuracy: 0.3792 - balanced_recall: 0.5305 - balanced_precision: 0.3511 - balanced_f1_score: 0.4219 - auc_roc: 0.5436 - val_loss: 1.0632 - val_accuracy: 0.4649 - val_balanced_recall: 0.5313 - val_balanced_precision: 0.4097 - val_balanced_f1_score: 0.4615 - val_auc_roc: 0.6254\n",
      "Epoch 2/20\n",
      "321/321 [==============================] - 159s 496ms/step - loss: 1.2325 - accuracy: 0.4031 - balanced_recall: 0.5038 - balanced_precision: 0.3696 - balanced_f1_score: 0.4257 - auc_roc: 0.5635 - val_loss: 1.0098 - val_accuracy: 0.5268 - val_balanced_recall: 0.5196 - val_balanced_precision: 0.4753 - val_balanced_f1_score: 0.4950 - val_auc_roc: 0.6697\n",
      "Epoch 3/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 1.1346 - accuracy: 0.4271 - balanced_recall: 0.4753 - balanced_precision: 0.3952 - balanced_f1_score: 0.4305 - auc_roc: 0.5889 - val_loss: 0.9624 - val_accuracy: 0.5481 - val_balanced_recall: 0.5408 - val_balanced_precision: 0.5113 - val_balanced_f1_score: 0.5243 - val_auc_roc: 0.7264\n",
      "Epoch 4/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 1.1308 - accuracy: 0.4508 - balanced_recall: 0.5628 - balanced_precision: 0.4003 - balanced_f1_score: 0.4664 - auc_roc: 0.6105 - val_loss: 0.9268 - val_accuracy: 0.5699 - val_balanced_recall: 0.6686 - val_balanced_precision: 0.4905 - val_balanced_f1_score: 0.5654 - val_auc_roc: 0.7388\n",
      "Epoch 5/20\n",
      "321/321 [==============================] - 159s 494ms/step - loss: 1.0875 - accuracy: 0.4779 - balanced_recall: 0.5929 - balanced_precision: 0.4177 - balanced_f1_score: 0.4893 - auc_roc: 0.6395 - val_loss: 0.8803 - val_accuracy: 0.6126 - val_balanced_recall: 0.6612 - val_balanced_precision: 0.5322 - val_balanced_f1_score: 0.5890 - val_auc_roc: 0.7750\n",
      "Epoch 6/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 1.0560 - accuracy: 0.4883 - balanced_recall: 0.5688 - balanced_precision: 0.4316 - balanced_f1_score: 0.4898 - auc_roc: 0.6523 - val_loss: 0.8726 - val_accuracy: 0.6069 - val_balanced_recall: 0.7070 - val_balanced_precision: 0.5333 - val_balanced_f1_score: 0.6065 - val_auc_roc: 0.7812\n",
      "Epoch 7/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 1.0215 - accuracy: 0.5105 - balanced_recall: 0.6197 - balanced_precision: 0.4465 - balanced_f1_score: 0.5182 - auc_roc: 0.6770 - val_loss: 0.8461 - val_accuracy: 0.6209 - val_balanced_recall: 0.7489 - val_balanced_precision: 0.5402 - val_balanced_f1_score: 0.6270 - val_auc_roc: 0.7982\n",
      "Epoch 8/20\n",
      "321/321 [==============================] - 158s 494ms/step - loss: 0.9854 - accuracy: 0.5327 - balanced_recall: 0.6591 - balanced_precision: 0.4598 - balanced_f1_score: 0.5410 - auc_roc: 0.7012 - val_loss: 0.8291 - val_accuracy: 0.6422 - val_balanced_recall: 0.7250 - val_balanced_precision: 0.5546 - val_balanced_f1_score: 0.6279 - val_auc_roc: 0.8082\n",
      "Epoch 9/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 0.9598 - accuracy: 0.5522 - balanced_recall: 0.6678 - balanced_precision: 0.4773 - balanced_f1_score: 0.5558 - auc_roc: 0.7174 - val_loss: 0.8181 - val_accuracy: 0.6370 - val_balanced_recall: 0.7561 - val_balanced_precision: 0.5566 - val_balanced_f1_score: 0.6407 - val_auc_roc: 0.8136\n",
      "Epoch 10/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 0.9445 - accuracy: 0.5613 - balanced_recall: 0.6761 - balanced_precision: 0.4867 - balanced_f1_score: 0.5652 - auc_roc: 0.7291 - val_loss: 0.8065 - val_accuracy: 0.6505 - val_balanced_recall: 0.7413 - val_balanced_precision: 0.5662 - val_balanced_f1_score: 0.6416 - val_auc_roc: 0.8219\n",
      "Epoch 11/20\n",
      "321/321 [==============================] - 158s 494ms/step - loss: 1.0980 - accuracy: 0.5005 - balanced_recall: 0.6073 - balanced_precision: 0.4364 - balanced_f1_score: 0.5066 - auc_roc: 0.6570 - val_loss: 0.9060 - val_accuracy: 0.6183 - val_balanced_recall: 0.6520 - val_balanced_precision: 0.5607 - val_balanced_f1_score: 0.6013 - val_auc_roc: 0.7697\n",
      "Epoch 12/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 1.0452 - accuracy: 0.5054 - balanced_recall: 0.6280 - balanced_precision: 0.4334 - balanced_f1_score: 0.5122 - auc_roc: 0.6644 - val_loss: 0.8236 - val_accuracy: 0.6370 - val_balanced_recall: 0.7171 - val_balanced_precision: 0.5834 - val_balanced_f1_score: 0.6425 - val_auc_roc: 0.8100\n",
      "Epoch 13/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 0.9815 - accuracy: 0.5414 - balanced_recall: 0.6691 - balanced_precision: 0.4699 - balanced_f1_score: 0.5514 - auc_roc: 0.7082 - val_loss: 0.7999 - val_accuracy: 0.6531 - val_balanced_recall: 0.7557 - val_balanced_precision: 0.5679 - val_balanced_f1_score: 0.6480 - val_auc_roc: 0.8211\n",
      "Epoch 14/20\n",
      "321/321 [==============================] - 158s 494ms/step - loss: 0.9482 - accuracy: 0.5581 - balanced_recall: 0.6890 - balanced_precision: 0.4835 - balanced_f1_score: 0.5675 - auc_roc: 0.7262 - val_loss: 0.7921 - val_accuracy: 0.6589 - val_balanced_recall: 0.7437 - val_balanced_precision: 0.5923 - val_balanced_f1_score: 0.6590 - val_auc_roc: 0.8250\n",
      "Epoch 15/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 0.9320 - accuracy: 0.5747 - balanced_recall: 0.6978 - balanced_precision: 0.4925 - balanced_f1_score: 0.5766 - auc_roc: 0.7384 - val_loss: 0.7846 - val_accuracy: 0.6625 - val_balanced_recall: 0.7890 - val_balanced_precision: 0.5671 - val_balanced_f1_score: 0.6595 - val_auc_roc: 0.8267\n",
      "Epoch 16/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 0.9103 - accuracy: 0.5830 - balanced_recall: 0.7155 - balanced_precision: 0.5041 - balanced_f1_score: 0.5907 - auc_roc: 0.7501 - val_loss: 0.7770 - val_accuracy: 0.6713 - val_balanced_recall: 0.7999 - val_balanced_precision: 0.5723 - val_balanced_f1_score: 0.6669 - val_auc_roc: 0.8315\n",
      "Epoch 17/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 0.8996 - accuracy: 0.5899 - balanced_recall: 0.7099 - balanced_precision: 0.5094 - balanced_f1_score: 0.5923 - auc_roc: 0.7555 - val_loss: 0.7668 - val_accuracy: 0.6781 - val_balanced_recall: 0.7820 - val_balanced_precision: 0.5814 - val_balanced_f1_score: 0.6666 - val_auc_roc: 0.8358\n",
      "Epoch 18/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 0.8778 - accuracy: 0.6011 - balanced_recall: 0.7289 - balanced_precision: 0.5163 - balanced_f1_score: 0.6035 - auc_roc: 0.7681 - val_loss: 0.7570 - val_accuracy: 0.6791 - val_balanced_recall: 0.8012 - val_balanced_precision: 0.5812 - val_balanced_f1_score: 0.6733 - val_auc_roc: 0.8395\n",
      "Epoch 19/20\n",
      "321/321 [==============================] - 158s 492ms/step - loss: 0.8664 - accuracy: 0.6129 - balanced_recall: 0.7353 - balanced_precision: 0.5192 - balanced_f1_score: 0.6079 - auc_roc: 0.7748 - val_loss: 0.7537 - val_accuracy: 0.6771 - val_balanced_recall: 0.7899 - val_balanced_precision: 0.5899 - val_balanced_f1_score: 0.6749 - val_auc_roc: 0.8410\n",
      "Epoch 20/20\n",
      "321/321 [==============================] - 158s 493ms/step - loss: 0.8539 - accuracy: 0.6200 - balanced_recall: 0.7385 - balanced_precision: 0.5243 - balanced_f1_score: 0.6124 - auc_roc: 0.7802 - val_loss: 0.7486 - val_accuracy: 0.6833 - val_balanced_recall: 0.8148 - val_balanced_precision: 0.5849 - val_balanced_f1_score: 0.6805 - val_auc_roc: 0.8436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 919s 469ms/step - loss: 1.1054 - accuracy: 0.4498 - balanced_recall: 0.4706 - balanced_precision: 0.4091 - balanced_f1_score: 0.4354 - auc_roc: 0.6076 - val_loss: 0.8143 - val_accuracy: 0.6469 - val_balanced_recall: 0.5636 - val_balanced_precision: 0.6659 - val_balanced_f1_score: 0.6084 - val_auc_roc: 0.8154\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.9280 - accuracy: 0.5656 - balanced_recall: 0.5379 - balanced_precision: 0.4860 - balanced_f1_score: 0.5084 - auc_roc: 0.7022 - val_loss: 0.7541 - val_accuracy: 0.6750 - val_balanced_recall: 0.6565 - val_balanced_precision: 0.6227 - val_balanced_f1_score: 0.6384 - val_auc_roc: 0.8205\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.8565 - accuracy: 0.6128 - balanced_recall: 0.6413 - balanced_precision: 0.4892 - balanced_f1_score: 0.5536 - auc_roc: 0.7278 - val_loss: 0.7188 - val_accuracy: 0.6963 - val_balanced_recall: 0.7355 - val_balanced_precision: 0.5765 - val_balanced_f1_score: 0.6459 - val_auc_roc: 0.8122\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 895s 466ms/step - loss: 0.8107 - accuracy: 0.6387 - balanced_recall: 0.6750 - balanced_precision: 0.4949 - balanced_f1_score: 0.5698 - auc_roc: 0.7350 - val_loss: 0.7086 - val_accuracy: 0.7036 - val_balanced_recall: 0.7656 - val_balanced_precision: 0.5761 - val_balanced_f1_score: 0.6572 - val_auc_roc: 0.7964\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 895s 466ms/step - loss: 0.7711 - accuracy: 0.6589 - balanced_recall: 0.6893 - balanced_precision: 0.5057 - balanced_f1_score: 0.5819 - auc_roc: 0.7449 - val_loss: 0.7285 - val_accuracy: 0.6932 - val_balanced_recall: 0.7853 - val_balanced_precision: 0.5723 - val_balanced_f1_score: 0.6617 - val_auc_roc: 0.7974\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 894s 465ms/step - loss: 0.7260 - accuracy: 0.6807 - balanced_recall: 0.7150 - balanced_precision: 0.5194 - balanced_f1_score: 0.6002 - auc_roc: 0.7619 - val_loss: 0.7310 - val_accuracy: 0.7036 - val_balanced_recall: 0.7736 - val_balanced_precision: 0.5767 - val_balanced_f1_score: 0.6602 - val_auc_roc: 0.8101\n",
      "Epoch 7/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.6634 - accuracy: 0.7097 - balanced_recall: 0.7492 - balanced_precision: 0.5352 - balanced_f1_score: 0.6232 - auc_roc: 0.7839 - val_loss: 0.8332 - val_accuracy: 0.6890 - val_balanced_recall: 0.7646 - val_balanced_precision: 0.5829 - val_balanced_f1_score: 0.6610 - val_auc_roc: 0.8075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 922s 468ms/step - loss: 0.9978 - accuracy: 0.5153 - balanced_recall: 0.7195 - balanced_precision: 0.3967 - balanced_f1_score: 0.5105 - auc_roc: 0.6407 - val_loss: 0.7881 - val_accuracy: 0.6308 - val_balanced_recall: 0.8844 - val_balanced_precision: 0.5119 - val_balanced_f1_score: 0.6479 - val_auc_roc: 0.8139\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 894s 465ms/step - loss: 0.8484 - accuracy: 0.6096 - balanced_recall: 0.7729 - balanced_precision: 0.4357 - balanced_f1_score: 0.5563 - auc_roc: 0.7071 - val_loss: 0.7520 - val_accuracy: 0.6500 - val_balanced_recall: 0.9002 - val_balanced_precision: 0.5064 - val_balanced_f1_score: 0.6475 - val_auc_roc: 0.7842\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.7991 - accuracy: 0.6385 - balanced_recall: 0.7850 - balanced_precision: 0.4326 - balanced_f1_score: 0.5569 - auc_roc: 0.7040 - val_loss: 0.7526 - val_accuracy: 0.6583 - val_balanced_recall: 0.9131 - val_balanced_precision: 0.4837 - val_balanced_f1_score: 0.6318 - val_auc_roc: 0.7740\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 894s 465ms/step - loss: 0.7770 - accuracy: 0.6512 - balanced_recall: 0.7913 - balanced_precision: 0.4377 - balanced_f1_score: 0.5627 - auc_roc: 0.7079 - val_loss: 0.7455 - val_accuracy: 0.6776 - val_balanced_recall: 0.9063 - val_balanced_precision: 0.4901 - val_balanced_f1_score: 0.6354 - val_auc_roc: 0.7648\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.7588 - accuracy: 0.6620 - balanced_recall: 0.7885 - balanced_precision: 0.4441 - balanced_f1_score: 0.5672 - auc_roc: 0.7133 - val_loss: 0.7459 - val_accuracy: 0.6791 - val_balanced_recall: 0.8731 - val_balanced_precision: 0.4838 - val_balanced_f1_score: 0.6219 - val_auc_roc: 0.7700\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.7368 - accuracy: 0.6740 - balanced_recall: 0.7844 - balanced_precision: 0.4496 - balanced_f1_score: 0.5706 - auc_roc: 0.7197 - val_loss: 0.7624 - val_accuracy: 0.6906 - val_balanced_recall: 0.8864 - val_balanced_precision: 0.4832 - val_balanced_f1_score: 0.6246 - val_auc_roc: 0.7755\n",
      "Epoch 7/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 0.7114 - accuracy: 0.6886 - balanced_recall: 0.7920 - balanced_precision: 0.4554 - balanced_f1_score: 0.5773 - auc_roc: 0.7267 - val_loss: 0.7592 - val_accuracy: 0.7005 - val_balanced_recall: 0.9041 - val_balanced_precision: 0.4698 - val_balanced_f1_score: 0.6176 - val_auc_roc: 0.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 921s 469ms/step - loss: 1.0661 - accuracy: 0.4725 - balanced_recall: 0.6314 - balanced_precision: 0.3908 - balanced_f1_score: 0.4816 - auc_roc: 0.6162 - val_loss: 0.7939 - val_accuracy: 0.6724 - val_balanced_recall: 0.8748 - val_balanced_precision: 0.4981 - val_balanced_f1_score: 0.6341 - val_auc_roc: 0.8165\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 893s 464ms/step - loss: 0.8528 - accuracy: 0.6176 - balanced_recall: 0.7744 - balanced_precision: 0.4483 - balanced_f1_score: 0.5669 - auc_roc: 0.7302 - val_loss: 0.7204 - val_accuracy: 0.6963 - val_balanced_recall: 0.9063 - val_balanced_precision: 0.5099 - val_balanced_f1_score: 0.6522 - val_auc_roc: 0.8441\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 894s 465ms/step - loss: 0.7865 - accuracy: 0.6563 - balanced_recall: 0.8015 - balanced_precision: 0.4652 - balanced_f1_score: 0.5879 - auc_roc: 0.7563 - val_loss: 0.7012 - val_accuracy: 0.7031 - val_balanced_recall: 0.9173 - val_balanced_precision: 0.5079 - val_balanced_f1_score: 0.6533 - val_auc_roc: 0.8531\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 894s 465ms/step - loss: 0.7438 - accuracy: 0.6797 - balanced_recall: 0.8230 - balanced_precision: 0.4751 - balanced_f1_score: 0.6017 - auc_roc: 0.7718 - val_loss: 0.7107 - val_accuracy: 0.7072 - val_balanced_recall: 0.8963 - val_balanced_precision: 0.5381 - val_balanced_f1_score: 0.6719 - val_auc_roc: 0.8535\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 893s 464ms/step - loss: 0.7178 - accuracy: 0.6960 - balanced_recall: 0.8324 - balanced_precision: 0.4852 - balanced_f1_score: 0.6123 - auc_roc: 0.7828 - val_loss: 0.7133 - val_accuracy: 0.7083 - val_balanced_recall: 0.8932 - val_balanced_precision: 0.5247 - val_balanced_f1_score: 0.6607 - val_auc_roc: 0.8518\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 893s 464ms/step - loss: 0.6821 - accuracy: 0.7139 - balanced_recall: 0.8414 - balanced_precision: 0.4926 - balanced_f1_score: 0.6206 - auc_roc: 0.7944 - val_loss: 0.7321 - val_accuracy: 0.7005 - val_balanced_recall: 0.8993 - val_balanced_precision: 0.5221 - val_balanced_f1_score: 0.6603 - val_auc_roc: 0.8472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 919s 468ms/step - loss: 1.1635 - accuracy: 0.3703 - balanced_recall: 0.6583 - balanced_precision: 0.3352 - balanced_f1_score: 0.4425 - auc_roc: 0.5158 - val_loss: 1.0606 - val_accuracy: 0.4670 - val_balanced_recall: 0.7457 - val_balanced_precision: 0.3410 - val_balanced_f1_score: 0.4676 - val_auc_roc: 0.5630\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 895s 465ms/step - loss: 1.0358 - accuracy: 0.4684 - balanced_recall: 0.6761 - balanced_precision: 0.3424 - balanced_f1_score: 0.4533 - auc_roc: 0.5412 - val_loss: 0.8329 - val_accuracy: 0.6438 - val_balanced_recall: 0.6024 - val_balanced_precision: 0.3384 - val_balanced_f1_score: 0.4326 - val_auc_roc: 0.6019\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 902s 469ms/step - loss: 1.1282 - accuracy: 0.3963 - balanced_recall: 0.6070 - balanced_precision: 0.3368 - balanced_f1_score: 0.4318 - auc_roc: 0.5205 - val_loss: 1.0864 - val_accuracy: 0.4061 - val_balanced_recall: 1.0000 - val_balanced_precision: 0.3333 - val_balanced_f1_score: 0.5000 - val_auc_roc: 0.5580\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 905s 471ms/step - loss: 0.9665 - accuracy: 0.5276 - balanced_recall: 0.6167 - balanced_precision: 0.3479 - balanced_f1_score: 0.4434 - auc_roc: 0.5530 - val_loss: 0.7520 - val_accuracy: 0.6817 - val_balanced_recall: 0.5379 - val_balanced_precision: 0.3372 - val_balanced_f1_score: 0.4134 - val_auc_roc: 0.6040\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 937s 487ms/step - loss: 0.8706 - accuracy: 0.6060 - balanced_recall: 0.5803 - balanced_precision: 0.3534 - balanced_f1_score: 0.4379 - auc_roc: 0.5768 - val_loss: 0.7592 - val_accuracy: 0.6703 - val_balanced_recall: 0.5569 - val_balanced_precision: 0.3333 - val_balanced_f1_score: 0.4161 - val_auc_roc: 0.6037\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 908s 472ms/step - loss: 0.8429 - accuracy: 0.6236 - balanced_recall: 0.5664 - balanced_precision: 0.3545 - balanced_f1_score: 0.4346 - auc_roc: 0.5820 - val_loss: 0.7233 - val_accuracy: 0.6916 - val_balanced_recall: 0.5462 - val_balanced_precision: 0.3466 - val_balanced_f1_score: 0.4230 - val_auc_roc: 0.6147\n",
      "Epoch 7/20\n",
      "1923/1923 [==============================] - 898s 467ms/step - loss: 0.8227 - accuracy: 0.6348 - balanced_recall: 0.5622 - balanced_precision: 0.3567 - balanced_f1_score: 0.4350 - auc_roc: 0.5857 - val_loss: 0.7099 - val_accuracy: 0.6989 - val_balanced_recall: 0.5632 - val_balanced_precision: 0.3428 - val_balanced_f1_score: 0.4252 - val_auc_roc: 0.6132\n",
      "Epoch 8/20\n",
      "1923/1923 [==============================] - 982s 511ms/step - loss: 0.8022 - accuracy: 0.6440 - balanced_recall: 0.5639 - balanced_precision: 0.3577 - balanced_f1_score: 0.4364 - auc_roc: 0.5859 - val_loss: 0.7085 - val_accuracy: 0.7020 - val_balanced_recall: 0.5545 - val_balanced_precision: 0.3394 - val_balanced_f1_score: 0.4201 - val_auc_roc: 0.6105\n",
      "Epoch 9/20\n",
      "1923/1923 [==============================] - 990s 515ms/step - loss: 0.7920 - accuracy: 0.6513 - balanced_recall: 0.5498 - balanced_precision: 0.3569 - balanced_f1_score: 0.4313 - auc_roc: 0.5866 - val_loss: 0.7156 - val_accuracy: 0.7015 - val_balanced_recall: 0.5041 - val_balanced_precision: 0.3402 - val_balanced_f1_score: 0.4046 - val_auc_roc: 0.6042\n",
      "Epoch 10/20\n",
      "1923/1923 [==============================] - 1000s 520ms/step - loss: 0.7734 - accuracy: 0.6607 - balanced_recall: 0.5466 - balanced_precision: 0.3563 - balanced_f1_score: 0.4300 - auc_roc: 0.5868 - val_loss: 0.7100 - val_accuracy: 0.7051 - val_balanced_recall: 0.5353 - val_balanced_precision: 0.3384 - val_balanced_f1_score: 0.4134 - val_auc_roc: 0.6063\n",
      "Epoch 11/20\n",
      "1923/1923 [==============================] - 992s 516ms/step - loss: 0.7602 - accuracy: 0.6665 - balanced_recall: 0.5568 - balanced_precision: 0.3572 - balanced_f1_score: 0.4336 - auc_roc: 0.5867 - val_loss: 0.7358 - val_accuracy: 0.6953 - val_balanced_recall: 0.4929 - val_balanced_precision: 0.3440 - val_balanced_f1_score: 0.4038 - val_auc_roc: 0.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 933s 473ms/step - loss: 1.0543 - accuracy: 0.4937 - balanced_recall: 0.6870 - balanced_precision: 0.4115 - balanced_f1_score: 0.5126 - auc_roc: 0.6441 - val_loss: 0.7787 - val_accuracy: 0.6594 - val_balanced_recall: 0.7393 - val_balanced_precision: 0.5925 - val_balanced_f1_score: 0.6569 - val_auc_roc: 0.8111\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 1024s 533ms/step - loss: 0.8444 - accuracy: 0.6271 - balanced_recall: 0.7158 - balanced_precision: 0.5029 - balanced_f1_score: 0.5897 - auc_roc: 0.7572 - val_loss: 0.7199 - val_accuracy: 0.7010 - val_balanced_recall: 0.7704 - val_balanced_precision: 0.6205 - val_balanced_f1_score: 0.6868 - val_auc_roc: 0.8448\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 1024s 533ms/step - loss: 0.7781 - accuracy: 0.6664 - balanced_recall: 0.7388 - balanced_precision: 0.5257 - balanced_f1_score: 0.6132 - auc_roc: 0.7848 - val_loss: 0.7153 - val_accuracy: 0.6984 - val_balanced_recall: 0.8003 - val_balanced_precision: 0.6357 - val_balanced_f1_score: 0.7081 - val_auc_roc: 0.8512\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 967s 503ms/step - loss: 0.7511 - accuracy: 0.6828 - balanced_recall: 0.7322 - balanced_precision: 0.5356 - balanced_f1_score: 0.6175 - auc_roc: 0.7935 - val_loss: 0.7197 - val_accuracy: 0.6958 - val_balanced_recall: 0.7856 - val_balanced_precision: 0.6410 - val_balanced_f1_score: 0.7055 - val_auc_roc: 0.8504\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 900s 468ms/step - loss: 0.6789 - accuracy: 0.7143 - balanced_recall: 0.7397 - balanced_precision: 0.5532 - balanced_f1_score: 0.6317 - auc_roc: 0.8110 - val_loss: 0.7873 - val_accuracy: 0.6885 - val_balanced_recall: 0.7776 - val_balanced_precision: 0.6175 - val_balanced_f1_score: 0.6879 - val_auc_roc: 0.8390\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 904s 470ms/step - loss: 0.6138 - accuracy: 0.7447 - balanced_recall: 0.7446 - balanced_precision: 0.5672 - balanced_f1_score: 0.6426 - auc_roc: 0.8251 - val_loss: 0.7776 - val_accuracy: 0.6875 - val_balanced_recall: 0.7395 - val_balanced_precision: 0.6437 - val_balanced_f1_score: 0.6876 - val_auc_roc: 0.8376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1923/1923 [==============================] - 989s 503ms/step - loss: 1.1270 - accuracy: 0.4058 - balanced_recall: 0.6336 - balanced_precision: 0.3527 - balanced_f1_score: 0.4519 - auc_roc: 0.5527 - val_loss: 0.9304 - val_accuracy: 0.5632 - val_balanced_recall: 0.8081 - val_balanced_precision: 0.4196 - val_balanced_f1_score: 0.5513 - val_auc_roc: 0.7003\n",
      "Epoch 2/20\n",
      "1923/1923 [==============================] - 1014s 527ms/step - loss: 0.9893 - accuracy: 0.5074 - balanced_recall: 0.6663 - balanced_precision: 0.3903 - balanced_f1_score: 0.4911 - auc_roc: 0.6319 - val_loss: 0.8254 - val_accuracy: 0.6256 - val_balanced_recall: 0.7824 - val_balanced_precision: 0.5434 - val_balanced_f1_score: 0.6406 - val_auc_roc: 0.7565\n",
      "Epoch 3/20\n",
      "1923/1923 [==============================] - 1027s 534ms/step - loss: 0.9311 - accuracy: 0.5612 - balanced_recall: 0.6405 - balanced_precision: 0.4132 - balanced_f1_score: 0.5008 - auc_roc: 0.6603 - val_loss: 0.7914 - val_accuracy: 0.6464 - val_balanced_recall: 0.7548 - val_balanced_precision: 0.5833 - val_balanced_f1_score: 0.6570 - val_auc_roc: 0.7645\n",
      "Epoch 4/20\n",
      "1923/1923 [==============================] - 977s 508ms/step - loss: 0.8949 - accuracy: 0.5876 - balanced_recall: 0.6409 - balanced_precision: 0.4263 - balanced_f1_score: 0.5106 - auc_roc: 0.6766 - val_loss: 0.7543 - val_accuracy: 0.6817 - val_balanced_recall: 0.7749 - val_balanced_precision: 0.5930 - val_balanced_f1_score: 0.6712 - val_auc_roc: 0.7731\n",
      "Epoch 5/20\n",
      "1923/1923 [==============================] - 967s 503ms/step - loss: 0.8623 - accuracy: 0.6147 - balanced_recall: 0.6626 - balanced_precision: 0.4331 - balanced_f1_score: 0.5223 - auc_roc: 0.6880 - val_loss: 0.7281 - val_accuracy: 0.6927 - val_balanced_recall: 0.7638 - val_balanced_precision: 0.5920 - val_balanced_f1_score: 0.6660 - val_auc_roc: 0.7745\n",
      "Epoch 6/20\n",
      "1923/1923 [==============================] - 943s 491ms/step - loss: 0.8378 - accuracy: 0.6278 - balanced_recall: 0.6522 - balanced_precision: 0.4368 - balanced_f1_score: 0.5216 - auc_roc: 0.6922 - val_loss: 0.7212 - val_accuracy: 0.6958 - val_balanced_recall: 0.7833 - val_balanced_precision: 0.5864 - val_balanced_f1_score: 0.6698 - val_auc_roc: 0.7692\n",
      "Epoch 7/20\n",
      "1923/1923 [==============================] - 961s 500ms/step - loss: 0.8240 - accuracy: 0.6357 - balanced_recall: 0.6525 - balanced_precision: 0.4384 - balanced_f1_score: 0.5230 - auc_roc: 0.6947 - val_loss: 0.7139 - val_accuracy: 0.7036 - val_balanced_recall: 0.7711 - val_balanced_precision: 0.5737 - val_balanced_f1_score: 0.6565 - val_auc_roc: 0.7742\n",
      "Epoch 8/20\n",
      "1923/1923 [==============================] - 964s 501ms/step - loss: 0.8076 - accuracy: 0.6452 - balanced_recall: 0.6568 - balanced_precision: 0.4412 - balanced_f1_score: 0.5262 - auc_roc: 0.6992 - val_loss: 0.7058 - val_accuracy: 0.7088 - val_balanced_recall: 0.7359 - val_balanced_precision: 0.5931 - val_balanced_f1_score: 0.6556 - val_auc_roc: 0.7749\n",
      "Epoch 9/20\n",
      "1923/1923 [==============================] - 980s 510ms/step - loss: 0.8223 - accuracy: 0.6352 - balanced_recall: 0.6456 - balanced_precision: 0.4344 - balanced_f1_score: 0.5176 - auc_roc: 0.6879 - val_loss: 0.7181 - val_accuracy: 0.6989 - val_balanced_recall: 0.7591 - val_balanced_precision: 0.5840 - val_balanced_f1_score: 0.6587 - val_auc_roc: 0.7701\n",
      "Epoch 10/20\n",
      "1923/1923 [==============================] - 1014s 527ms/step - loss: 0.7891 - accuracy: 0.6528 - balanced_recall: 0.6332 - balanced_precision: 0.4440 - balanced_f1_score: 0.5203 - auc_roc: 0.6963 - val_loss: 0.7040 - val_accuracy: 0.7140 - val_balanced_recall: 0.7286 - val_balanced_precision: 0.5945 - val_balanced_f1_score: 0.6536 - val_auc_roc: 0.7645\n",
      "Epoch 11/20\n",
      "1923/1923 [==============================] - 964s 501ms/step - loss: 0.7513 - accuracy: 0.6728 - balanced_recall: 0.6481 - balanced_precision: 0.4528 - balanced_f1_score: 0.5314 - auc_roc: 0.7068 - val_loss: 0.7071 - val_accuracy: 0.7129 - val_balanced_recall: 0.7525 - val_balanced_precision: 0.5903 - val_balanced_f1_score: 0.6605 - val_auc_roc: 0.7698\n",
      "Epoch 12/20\n",
      "1923/1923 [==============================] - 956s 497ms/step - loss: 0.7110 - accuracy: 0.6956 - balanced_recall: 0.6399 - balanced_precision: 0.4635 - balanced_f1_score: 0.5358 - auc_roc: 0.7169 - val_loss: 0.7196 - val_accuracy: 0.7041 - val_balanced_recall: 0.7210 - val_balanced_precision: 0.5904 - val_balanced_f1_score: 0.6482 - val_auc_roc: 0.7671\n",
      "Epoch 13/20\n",
      "1923/1923 [==============================] - 1012s 526ms/step - loss: 0.6454 - accuracy: 0.7261 - balanced_recall: 0.6413 - balanced_precision: 0.4764 - balanced_f1_score: 0.5447 - auc_roc: 0.7305 - val_loss: 0.7619 - val_accuracy: 0.6927 - val_balanced_recall: 0.6858 - val_balanced_precision: 0.6036 - val_balanced_f1_score: 0.6402 - val_auc_roc: 0.7614\n",
      "Wall time: 13h 57min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# original data set\n",
    "Accuracy_orig, Macro_F1_orig, ROC_AUC_orig, metrics_orig = fine_tune_BERT(X_train_orig, X_dev_orig, X_test_orig, \n",
    "                                                            y_train_orig, y_dev_orig, y_test_orig, \n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)\n",
    "\n",
    "# augmented with sr = 0.1\n",
    "Accuracy_aug_sr, Macro_F1_aug_sr, ROC_AUC_aug_sr, metrics_sr = fine_tune_BERT(X_train_aug_sr, X_dev_aug_sr, X_test_aug_sr, \n",
    "                                                            y_train_aug_sr, y_dev_orig, y_test_orig, \n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)\n",
    "\n",
    "# augmented with ri = 0.1\n",
    "Accuracy_aug_ri, Macro_F1_aug_ri, ROC_AUC_aug_ri, metrics_ri = fine_tune_BERT(X_train_aug_ri, X_dev_aug_ri, X_test_aug_ri, \n",
    "                                                            y_train_aug_ri, y_dev_orig, y_test_orig, \n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)\n",
    "\n",
    "# augmented with rs = 0.1\n",
    "Accuracy_aug_rs, Macro_F1_aug_rs, ROC_AUC_aug_rs, metrics_rs = fine_tune_BERT(X_train_aug_rs, X_dev_aug_rs, X_test_aug_rs, \n",
    "                                                            y_train_aug_rs, y_dev_orig, y_test_orig, \n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)\n",
    "\n",
    "# augmented with rd = 0.1\n",
    "Accuracy_aug_rd, Macro_F1_aug_rd, ROC_AUC_aug_rd, metrics_rd = fine_tune_BERT(X_train_aug_rd, X_dev_aug_rd, X_test_aug_rd, \n",
    "                                                            y_train_aug_rd, y_dev_orig, y_test_orig,\n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)\n",
    "\n",
    "# augmented with all = 0.1\n",
    "Accuracy_aug_all_1, Macro_F1_aug_all_1, ROC_AUC_aug_all_1, metrics_all_1 = fine_tune_BERT(X_train_all_1, X_dev_all_1, X_test_all_1, \n",
    "                                                            y_train_all_1, y_dev_orig, y_test_orig, \n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)\n",
    "\n",
    "# augmented with all = 0.5\n",
    "Accuracy_aug_all_5, Macro_F1_aug_all_5, ROC_AUC_aug_all_5, metrics_all_5 = fine_tune_BERT(X_train_all_5, X_dev_all_5, X_test_all_5, \n",
    "                                                            y_train_all_5, y_dev_orig, y_test_orig, \n",
    "                                                            learning_rate = 5e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 20, batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6609464378575143,\n",
       " 0.6319246919999925,\n",
       " 0.7326758982835102,\n",
       " {'loss': [1.414437174797058,\n",
       "   1.2325364351272583,\n",
       "   1.13459050655365,\n",
       "   1.130818486213684,\n",
       "   1.0874961614608765,\n",
       "   1.0560382604599,\n",
       "   1.0214968919754028,\n",
       "   0.9854006767272949,\n",
       "   0.9597710967063904,\n",
       "   0.9445297122001648,\n",
       "   1.0980370044708252,\n",
       "   1.0452228784561157,\n",
       "   0.981499969959259,\n",
       "   0.9482216238975525,\n",
       "   0.9320251941680908,\n",
       "   0.9102798104286194,\n",
       "   0.8996171355247498,\n",
       "   0.8778436779975891,\n",
       "   0.8663511872291565,\n",
       "   0.8538827896118164],\n",
       "  'accuracy': [0.37924981117248535,\n",
       "   0.40310731530189514,\n",
       "   0.42709484696388245,\n",
       "   0.4508223235607147,\n",
       "   0.4779301881790161,\n",
       "   0.48833128809928894,\n",
       "   0.510498583316803,\n",
       "   0.5326659083366394,\n",
       "   0.5521679520606995,\n",
       "   0.5612689256668091,\n",
       "   0.5004875659942627,\n",
       "   0.5054280757904053,\n",
       "   0.5413768291473389,\n",
       "   0.5581486225128174,\n",
       "   0.5746603608131409,\n",
       "   0.5830461978912354,\n",
       "   0.5898719429969788,\n",
       "   0.6011180877685547,\n",
       "   0.6129493713378906,\n",
       "   0.6200351119041443],\n",
       "  'balanced_recall': [0.5305141806602478,\n",
       "   0.5037591457366943,\n",
       "   0.4752684533596039,\n",
       "   0.5628207325935364,\n",
       "   0.5928968191146851,\n",
       "   0.5687585473060608,\n",
       "   0.6196597218513489,\n",
       "   0.6590510606765747,\n",
       "   0.6678144335746765,\n",
       "   0.676145076751709,\n",
       "   0.6072837710380554,\n",
       "   0.6280187964439392,\n",
       "   0.6691320538520813,\n",
       "   0.6889703869819641,\n",
       "   0.6978197693824768,\n",
       "   0.7154741883277893,\n",
       "   0.709929347038269,\n",
       "   0.7289432287216187,\n",
       "   0.7353103756904602,\n",
       "   0.7384868264198303],\n",
       "  'balanced_precision': [0.3510968089103699,\n",
       "   0.3696170151233673,\n",
       "   0.3952430784702301,\n",
       "   0.4003330171108246,\n",
       "   0.4177340269088745,\n",
       "   0.43157774209976196,\n",
       "   0.4464920461177826,\n",
       "   0.45983943343162537,\n",
       "   0.47726303339004517,\n",
       "   0.4866858124732971,\n",
       "   0.4363586902618408,\n",
       "   0.4334218502044678,\n",
       "   0.46993377804756165,\n",
       "   0.483532577753067,\n",
       "   0.4925445318222046,\n",
       "   0.5040770173072815,\n",
       "   0.5094095468521118,\n",
       "   0.5163082480430603,\n",
       "   0.5191746354103088,\n",
       "   0.5243048667907715],\n",
       "  'balanced_f1_score': [0.42190903425216675,\n",
       "   0.42570337653160095,\n",
       "   0.43051907420158386,\n",
       "   0.46644681692123413,\n",
       "   0.48929136991500854,\n",
       "   0.4898035228252411,\n",
       "   0.5181771516799927,\n",
       "   0.5410463213920593,\n",
       "   0.5558457970619202,\n",
       "   0.5651957392692566,\n",
       "   0.5066293478012085,\n",
       "   0.5122105479240417,\n",
       "   0.5513628125190735,\n",
       "   0.5674872994422913,\n",
       "   0.5765950083732605,\n",
       "   0.5907091498374939,\n",
       "   0.5923346877098083,\n",
       "   0.6035486459732056,\n",
       "   0.6078922152519226,\n",
       "   0.6124083995819092],\n",
       "  'auc_roc': [0.5436034798622131,\n",
       "   0.563521683216095,\n",
       "   0.5888548493385315,\n",
       "   0.6104918718338013,\n",
       "   0.6395410895347595,\n",
       "   0.6522970795631409,\n",
       "   0.6770181059837341,\n",
       "   0.7012124061584473,\n",
       "   0.7174274325370789,\n",
       "   0.729079008102417,\n",
       "   0.6570261716842651,\n",
       "   0.6644488573074341,\n",
       "   0.7081659436225891,\n",
       "   0.7262471914291382,\n",
       "   0.7384495735168457,\n",
       "   0.7501387596130371,\n",
       "   0.7555396556854248,\n",
       "   0.768138587474823,\n",
       "   0.774825930595398,\n",
       "   0.7802315354347229],\n",
       "  'val_loss': [1.063222050666809,\n",
       "   1.0098096132278442,\n",
       "   0.9624096155166626,\n",
       "   0.926771879196167,\n",
       "   0.8802525997161865,\n",
       "   0.8726146221160889,\n",
       "   0.8460701107978821,\n",
       "   0.8291119933128357,\n",
       "   0.8180981874465942,\n",
       "   0.8065207004547119,\n",
       "   0.9060344099998474,\n",
       "   0.8235667943954468,\n",
       "   0.7998805642127991,\n",
       "   0.7921160459518433,\n",
       "   0.7845783829689026,\n",
       "   0.7769659757614136,\n",
       "   0.7667956948280334,\n",
       "   0.7570348381996155,\n",
       "   0.7537350654602051,\n",
       "   0.7486427426338196],\n",
       "  'val_accuracy': [0.46489858627319336,\n",
       "   0.5267810821533203,\n",
       "   0.5481019020080566,\n",
       "   0.5699427723884583,\n",
       "   0.6125845313072205,\n",
       "   0.6068642735481262,\n",
       "   0.6209048628807068,\n",
       "   0.6422256827354431,\n",
       "   0.6370254755020142,\n",
       "   0.6505460143089294,\n",
       "   0.6183047294616699,\n",
       "   0.6370254755020142,\n",
       "   0.6531461477279663,\n",
       "   0.6588663458824158,\n",
       "   0.6625065207481384,\n",
       "   0.6713468432426453,\n",
       "   0.6781071424484253,\n",
       "   0.6791471838951111,\n",
       "   0.6770671010017395,\n",
       "   0.6833073496818542],\n",
       "  'val_balanced_recall': [0.5312702059745789,\n",
       "   0.519578218460083,\n",
       "   0.5407702922821045,\n",
       "   0.6686446070671082,\n",
       "   0.6611811518669128,\n",
       "   0.7069867849349976,\n",
       "   0.7489422559738159,\n",
       "   0.7250409722328186,\n",
       "   0.7560570240020752,\n",
       "   0.7412675023078918,\n",
       "   0.6519976258277893,\n",
       "   0.7170969247817993,\n",
       "   0.7556759715080261,\n",
       "   0.7437395453453064,\n",
       "   0.7889867424964905,\n",
       "   0.7998939156532288,\n",
       "   0.7820422649383545,\n",
       "   0.8012211322784424,\n",
       "   0.7898840308189392,\n",
       "   0.8148373961448669],\n",
       "  'val_balanced_precision': [0.4096512794494629,\n",
       "   0.47529077529907227,\n",
       "   0.5113264322280884,\n",
       "   0.490511953830719,\n",
       "   0.5321881175041199,\n",
       "   0.5333008170127869,\n",
       "   0.5401654839515686,\n",
       "   0.5545647144317627,\n",
       "   0.5566461086273193,\n",
       "   0.5662134289741516,\n",
       "   0.5607092976570129,\n",
       "   0.5834388732910156,\n",
       "   0.5678843259811401,\n",
       "   0.5922515988349915,\n",
       "   0.5670536160469055,\n",
       "   0.5723111033439636,\n",
       "   0.5813804864883423,\n",
       "   0.5811980366706848,\n",
       "   0.5899098515510559,\n",
       "   0.584894061088562],\n",
       "  'val_balanced_f1_score': [0.4614778459072113,\n",
       "   0.49495255947113037,\n",
       "   0.5243185758590698,\n",
       "   0.5653783679008484,\n",
       "   0.589029848575592,\n",
       "   0.6065234541893005,\n",
       "   0.6269509792327881,\n",
       "   0.627915620803833,\n",
       "   0.6407073736190796,\n",
       "   0.6416234970092773,\n",
       "   0.6012503504753113,\n",
       "   0.6425275206565857,\n",
       "   0.6479559540748596,\n",
       "   0.6589592099189758,\n",
       "   0.6595087051391602,\n",
       "   0.6669070720672607,\n",
       "   0.6665875315666199,\n",
       "   0.6733022928237915,\n",
       "   0.6749357581138611,\n",
       "   0.6805369853973389],\n",
       "  'val_auc_roc': [0.6253710985183716,\n",
       "   0.6696575880050659,\n",
       "   0.7264331579208374,\n",
       "   0.7387948036193848,\n",
       "   0.7749848961830139,\n",
       "   0.7811866998672485,\n",
       "   0.7981998920440674,\n",
       "   0.8081774711608887,\n",
       "   0.8135595917701721,\n",
       "   0.8218651413917542,\n",
       "   0.769684374332428,\n",
       "   0.8100413084030151,\n",
       "   0.821062445640564,\n",
       "   0.8249642848968506,\n",
       "   0.8267428278923035,\n",
       "   0.831516444683075,\n",
       "   0.8358442783355713,\n",
       "   0.8394848704338074,\n",
       "   0.841029167175293,\n",
       "   0.8436336517333984]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_orig, Macro_F1_orig, ROC_AUC_orig, metrics_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6703068122724909,\n",
       " 0.6538685661420338,\n",
       " 0.7450707431347788,\n",
       " {'loss': [1.1054279804229736,\n",
       "   0.9279928207397461,\n",
       "   0.8564785718917847,\n",
       "   0.8107340931892395,\n",
       "   0.7710567116737366,\n",
       "   0.7259699702262878,\n",
       "   0.6634292006492615],\n",
       "  'accuracy': [0.4498472213745117,\n",
       "   0.5655810236930847,\n",
       "   0.6128085255622864,\n",
       "   0.6387462615966797,\n",
       "   0.6589092016220093,\n",
       "   0.6806864738464355,\n",
       "   0.7096686959266663],\n",
       "  'balanced_recall': [0.4705999493598938,\n",
       "   0.5378668308258057,\n",
       "   0.6412853002548218,\n",
       "   0.6750226020812988,\n",
       "   0.6892650127410889,\n",
       "   0.7149829864501953,\n",
       "   0.7492078542709351],\n",
       "  'balanced_precision': [0.409149706363678,\n",
       "   0.48599928617477417,\n",
       "   0.4892413914203644,\n",
       "   0.49492835998535156,\n",
       "   0.5056651830673218,\n",
       "   0.5193694829940796,\n",
       "   0.5352498888969421],\n",
       "  'balanced_f1_score': [0.43542370200157166,\n",
       "   0.5083931088447571,\n",
       "   0.5535715818405151,\n",
       "   0.5698105692863464,\n",
       "   0.5818925499916077,\n",
       "   0.6002241969108582,\n",
       "   0.6231601238250732],\n",
       "  'auc_roc': [0.6076003313064575,\n",
       "   0.7021828889846802,\n",
       "   0.7278401255607605,\n",
       "   0.734996497631073,\n",
       "   0.7448707818984985,\n",
       "   0.7618610858917236,\n",
       "   0.7839392423629761],\n",
       "  'val_loss': [0.8142868280410767,\n",
       "   0.7541282176971436,\n",
       "   0.7188167572021484,\n",
       "   0.7085944414138794,\n",
       "   0.7284834980964661,\n",
       "   0.7310092449188232,\n",
       "   0.8332071900367737],\n",
       "  'val_accuracy': [0.6469058990478516,\n",
       "   0.6749870181083679,\n",
       "   0.6963078379631042,\n",
       "   0.7035881280899048,\n",
       "   0.6931877136230469,\n",
       "   0.7035881280899048,\n",
       "   0.6890275478363037],\n",
       "  'val_balanced_recall': [0.5636148452758789,\n",
       "   0.6564643383026123,\n",
       "   0.7355085611343384,\n",
       "   0.7655977010726929,\n",
       "   0.78525310754776,\n",
       "   0.7736219167709351,\n",
       "   0.7646469473838806],\n",
       "  'val_balanced_precision': [0.6658823490142822,\n",
       "   0.6226708889007568,\n",
       "   0.5765248537063599,\n",
       "   0.5761401653289795,\n",
       "   0.5723255276679993,\n",
       "   0.5766509175300598,\n",
       "   0.5828589200973511],\n",
       "  'val_balanced_f1_score': [0.6084133386611938,\n",
       "   0.6384301781654358,\n",
       "   0.6458807587623596,\n",
       "   0.6571536064147949,\n",
       "   0.6617081761360168,\n",
       "   0.660226047039032,\n",
       "   0.6609829068183899],\n",
       "  'val_auc_roc': [0.8154221177101135,\n",
       "   0.8205361366271973,\n",
       "   0.8121747970581055,\n",
       "   0.7964485287666321,\n",
       "   0.7973989248275757,\n",
       "   0.8101403713226318,\n",
       "   0.8074585795402527]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_aug_sr, Macro_F1_aug_sr, ROC_AUC_aug_sr, metrics_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6448257930317213,\n",
       " 0.5888863055619634,\n",
       " 0.7136823288681992,\n",
       " {'loss': [0.9977815747261047,\n",
       "   0.848426342010498,\n",
       "   0.7991135716438293,\n",
       "   0.7769655585289001,\n",
       "   0.7588010430335999,\n",
       "   0.7368476390838623,\n",
       "   0.711444616317749],\n",
       "  'accuracy': [0.5153090953826904,\n",
       "   0.6095581650733948,\n",
       "   0.6384970545768738,\n",
       "   0.6512166857719421,\n",
       "   0.662029504776001,\n",
       "   0.6740015745162964,\n",
       "   0.6886281371116638],\n",
       "  'balanced_recall': [0.7195204496383667,\n",
       "   0.7729053497314453,\n",
       "   0.7849979996681213,\n",
       "   0.7913492918014526,\n",
       "   0.7885153889656067,\n",
       "   0.7843513488769531,\n",
       "   0.7920415997505188],\n",
       "  'balanced_precision': [0.3967333734035492,\n",
       "   0.4356802999973297,\n",
       "   0.4325752258300781,\n",
       "   0.4377046823501587,\n",
       "   0.4441376328468323,\n",
       "   0.4495792090892792,\n",
       "   0.45542436838150024],\n",
       "  'balanced_f1_score': [0.5104688405990601,\n",
       "   0.5563392639160156,\n",
       "   0.556854248046875,\n",
       "   0.5626671314239502,\n",
       "   0.5672370195388794,\n",
       "   0.5705582499504089,\n",
       "   0.5773205757141113],\n",
       "  'auc_roc': [0.6407245993614197,\n",
       "   0.7071360945701599,\n",
       "   0.7040086388587952,\n",
       "   0.7078578472137451,\n",
       "   0.7133249640464783,\n",
       "   0.7197328209877014,\n",
       "   0.7267161011695862],\n",
       "  'val_loss': [0.7880556583404541,\n",
       "   0.7519842982292175,\n",
       "   0.7525835633277893,\n",
       "   0.7455452680587769,\n",
       "   0.7459281086921692,\n",
       "   0.7624186277389526,\n",
       "   0.759226381778717],\n",
       "  'val_accuracy': [0.6307852268218994,\n",
       "   0.6500260233879089,\n",
       "   0.6583463549613953,\n",
       "   0.67758709192276,\n",
       "   0.6791471838951111,\n",
       "   0.6905876398086548,\n",
       "   0.7004680037498474],\n",
       "  'val_balanced_recall': [0.884430468082428,\n",
       "   0.9001567959785461,\n",
       "   0.9130533933639526,\n",
       "   0.9063422083854675,\n",
       "   0.8730539679527283,\n",
       "   0.8863604664802551,\n",
       "   0.9040671586990356],\n",
       "  'val_balanced_precision': [0.5119383335113525,\n",
       "   0.5063710808753967,\n",
       "   0.4836919903755188,\n",
       "   0.49008095264434814,\n",
       "   0.48381224274635315,\n",
       "   0.4832310676574707,\n",
       "   0.4698430001735687],\n",
       "  'val_balanced_f1_score': [0.6479243040084839,\n",
       "   0.6474575400352478,\n",
       "   0.6318023204803467,\n",
       "   0.6353793144226074,\n",
       "   0.6218888163566589,\n",
       "   0.6245530843734741,\n",
       "   0.6176379919052124],\n",
       "  'val_auc_roc': [0.8139263987541199,\n",
       "   0.7842462062835693,\n",
       "   0.7739771604537964,\n",
       "   0.7648097276687622,\n",
       "   0.7699649333953857,\n",
       "   0.7754572629928589,\n",
       "   0.7820668816566467]})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_aug_ri, Macro_F1_aug_ri, ROC_AUC_aug_ri, metrics_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6775871034841394,\n",
       " 0.6542451466652167,\n",
       " 0.7465263218765769,\n",
       " {'loss': [1.0660706758499146,\n",
       "   0.8527681827545166,\n",
       "   0.7865257859230042,\n",
       "   0.7437723875045776,\n",
       "   0.7178320288658142,\n",
       "   0.6820753812789917],\n",
       "  'accuracy': [0.47251296043395996,\n",
       "   0.6175540089607239,\n",
       "   0.6562764048576355,\n",
       "   0.6796788573265076,\n",
       "   0.6960497498512268,\n",
       "   0.7139157652854919],\n",
       "  'balanced_recall': [0.6313719749450684,\n",
       "   0.7743516564369202,\n",
       "   0.8015339374542236,\n",
       "   0.8229678869247437,\n",
       "   0.8323614001274109,\n",
       "   0.8414154648780823],\n",
       "  'balanced_precision': [0.3908116817474365,\n",
       "   0.448280394077301,\n",
       "   0.46522659063339233,\n",
       "   0.47511905431747437,\n",
       "   0.48521748185157776,\n",
       "   0.4926108121871948],\n",
       "  'balanced_f1_score': [0.4816170334815979,\n",
       "   0.5669378638267517,\n",
       "   0.5878910422325134,\n",
       "   0.601685106754303,\n",
       "   0.6122819185256958,\n",
       "   0.6206327080726624],\n",
       "  'auc_roc': [0.6162319183349609,\n",
       "   0.7302096486091614,\n",
       "   0.7563493251800537,\n",
       "   0.7717620730400085,\n",
       "   0.7827745676040649,\n",
       "   0.7944461703300476],\n",
       "  'val_loss': [0.7939391136169434,\n",
       "   0.7203681468963623,\n",
       "   0.7011656761169434,\n",
       "   0.71066814661026,\n",
       "   0.7132619023323059,\n",
       "   0.7320969104766846],\n",
       "  'val_accuracy': [0.672386884689331,\n",
       "   0.6963078379631042,\n",
       "   0.7030681371688843,\n",
       "   0.7072283029556274,\n",
       "   0.7082683444023132,\n",
       "   0.7004680037498474],\n",
       "  'val_balanced_recall': [0.8747625350952148,\n",
       "   0.9062836170196533,\n",
       "   0.9173181056976318,\n",
       "   0.8962506651878357,\n",
       "   0.8932191133499146,\n",
       "   0.899343729019165],\n",
       "  'val_balanced_precision': [0.4980570077896118,\n",
       "   0.5098723769187927,\n",
       "   0.5078673958778381,\n",
       "   0.5380670428276062,\n",
       "   0.5246984362602234,\n",
       "   0.5221368074417114],\n",
       "  'val_balanced_f1_score': [0.634060263633728,\n",
       "   0.6521931886672974,\n",
       "   0.6533174514770508,\n",
       "   0.6718876957893372,\n",
       "   0.6606809496879578,\n",
       "   0.6603093147277832],\n",
       "  'val_auc_roc': [0.8164656162261963,\n",
       "   0.8441405296325684,\n",
       "   0.853141725063324,\n",
       "   0.8535165190696716,\n",
       "   0.8517760038375854,\n",
       "   0.8472248911857605]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_aug_rs, Macro_F1_aug_rs, ROC_AUC_aug_rs, metrics_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6734269370774831,\n",
       " 0.6482129102106291,\n",
       " 0.7407903276343201,\n",
       " {'loss': [1.1635398864746094,\n",
       "   1.0358493328094482,\n",
       "   1.128196358680725,\n",
       "   0.9664922952651978,\n",
       "   0.8705714344978333,\n",
       "   0.8428657054901123,\n",
       "   0.8227418065071106,\n",
       "   0.802208423614502,\n",
       "   0.7920058369636536,\n",
       "   0.7733984589576721,\n",
       "   0.7601956725120544],\n",
       "  'accuracy': [0.3703330457210541,\n",
       "   0.46836334466934204,\n",
       "   0.39625993371009827,\n",
       "   0.5276170372962952,\n",
       "   0.605982780456543,\n",
       "   0.623599648475647,\n",
       "   0.6348024606704712,\n",
       "   0.6440117955207825,\n",
       "   0.6512817144393921,\n",
       "   0.6606968641281128,\n",
       "   0.6664716601371765],\n",
       "  'balanced_recall': [0.6582804918289185,\n",
       "   0.6761072874069214,\n",
       "   0.6070119142532349,\n",
       "   0.6166681051254272,\n",
       "   0.5802937746047974,\n",
       "   0.5663964748382568,\n",
       "   0.5621505379676819,\n",
       "   0.5638511776924133,\n",
       "   0.549810528755188,\n",
       "   0.5466416478157043,\n",
       "   0.5568165183067322],\n",
       "  'balanced_precision': [0.3352229595184326,\n",
       "   0.34241780638694763,\n",
       "   0.3367694616317749,\n",
       "   0.34790241718292236,\n",
       "   0.35342496633529663,\n",
       "   0.3545372188091278,\n",
       "   0.35674574971199036,\n",
       "   0.3577224612236023,\n",
       "   0.35693803429603577,\n",
       "   0.35630208253860474,\n",
       "   0.35715657472610474],\n",
       "  'balanced_f1_score': [0.4425354599952698,\n",
       "   0.4533190429210663,\n",
       "   0.43181827664375305,\n",
       "   0.44339120388031006,\n",
       "   0.4379136562347412,\n",
       "   0.43459126353263855,\n",
       "   0.435024231672287,\n",
       "   0.4363653063774109,\n",
       "   0.4313463270664215,\n",
       "   0.4300204813480377,\n",
       "   0.4336166977882385],\n",
       "  'auc_roc': [0.5157514810562134,\n",
       "   0.5411579608917236,\n",
       "   0.5205346345901489,\n",
       "   0.5530482530593872,\n",
       "   0.5768093466758728,\n",
       "   0.5819733142852783,\n",
       "   0.5857454538345337,\n",
       "   0.5859339833259583,\n",
       "   0.5866225361824036,\n",
       "   0.5867741703987122,\n",
       "   0.586747407913208],\n",
       "  'val_loss': [1.0606369972229004,\n",
       "   0.8329064846038818,\n",
       "   1.0864102840423584,\n",
       "   0.7519769668579102,\n",
       "   0.7591904997825623,\n",
       "   0.7232745289802551,\n",
       "   0.709935188293457,\n",
       "   0.7085176110267639,\n",
       "   0.7155709266662598,\n",
       "   0.7100246548652649,\n",
       "   0.7358348369598389],\n",
       "  'val_accuracy': [0.46697866916656494,\n",
       "   0.6437857747077942,\n",
       "   0.40613624453544617,\n",
       "   0.6817472577095032,\n",
       "   0.6703068017959595,\n",
       "   0.6916276812553406,\n",
       "   0.6989079713821411,\n",
       "   0.7020280957221985,\n",
       "   0.7015080451965332,\n",
       "   0.7051482200622559,\n",
       "   0.6952677965164185],\n",
       "  'val_balanced_recall': [0.7457166314125061,\n",
       "   0.6024320125579834,\n",
       "   1.0,\n",
       "   0.5379423499107361,\n",
       "   0.5569272041320801,\n",
       "   0.5462454557418823,\n",
       "   0.563247799873352,\n",
       "   0.5545321106910706,\n",
       "   0.5040528178215027,\n",
       "   0.5352966785430908,\n",
       "   0.4928933084011078],\n",
       "  'val_balanced_precision': [0.34103307127952576,\n",
       "   0.3383728265762329,\n",
       "   0.33333322405815125,\n",
       "   0.3372180163860321,\n",
       "   0.33328717947006226,\n",
       "   0.34660473465919495,\n",
       "   0.34275805950164795,\n",
       "   0.3394211232662201,\n",
       "   0.34017127752304077,\n",
       "   0.33843347430229187,\n",
       "   0.3440178334712982],\n",
       "  'val_balanced_f1_score': [0.46755096316337585,\n",
       "   0.4326210618019104,\n",
       "   0.4999999403953552,\n",
       "   0.41344186663627625,\n",
       "   0.4160996079444885,\n",
       "   0.42304912209510803,\n",
       "   0.4252060651779175,\n",
       "   0.4200739860534668,\n",
       "   0.4046364724636078,\n",
       "   0.413429319858551,\n",
       "   0.40375852584838867],\n",
       "  'val_auc_roc': [0.563033401966095,\n",
       "   0.6018533706665039,\n",
       "   0.5580203533172607,\n",
       "   0.6039579510688782,\n",
       "   0.6036527752876282,\n",
       "   0.6146678328514099,\n",
       "   0.6131887435913086,\n",
       "   0.6105414628982544,\n",
       "   0.6041663885116577,\n",
       "   0.6062847971916199,\n",
       "   0.5965418815612793]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_aug_rd, Macro_F1_aug_rd, ROC_AUC_aug_rd, metrics_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6692667706708268,\n",
       " 0.6651056681811542,\n",
       " 0.7508844564104412,\n",
       " {'loss': [1.0542728900909424,\n",
       "   0.8443873524665833,\n",
       "   0.7781355381011963,\n",
       "   0.7510735988616943,\n",
       "   0.6788820624351501,\n",
       "   0.6138486862182617],\n",
       "  'accuracy': [0.4936618208885193,\n",
       "   0.627055823802948,\n",
       "   0.666374146938324,\n",
       "   0.6828208565711975,\n",
       "   0.7142516374588013,\n",
       "   0.7447073459625244],\n",
       "  'balanced_recall': [0.6870146989822388,\n",
       "   0.7157942652702332,\n",
       "   0.7388201355934143,\n",
       "   0.7321839928627014,\n",
       "   0.7397295236587524,\n",
       "   0.74458247423172],\n",
       "  'balanced_precision': [0.411501944065094,\n",
       "   0.5028978586196899,\n",
       "   0.5256931185722351,\n",
       "   0.5356272459030151,\n",
       "   0.5532181859016418,\n",
       "   0.5672118067741394],\n",
       "  'balanced_f1_score': [0.5125657320022583,\n",
       "   0.5897437334060669,\n",
       "   0.6132490634918213,\n",
       "   0.6174566745758057,\n",
       "   0.6317146420478821,\n",
       "   0.6426250338554382],\n",
       "  'auc_roc': [0.6440902352333069,\n",
       "   0.7572376132011414,\n",
       "   0.784781813621521,\n",
       "   0.7935385704040527,\n",
       "   0.8110112547874451,\n",
       "   0.8251016139984131],\n",
       "  'val_loss': [0.7787374258041382,\n",
       "   0.7198883891105652,\n",
       "   0.7152785062789917,\n",
       "   0.7197138071060181,\n",
       "   0.787317156791687,\n",
       "   0.7776035070419312],\n",
       "  'val_accuracy': [0.659386396408081,\n",
       "   0.7009880542755127,\n",
       "   0.6983879208564758,\n",
       "   0.6957878470420837,\n",
       "   0.6885075569152832,\n",
       "   0.6874675154685974],\n",
       "  'val_balanced_recall': [0.7392504811286926,\n",
       "   0.7704437375068665,\n",
       "   0.8002674579620361,\n",
       "   0.7856400609016418,\n",
       "   0.7776323556900024,\n",
       "   0.7394835352897644],\n",
       "  'val_balanced_precision': [0.5925226807594299,\n",
       "   0.6204628348350525,\n",
       "   0.6357453465461731,\n",
       "   0.6410230994224548,\n",
       "   0.6174560785293579,\n",
       "   0.6437048316001892],\n",
       "  'val_balanced_f1_score': [0.6568601131439209,\n",
       "   0.6868483424186707,\n",
       "   0.7081219553947449,\n",
       "   0.7055338621139526,\n",
       "   0.6878902912139893,\n",
       "   0.6875863075256348],\n",
       "  'val_auc_roc': [0.8111099004745483,\n",
       "   0.8447576761245728,\n",
       "   0.8512426614761353,\n",
       "   0.8504380583763123,\n",
       "   0.8389981985092163,\n",
       "   0.8376273512840271]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_aug_all_1, Macro_F1_aug_all_1, ROC_AUC_aug_all_1, metrics_all_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6801872074882995,\n",
       " 0.6553712454377197,\n",
       " 0.748144649373535,\n",
       " {'loss': [1.1269656419754028,\n",
       "   0.9892517924308777,\n",
       "   0.9310850501060486,\n",
       "   0.8949293494224548,\n",
       "   0.8623104095458984,\n",
       "   0.8377537727355957,\n",
       "   0.8240257501602173,\n",
       "   0.8075839281082153,\n",
       "   0.8223223686218262,\n",
       "   0.7890941500663757,\n",
       "   0.7513064742088318,\n",
       "   0.7109605073928833,\n",
       "   0.6454113721847534],\n",
       "  'accuracy': [0.4057617783546448,\n",
       "   0.5073782801628113,\n",
       "   0.5612147450447083,\n",
       "   0.5876400470733643,\n",
       "   0.6147153973579407,\n",
       "   0.6277925968170166,\n",
       "   0.635680079460144,\n",
       "   0.645236074924469,\n",
       "   0.6352142095565796,\n",
       "   0.6527660489082336,\n",
       "   0.6727989912033081,\n",
       "   0.6956380605697632,\n",
       "   0.7260503768920898],\n",
       "  'balanced_recall': [0.6335519552230835,\n",
       "   0.6663182377815247,\n",
       "   0.6404587626457214,\n",
       "   0.6408832669258118,\n",
       "   0.6626099348068237,\n",
       "   0.6521501541137695,\n",
       "   0.6525240540504456,\n",
       "   0.65675288438797,\n",
       "   0.6455704569816589,\n",
       "   0.6332390308380127,\n",
       "   0.648090124130249,\n",
       "   0.639869749546051,\n",
       "   0.6412532329559326],\n",
       "  'balanced_precision': [0.3526622951030731,\n",
       "   0.3902851939201355,\n",
       "   0.41324159502983093,\n",
       "   0.4262876510620117,\n",
       "   0.4330786466598511,\n",
       "   0.4368284344673157,\n",
       "   0.4384339451789856,\n",
       "   0.44118306040763855,\n",
       "   0.4343588948249817,\n",
       "   0.4440406858921051,\n",
       "   0.4528435468673706,\n",
       "   0.46352896094322205,\n",
       "   0.47635555267333984],\n",
       "  'balanced_f1_score': [0.45194029808044434,\n",
       "   0.4911309778690338,\n",
       "   0.5007643699645996,\n",
       "   0.510550856590271,\n",
       "   0.5223405957221985,\n",
       "   0.5216230154037476,\n",
       "   0.5229600071907043,\n",
       "   0.5262272357940674,\n",
       "   0.517612874507904,\n",
       "   0.5203015804290771,\n",
       "   0.5314065217971802,\n",
       "   0.5358222126960754,\n",
       "   0.5447345972061157],\n",
       "  'auc_roc': [0.5527286529541016,\n",
       "   0.6319282054901123,\n",
       "   0.6602522730827332,\n",
       "   0.6766284704208374,\n",
       "   0.6879960298538208,\n",
       "   0.6921629309654236,\n",
       "   0.6947306394577026,\n",
       "   0.699220597743988,\n",
       "   0.6879487037658691,\n",
       "   0.6963071823120117,\n",
       "   0.7068457007408142,\n",
       "   0.716878354549408,\n",
       "   0.7305365204811096],\n",
       "  'val_loss': [0.9304162859916687,\n",
       "   0.8253703713417053,\n",
       "   0.7913828492164612,\n",
       "   0.7543250918388367,\n",
       "   0.7281466722488403,\n",
       "   0.7211687564849854,\n",
       "   0.7138577699661255,\n",
       "   0.7058225870132446,\n",
       "   0.7181218862533569,\n",
       "   0.7039891481399536,\n",
       "   0.7070800065994263,\n",
       "   0.7195740342140198,\n",
       "   0.7618501782417297],\n",
       "  'val_accuracy': [0.563182532787323,\n",
       "   0.6255850195884705,\n",
       "   0.6463858485221863,\n",
       "   0.6817472577095032,\n",
       "   0.6926677227020264,\n",
       "   0.6957878470420837,\n",
       "   0.7035881280899048,\n",
       "   0.7087883353233337,\n",
       "   0.6989079713821411,\n",
       "   0.7139885425567627,\n",
       "   0.7129485011100769,\n",
       "   0.7041081786155701,\n",
       "   0.6926677227020264],\n",
       "  'val_balanced_recall': [0.8080614805221558,\n",
       "   0.7823648452758789,\n",
       "   0.7547867894172668,\n",
       "   0.7749412655830383,\n",
       "   0.7637816667556763,\n",
       "   0.7833102345466614,\n",
       "   0.7711179256439209,\n",
       "   0.7359342575073242,\n",
       "   0.7591301202774048,\n",
       "   0.7285996079444885,\n",
       "   0.7524983882904053,\n",
       "   0.7209647297859192,\n",
       "   0.6858296990394592],\n",
       "  'val_balanced_precision': [0.41964033246040344,\n",
       "   0.5433614253997803,\n",
       "   0.5833263993263245,\n",
       "   0.5930306315422058,\n",
       "   0.5920254588127136,\n",
       "   0.5863509178161621,\n",
       "   0.5736548900604248,\n",
       "   0.5930830240249634,\n",
       "   0.5840364098548889,\n",
       "   0.5945272445678711,\n",
       "   0.5903161764144897,\n",
       "   0.5903730988502502,\n",
       "   0.6035869121551514],\n",
       "  'val_balanced_f1_score': [0.5513038039207458,\n",
       "   0.6406064629554749,\n",
       "   0.6569753885269165,\n",
       "   0.6712192296981812,\n",
       "   0.6659992337226868,\n",
       "   0.669771671295166,\n",
       "   0.6565482020378113,\n",
       "   0.6555854678153992,\n",
       "   0.6587048172950745,\n",
       "   0.6536240577697754,\n",
       "   0.6605388522148132,\n",
       "   0.6482000350952148,\n",
       "   0.6401910781860352],\n",
       "  'val_auc_roc': [0.7003446221351624,\n",
       "   0.756450355052948,\n",
       "   0.7644733786582947,\n",
       "   0.7731377482414246,\n",
       "   0.7744917273521423,\n",
       "   0.7692030668258667,\n",
       "   0.7742417454719543,\n",
       "   0.774853527545929,\n",
       "   0.7700950503349304,\n",
       "   0.7644635438919067,\n",
       "   0.7697938084602356,\n",
       "   0.7671470046043396,\n",
       "   0.7613966464996338]})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_aug_all_5, Macro_F1_aug_all_5, ROC_AUC_aug_all_5, metrics_all_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name_list = ['Original Data', 'Augmented SR 0.1', 'Augmented RI 0.1', \n",
    "                   'Augmented RS 0.1', 'Augmented RD 0.1', 'Augmented All 0.1', 'Augmented All 0.5']\n",
    "\n",
    "acc_list = [Accuracy_orig, Accuracy_aug_sr, Accuracy_aug_ri, Accuracy_aug_rs, \n",
    "            Accuracy_aug_rd, Accuracy_aug_all_1, Accuracy_aug_all_5]\n",
    "\n",
    "macro_f1_list = [Macro_F1_orig, Macro_F1_aug_sr, Macro_F1_aug_ri, Macro_F1_aug_rs, \n",
    "                 Macro_F1_aug_rd, Macro_F1_aug_all_1, Macro_F1_aug_all_5]\n",
    "\n",
    "roc_auc_list = [ROC_AUC_orig, ROC_AUC_aug_sr, ROC_AUC_aug_ri, ROC_AUC_aug_rs, \n",
    "                ROC_AUC_aug_rd, ROC_AUC_aug_all_1, ROC_AUC_aug_all_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'Trial Name' : trial_name_list, 'Test Accuracy Score' : acc_list, \n",
    "               'Test Macro F1 Score' : macro_f1_list, 'Test ROC AUC Score' : roc_auc_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial Name</th>\n",
       "      <th>Test Accuracy Score</th>\n",
       "      <th>Test Macro F1 Score</th>\n",
       "      <th>Test ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Data</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.732676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Augmented SR 0.1</td>\n",
       "      <td>0.670307</td>\n",
       "      <td>0.653869</td>\n",
       "      <td>0.745071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Augmented RI 0.1</td>\n",
       "      <td>0.644826</td>\n",
       "      <td>0.588886</td>\n",
       "      <td>0.713682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Augmented RS 0.1</td>\n",
       "      <td>0.677587</td>\n",
       "      <td>0.654245</td>\n",
       "      <td>0.746526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Augmented RD 0.1</td>\n",
       "      <td>0.673427</td>\n",
       "      <td>0.648213</td>\n",
       "      <td>0.740790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Augmented All 0.1</td>\n",
       "      <td>0.669267</td>\n",
       "      <td>0.665106</td>\n",
       "      <td>0.750884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Augmented All 0.5</td>\n",
       "      <td>0.680187</td>\n",
       "      <td>0.655371</td>\n",
       "      <td>0.748145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Trial Name  Test Accuracy Score  Test Macro F1 Score  \\\n",
       "0      Original Data             0.660946             0.631925   \n",
       "1   Augmented SR 0.1             0.670307             0.653869   \n",
       "2   Augmented RI 0.1             0.644826             0.588886   \n",
       "3   Augmented RS 0.1             0.677587             0.654245   \n",
       "4   Augmented RD 0.1             0.673427             0.648213   \n",
       "5  Augmented All 0.1             0.669267             0.665106   \n",
       "6  Augmented All 0.5             0.680187             0.655371   \n",
       "\n",
       "   Test ROC AUC Score  \n",
       "0            0.732676  \n",
       "1            0.745071  \n",
       "2            0.713682  \n",
       "3            0.746526  \n",
       "4            0.740790  \n",
       "5            0.750884  \n",
       "6            0.748145  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(result_dict)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('All_DA_BERT_large_uncased_unaug_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOeNGBZaTc3vi1iokDn5dgn",
   "collapsed_sections": [],
   "name": "Data_Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d7e8c53bf94bf48c06cea9abbd9aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf38f0560d3e493ca2b97fd974d00462",
       "IPY_MODEL_8a60b779e7d749d284b791b9e5126a62",
       "IPY_MODEL_2e51f1cad2b84893b537beb7e4ebf67c"
      ],
      "layout": "IPY_MODEL_d57bc505733b4c738cf84db24feba360"
     }
    },
    "047bcb706b304be09200793be7524708": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "071ca09b48bf4d9989852d66f8d57642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8aa487d37b284b2ba88903923a0086d9",
       "IPY_MODEL_b3ba42a7365d418f9cbf7f68ede3b65a",
       "IPY_MODEL_c7e4cea875eb41c8950f97350c237730"
      ],
      "layout": "IPY_MODEL_15db3b4b336b41cdb973852bb3fef72f"
     }
    },
    "0c234fac6d10482089dacd2c03a5bbde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12bf3b8f0bab4586847a07e8c438dafa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e67ba177d3744ea4bcc652774cd13abd",
       "IPY_MODEL_43eb8a62436a4c149e25f98f49a7c68d",
       "IPY_MODEL_3723a8c5f8eb47efa71e50a5ef924123"
      ],
      "layout": "IPY_MODEL_8039ef2f59ee482781f325f5a91b93e8"
     }
    },
    "15db3b4b336b41cdb973852bb3fef72f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b1a083fc8e643a78f055105960b523e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "263134a33eaa4345926dd786256c08eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2af599ea5c3d4874aff863303c5b5703": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b473e96d36604d71ae5d3d8e69cc01c3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_263134a33eaa4345926dd786256c08eb",
      "value": "Downloading: 100%"
     }
    },
    "2e51f1cad2b84893b537beb7e4ebf67c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3df12951362451685bea68b7091c69f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b8b44bed109443fd9bba63a7039f3c93",
      "value": " 226k/226k [00:00&lt;00:00, 3.21MB/s]"
     }
    },
    "3723a8c5f8eb47efa71e50a5ef924123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b1a083fc8e643a78f055105960b523e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c26d9b9e910a43febfd588927c3e7756",
      "value": " 299/299 [00:00&lt;00:00, 5.18kB/s]"
     }
    },
    "3dfc3ee445f2403a8ed7b4e6f5a8b3d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43eb8a62436a4c149e25f98f49a7c68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7942944ae43141c0aa83ec76fc0deafa",
      "max": 299,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d2efc2c1758475c9d1cd51cdc7edf0a",
      "value": 299
     }
    },
    "45b7612393254fe19709bdae7d7bbbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4656eb21ff2245b7be51f82c1e2c7e6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2af599ea5c3d4874aff863303c5b5703",
       "IPY_MODEL_c64b940afcc94ee3b2b88c582b54d97f",
       "IPY_MODEL_8a798f3e801d47df8771840991f7cfa3"
      ],
      "layout": "IPY_MODEL_ab8f5f020c76459aad12d4cab6a36a72"
     }
    },
    "5d2efc2c1758475c9d1cd51cdc7edf0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e02a09e9fe24718a8f1f4167c42d099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70f68856bdb64c30aa57e6046468b3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7942944ae43141c0aa83ec76fc0deafa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d3ff64481b64406aadb34439d2ad02b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d77d8f8c129400d9f61b60da03891b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98efd1135c4f438c8b8dd5c130cc667c",
       "IPY_MODEL_9aca8f0c4013472c8514d2d57f9ea3e8",
       "IPY_MODEL_807b39071d354a1ab7af51a05f1ef3b1"
      ],
      "layout": "IPY_MODEL_971c955528914b05afe5d12e9c626cf1"
     }
    },
    "8039ef2f59ee482781f325f5a91b93e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "807b39071d354a1ab7af51a05f1ef3b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc6b1e6a0e254b82b6c7277f10a5d542",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e02a09e9fe24718a8f1f4167c42d099",
      "value": " 112/112 [00:00&lt;00:00, 2.56kB/s]"
     }
    },
    "8a60b779e7d749d284b791b9e5126a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c234fac6d10482089dacd2c03a5bbde",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70f68856bdb64c30aa57e6046468b3d6",
      "value": 231508
     }
    },
    "8a798f3e801d47df8771840991f7cfa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_047bcb706b304be09200793be7524708",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c4792815ec0d4591bcaea2e7a0539e6b",
      "value": " 790/790 [00:00&lt;00:00, 14.6kB/s]"
     }
    },
    "8aa487d37b284b2ba88903923a0086d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee76f1517ed64f4fa49d998d2448f9c2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e88a61936e0949c490366d0619869b6c",
      "value": "Downloading: 100%"
     }
    },
    "971c955528914b05afe5d12e9c626cf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98efd1135c4f438c8b8dd5c130cc667c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b575b556bb9445ceb5c662b9d224e171",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_acd4639a73904507b7884adc96512dc5",
      "value": "Downloading: 100%"
     }
    },
    "9aca8f0c4013472c8514d2d57f9ea3e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2803d4a8a794a83a2ebcf61ce3097ff",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9a30d0d10744d14a47b500251c1973c",
      "value": 112
     }
    },
    "9e9b4804607046678d3d132528486b0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab8f5f020c76459aad12d4cab6a36a72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acd4639a73904507b7884adc96512dc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3ba42a7365d418f9cbf7f68ede3b65a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d12cbe52662546d1be82cfd4536dfdfc",
      "max": 437996231,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45b7612393254fe19709bdae7d7bbbe6",
      "value": 437996231
     }
    },
    "b473e96d36604d71ae5d3d8e69cc01c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b575b556bb9445ceb5c662b9d224e171": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8b44bed109443fd9bba63a7039f3c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf38f0560d3e493ca2b97fd974d00462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feb0fac998144444bfd9373ce537bbc3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7d3ff64481b64406aadb34439d2ad02b",
      "value": "Downloading: 100%"
     }
    },
    "c26d9b9e910a43febfd588927c3e7756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3df12951362451685bea68b7091c69f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4792815ec0d4591bcaea2e7a0539e6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c64b940afcc94ee3b2b88c582b54d97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e35113cc44f34a1fbb22f109f49f7bdd",
      "max": 790,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dfc3ee445f2403a8ed7b4e6f5a8b3d3",
      "value": 790
     }
    },
    "c7e4cea875eb41c8950f97350c237730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7abb004da9d42b787717cfdb3657f4e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ee89c9881c75441fbc9ec827d623134e",
      "value": " 418M/418M [00:11&lt;00:00, 37.0MB/s]"
     }
    },
    "d12cbe52662546d1be82cfd4536dfdfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2803d4a8a794a83a2ebcf61ce3097ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d57bc505733b4c738cf84db24feba360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7abb004da9d42b787717cfdb3657f4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e35113cc44f34a1fbb22f109f49f7bdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e567a77fb29d47c98fe19c440b2d31e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e67ba177d3744ea4bcc652774cd13abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e567a77fb29d47c98fe19c440b2d31e8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9e9b4804607046678d3d132528486b0b",
      "value": "Downloading: 100%"
     }
    },
    "e88a61936e0949c490366d0619869b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee76f1517ed64f4fa49d998d2448f9c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee89c9881c75441fbc9ec827d623134e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9a30d0d10744d14a47b500251c1973c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc6b1e6a0e254b82b6c7277f10a5d542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feb0fac998144444bfd9373ce537bbc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
