{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KSqG-xgDLRI"
   },
   "source": [
    "### All Easy DA - BERT Base Uncased\n",
    "\n",
    "#### Un-augmented test set\n",
    "#### Augment only the training set - 7 augmented examples per original\n",
    "\n",
    "#### Get Original Paper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1646721905242,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "y6DHMdiyDSTl"
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# !pip install ekphrasis\n",
    "# !pip install transformers\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646721905243,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "X-o7OyjjDYwr"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('../Data/classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.16.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, train, dev examples from base notebook\n",
    "\n",
    "train_data_df = pd.read_csv('./Saved_Models/EDA_base_uncased_5aug/All_DA_BERT_base_uncased_train_examples.csv')\n",
    "dev_data_df = pd.read_csv('./Saved_Models/EDA_base_uncased_5aug/All_DA_BERT_base_uncased_dev_examples.csv')\n",
    "test_data_df = pd.read_csv('./Saved_Models/EDA_base_uncased_5aug/All_DA_BERT_base_uncased_test_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1646721916193,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "zOn6K2RgJBkA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>rationales</th>\n",
       "      <th>final_label</th>\n",
       "      <th>text_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22448349_gab</td>\n",
       "      <td>['common', 'core', 'weed', 'too', 'much', 'rit...</td>\n",
       "      <td>['Men', 'Women']</td>\n",
       "      <td>['Women']</td>\n",
       "      <td>['None']</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "      <td>common core weed too much ritalan chem trails ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1178948520201637888_twitter</td>\n",
       "      <td>['took', 'my', 'nan', 'to', 'the', 'hospital',...</td>\n",
       "      <td>['None']</td>\n",
       "      <td>['None']</td>\n",
       "      <td>['None']</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "      <td>took my nan to the hospital for a x ray i turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1482573_gab</td>\n",
       "      <td>['&lt;user&gt;', 'well', 'not', 'really', 'islam', '...</td>\n",
       "      <td>['Islam']</td>\n",
       "      <td>['Other']</td>\n",
       "      <td>['Islam']</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>&lt;user&gt; well not really islam does not care for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1097184028149587969_twitter</td>\n",
       "      <td>['&lt;user&gt;', 'france', 'in', '&lt;number&gt;', 'after'...</td>\n",
       "      <td>['Islam', 'Other']</td>\n",
       "      <td>['Islam']</td>\n",
       "      <td>['Islam']</td>\n",
       "      <td>[]</td>\n",
       "      <td>normal</td>\n",
       "      <td>&lt;user&gt; france in &lt;number&gt; after muslims take o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1089569255111176192_twitter</td>\n",
       "      <td>['i', 'will', 'not', 'tolerate', 'non', 'arab'...</td>\n",
       "      <td>['Arab', 'Men', 'Women']</td>\n",
       "      <td>['Arab']</td>\n",
       "      <td>['Arab', 'Islam']</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>i will not tolerate non arab women slandering ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      post_id  \\\n",
       "0           0                 22448349_gab   \n",
       "1           1  1178948520201637888_twitter   \n",
       "2           2                  1482573_gab   \n",
       "3           3  1097184028149587969_twitter   \n",
       "4           4  1089569255111176192_twitter   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['common', 'core', 'weed', 'too', 'much', 'rit...   \n",
       "1  ['took', 'my', 'nan', 'to', 'the', 'hospital',...   \n",
       "2  ['<user>', 'well', 'not', 'really', 'islam', '...   \n",
       "3  ['<user>', 'france', 'in', '<number>', 'after'...   \n",
       "4  ['i', 'will', 'not', 'tolerate', 'non', 'arab'...   \n",
       "\n",
       "                    target1    target2            target3  \\\n",
       "0          ['Men', 'Women']  ['Women']           ['None']   \n",
       "1                  ['None']   ['None']           ['None']   \n",
       "2                 ['Islam']  ['Other']          ['Islam']   \n",
       "3        ['Islam', 'Other']  ['Islam']          ['Islam']   \n",
       "4  ['Arab', 'Men', 'Women']   ['Arab']  ['Arab', 'Islam']   \n",
       "\n",
       "                                          rationales final_label  \\\n",
       "0                                                 []      normal   \n",
       "1                                                 []      normal   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...   offensive   \n",
       "3                                                 []      normal   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,...  hatespeech   \n",
       "\n",
       "                                       text_combined  \n",
       "0  common core weed too much ritalan chem trails ...  \n",
       "1  took my nan to the hospital for a x ray i turn...  \n",
       "2  <user> well not really islam does not care for...  \n",
       "3  <user> france in <number> after muslims take o...  \n",
       "4  i will not tolerate non arab women slandering ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2005,
     "status": "ok",
     "timestamp": 1646722287248,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "wr-vv22ZMhT-"
   },
   "outputs": [],
   "source": [
    "X_train_id = train_data_df['post_id']\n",
    "X_test_id = test_data_df['post_id']\n",
    "X_dev_id = dev_data_df['post_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data_df['final_label']\n",
    "y_test = test_data_df['final_label']\n",
    "y_dev = dev_data_df['final_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15383\n",
      "1923\n",
      "1923\n"
     ]
    }
   ],
   "source": [
    "x_train_df = pd.DataFrame({'post_id' : X_train_id.to_list()})\n",
    "x_dev_df = pd.DataFrame({'post_id' : X_dev_id.to_list()})\n",
    "x_test_df = pd.DataFrame({'post_id' : X_test_id.to_list()})\n",
    "\n",
    "# X_train_df = pd.merge(x_train_df, raw_data_final, how='inner', on='post_id')\n",
    "# X_dev_df = pd.merge(x_dev_df, raw_data_final, how='inner', on='post_id')\n",
    "# X_test_df = pd.merge(x_test_df, raw_data_final, how='inner', on='post_id')\n",
    "\n",
    "X_train_text = train_data_df['text_combined'].to_list()\n",
    "X_dev_text= dev_data_df['text_combined'].to_list()\n",
    "X_test_text = test_data_df['text_combined'].to_list()\n",
    "\n",
    "print(len(X_train_text))\n",
    "print(len(X_dev_text))\n",
    "print(len(X_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153832"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load augmented datasets generated by EDA\n",
    "# sr = synonym replacement\n",
    "# ri = random synonym insertion\n",
    "# rs = random swap\n",
    "# rd = random deletion\n",
    "# dataframe name format: method_number \n",
    "\n",
    "sr_1_df = pd.read_csv('../test_data_set/EDA_7_0_7_sr_rest_0_1.csv')\n",
    "ri_1_df = pd.read_csv('../test_data_set/EDA_7_0_7_ri_rest_0_1.csv')\n",
    "rs_1_df = pd.read_csv('../test_data_set/EDA_7_0_7_rs_rest_0_1.csv')\n",
    "rd_1_df = pd.read_csv('../test_data_set/EDA_7_0_7_rd_rest_0_1.csv')\n",
    "all_1_df = pd.read_csv('../test_data_set/EDA_7_all_0_1s.csv')\n",
    "all_5_df = pd.read_csv('../test_data_set/EDA_7_all_0_5s.csv')\n",
    "\n",
    "# remove undecided labeled examples\n",
    "sr_1_df_filtered = sr_1_df[sr_1_df['final_label'] != 'undecided']\n",
    "ri_1_df_filtered = ri_1_df[ri_1_df['final_label'] != 'undecided']\n",
    "rs_1_df_filtered = rs_1_df[rs_1_df['final_label'] != 'undecided']\n",
    "rd_1_df_filtered = rd_1_df[rd_1_df['final_label'] != 'undecided']\n",
    "all_1_df_filtered = all_1_df[all_1_df['final_label'] != 'undecided']\n",
    "all_5_df_filtered = all_5_df[all_5_df['final_label'] != 'undecided']\n",
    "\n",
    "len(sr_1_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123064"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train, dev, test for each set\n",
    "sr_1_df_train = sr_1_df_filtered[sr_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "ri_1_df_train = ri_1_df_filtered[ri_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "rs_1_df_train = rs_1_df_filtered[rs_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "rd_1_df_train = rd_1_df_filtered[rd_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "all_1_df_train = all_1_df_filtered[all_1_df_filtered['post_id'].isin(X_train_id)]\n",
    "all_5_df_train = all_5_df_filtered[all_5_df_filtered['post_id'].isin(X_train_id)]\n",
    "\n",
    "# select text sets\n",
    "\n",
    "aug_sr_text = sr_1_df_train['text_str'].to_list()\n",
    "aug_ri_text = ri_1_df_train['text_str'].to_list()\n",
    "aug_rs_text = rs_1_df_train['text_str'].to_list()\n",
    "aug_rd_text = rd_1_df_train['text_str'].to_list()\n",
    "aug_all_1_text = all_1_df_train['text_str'].to_list()\n",
    "aug_all_5_text = all_5_df_train['text_str'].to_list()\n",
    "\n",
    "# select label sets\n",
    "\n",
    "aug_sr_labels = sr_1_df_train['final_label']\n",
    "aug_ri_labels = ri_1_df_train['final_label']\n",
    "aug_rs_labels = rs_1_df_train['final_label']\n",
    "aug_rd_labels = rd_1_df_train['final_label']\n",
    "aug_all_1_labels = all_1_df_train['final_label']\n",
    "aug_all_5_labels = all_5_df_train['final_label']\n",
    "\n",
    "len(aug_sr_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class label to 1 hot encoding\n",
    "\n",
    "def convert_to_oh(S):\n",
    "    '''takes a pandas series of text labels and returns one hot encoding equivalent\n",
    "    0 = normal, 1 = offensive, 2 = hatespeech\n",
    "    ''' \n",
    "    S_numerical = S.apply(lambda x: 0 if x=='normal' else (1 if x=='offensive' else 2))\n",
    "    S_oh = keras.utils.to_categorical(S_numerical, num_classes = 3, dtype = 'float32')\n",
    "    return S_oh\n",
    "    \n",
    "# original dataset - train, dev, and train\n",
    "y_train_orig = convert_to_oh(pd.Series(y_train))\n",
    "y_dev_orig = convert_to_oh(pd.Series(y_dev))\n",
    "y_test_orig = convert_to_oh(pd.Series(y_test))\n",
    "\n",
    "# augmented with sr = 0.1\n",
    "y_train_aug_sr = convert_to_oh(aug_sr_labels)\n",
    "\n",
    "# augmented with ri = 0.1\n",
    "y_train_aug_ri = convert_to_oh(aug_ri_labels)\n",
    "\n",
    "# augmented with rs = 0.1\n",
    "y_train_aug_rs = convert_to_oh(aug_rs_labels)\n",
    "\n",
    "# augmented with rd = 0.1\n",
    "y_train_aug_rd = convert_to_oh(aug_rd_labels)\n",
    "\n",
    "# augmented with all = 0.1\n",
    "y_train_all_1 = convert_to_oh(aug_all_1_labels)\n",
    "\n",
    "# augmented with all = 0.5\n",
    "y_train_all_5 = convert_to_oh(aug_all_5_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123064"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_ri_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123064"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_aug_ri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_aug_ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i dont retrieve im bugger off my cosset them edward white he has ii edward white joule and nike not still tinct',\n",
       " 'i dont think im getting my baby patrick white them white he has two white j and nikes not even touched',\n",
       " 'i dont suppose im beget my pamper them whiten he has deuce whiten watt second and nike not eve meet',\n",
       " 'i dont think im getting my baby them white he has two white j atomic number and nikes not even touched',\n",
       " 'i dont im getting my baby them white he has two j and nikes not even touched',\n",
       " 'touched dont think im getting my baby them white he has two white j and nikes not even i',\n",
       " 'i think im getting my baby them white he has two white j and nikes not even touched',\n",
       " 'i dont think im getting my baby them white he has two white j and nikes not even touched',\n",
       " 'we figure cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes grammatical gender to a sexual offences public list but meeting place will a trans lesbian bisexual and queer womxn be able to enter meeting place their information on the reporting sheet gender forum',\n",
       " 'we cannot continue calling ourselves their if the lesbian of all womxn arent addressed yes reporting a bisexual offences public list but will a trans rights sexual and queer womxn be able to enter feminists information on the to sheet gender forum',\n",
       " 'we cannot continue calling ourselves feminists if the rights of womxn arent addressed yes a sexual offences list but will a trans lesbian bisexual and queer womxn be able to enter information on reporting sheet gender forum',\n",
       " 'we cannot go along cry ourselves feminist if the rightfulness of all womxn arent plow yes to a intimate offensive activity populace inclination but will a trans sapphic bisexual person and scotch womxn be able bodied to move into their data on the account mainsheet sex meeting place',\n",
       " 'we cannot continue calling to feminists if the ourselves of all public arent addressed yes to a sexual offences womxn list but will a trans lesbian bisexual and queer womxn be able rights enter their information sheet the reporting on gender forum',\n",
       " 'we cannot continue calling ourselves feminists if the rights of all womxn arent addressed to a sexual list but will a trans lesbian bisexual and womxn be able enter their information on the gender forum',\n",
       " 'we cannot continue calling ourselves feminists if the rights of all womxn arent only addressed yes to a coverage sexual offences public list but will a trans lesbian bisexual and queer womxn be populace able to enter figure their information on the reporting sheet gender forum',\n",
       " 'we cannot continue calling ourselves feminists if the rights of all womxn arent addressed yes to a sexual offences public list but will a trans lesbian bisexual and queer womxn be able to enter their information on the reporting sheet gender forum',\n",
       " 'niggers ignoring me',\n",
       " 'nawt yall niggers ignoring me',\n",
       " 'niggers yall nawt ignoring me',\n",
       " 'nawt yall maine niggers ignoring me',\n",
       " 'nawt yall jigaboo brush aside me',\n",
       " 'nawt yall cut niggers ignoring me',\n",
       " 'nawt yall me ignoring niggers',\n",
       " 'nawt yall niggers ignoring me',\n",
       " 'this i am bit confused coz chinese ppl can not twitter access thn how user ching chong using it i think he pakistani',\n",
       " 'exploiter i am moment disconcert coz formosan ppl can not memory access chirrup thn how this ching chong habituate it i imagine he pakistani',\n",
       " 'user stool i am bit confused coz chinese ppl can not access twitter thn how this ching chong get at using it i think he pakistani',\n",
       " 'user i am bit coz chinese ppl can not access twitter thn how this chong using it i think he pakistani',\n",
       " 'exploiter i am piece illogical coz taiwanese ppl can not admittance chitter thn how this ching chong victimisation it i recollect he pakistani',\n",
       " 'user i am bit confused coz chinese ppl can not access twitter thn how this constitute ching chong using it i think he pakistani',\n",
       " 'user i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani',\n",
       " 'user i am bit confused coz chinese ppl can not access twitter thn how this ching chong using it i think he pakistani ',\n",
       " 'this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches',\n",
       " 'this bun in whataburger eating a burger with no top i and holding it palm up bitch hate white bitches',\n",
       " 'this bitch in whataburger eating a burger with top bun and it palm i white bitches',\n",
       " 'this beef in whataburger wipe out a hamburger with no cover roll and control it palm tree up i hatred albumen squawk',\n",
       " 'this bitch in whataburger tip eating a burger with no top bun and holding it palm up i hate white bitches',\n",
       " 'this bitch in whataburger eating a burger with no top bun and holding it palm ribbon up i hate white hatred bitches',\n",
       " 'this kick in whataburger use up a beefburger with no top of the inning roll and make it medallion up i hatred egg white kick',\n",
       " 'this bitch in whataburger eating a burger with no top bun and holding it palm up i hate white bitches',\n",
       " 'laura loomer raped me while at me in her disgusting kike language and said we must goyim laura loomer loomergate',\n",
       " 'laura loomer raped me while screaming at me in her disgusting kike language and said we must goyim laura loomer loomergate',\n",
       " 'laura loomer assault me while hilarious at me in her distasteful yid voice communication and aforesaid we mustiness uproot the non jew laura loomer loomergate',\n",
       " 'laura loomer ravaged me while call at me in her foul hymie lyric and read we mustiness uproot the goy laura loomer loomergate',\n",
       " 'laura loomer raped me while screaming at me in her disgusting maine maine kike language and said we must exterminate the goyim laura loomer loomergate',\n",
       " 'screaming loomer raped me while at laura me in her disgusting kike language and said we must exterminate the goyim laura loomer loomergate',\n",
       " 'laura loomer exterminate me loomergate screaming at me in her disgusting kike language and said we must raped the goyim laura loomer while',\n",
       " 'laura loomer raped me while screaming at me in her disgusting kike language and said we must exterminate the goyim laura loomer loomergate',\n",
       " 'and this is why i remnant up with nigga trainee furbish up who can not utter in good order deficiency staple noesis of biological science it genuinely scarey if the populace only bed',\n",
       " 'and this is why i terminate up with spade trainee furbish up who can not verbalise in good order want introductory noesis of biological science it genuinely chilling if the world only bonk',\n",
       " 'and this is why i end up with nigger trainee doctors who can not speak direct properly lack basic knowledge of biology address it truly scary if the public only knew',\n",
       " 'and this is why i end up with only public doctors who can not speak properly lack basic knowledge of biology it truly scary if the trainee nigger knew',\n",
       " 'and is this why i end up with nigger trainee doctors who can not speak properly lack basic knowledge only biology it truly scary if the public of knew',\n",
       " 'and this is why i up with nigger trainee doctors can not speak lack basic knowledge of it truly scary if the public only knew',\n",
       " 'and this is i end up with nigger trainee doctors can not properly lack basic knowledge of biology it scary if the public knew',\n",
       " 'and this is why i end up with nigger trainee doctors who can not speak properly lack basic knowledge of biology it truly scary if the public only knew',\n",
       " 'guilty until proven innocent unless you are a jew a nigger or a lover both',\n",
       " 'proven innocent you are a jew a a lover of both',\n",
       " 'hangdog until rise clean handed unless you are a israelite a spade or a devotee of both',\n",
       " 'shamed until evidence innocuous unless you are a israelite a spade or a buff of both',\n",
       " 'guilty until proven innocent unless you are or jew a nigger a a lover of both',\n",
       " 'hebrew guilty until proven innocent unless you are a jew a nigger or a lover of both',\n",
       " 'guilty until proven innocent unless you are a jew a nigger jigaboo or a lover of both',\n",
       " 'guilty until proven innocent unless you are a jew a nigger or a lover of both',\n",
       " 'timeworn i can not put up miscarriage from a lesson viewpoint telegraph i can put up it virtuously soft discontinue count at those niggling niglets as next bushel and take in them for what they in truth are next raper of bloodless woman and next public assistance recipient role of bloodless revenue enhancement dollar bill and next populist voter',\n",
       " 'tired i not support abortion from a moral standpoint wired i can support it morally easy stop looking at those little niglets as future doctors see them for what they are future rapists of white women and future welfare recipient of white tax dollars and future democrat voters',\n",
       " 'tired figure i can not support abortion from a moral standpoint wired i atomic number can support it morally easy stop looking at reckon those little niglets as future doctors and see them for what they really are future rapists of white women and future welfare recipient dollar of white tax dollars populist and future democrat voters',\n",
       " 'tire out i can not bear out miscarriage from a lesson stand telegraph i can bear out it virtuously comfortable closure bet at those fiddling niglets as succeeding touch on and take in them for what they rattling are succeeding raper of whiten charwoman and succeeding eudaemonia receiver of whiten revenue enhancement clam and succeeding populist voter',\n",
       " 'tired i can not support abortion from a moral standpoint wired i can support it stop looking at those little future doctors and them for what they really are future rapists of white women future welfare recipient of white tax dollars and future democrat voters',\n",
       " 'tired i can not support abortion from a moral standpoint wired miscarriage i can support it morally easy stop looking at those little niglets as be reckon future axerophthol doctors and see them for what they really are future rapists of white women and future welfare recipient of white receiver tax dollars and future democrat voters',\n",
       " 'tired i can not support doctors from it moral standpoint wired i can support a morally tax stop looking at those little niglets as future abortion and see them for what dollars really are future rapists of white women and future welfare recipient of white easy they and future democrat voters',\n",
       " 'tired i can not support abortion from a moral standpoint wired i can support it morally easy stop looking at those little niglets as future doctors and see them for what they really are future rapists of white women and future welfare recipient of white tax dollars and future democrat voters',\n",
       " 'number number percent of brits think is a failure guess the other percent are with their muzzie master there no great in britain anymore soon big ben will be converted into a minaret',\n",
       " 'failure number percent of brits think multiculturalism big a number i guess the other percent are happy with their muzzie master britain no great in there anymore soon is ben will be converted into a minaret',\n",
       " 'britain number percent of brits think multiculturalism is a failure their guess the other percent are happy be i muzzie master there no great in number anymore soon big ben will with converted into a minaret',\n",
       " 'type a number number percent of brits think multiculturalism is a failure i guess great britain the other percent are happy with their muzzie master there no great in leave britain anymore soon big ben will be converted into a minaret',\n",
       " 'number number percent of pct brits think multiculturalism is a failure i guess the other percent are happy with exchange their muzzie bang up master there no great in britain anymore soon big ben will be converted into a minaret',\n",
       " 'bit bit per centum of brit suppose multiculturalism is a nonstarter i gauge the other per centum are glad with their muzzie professional there no nifty in united kingdom of great britain and northern ireland any longer before long bad ben will be change into a minaret',\n",
       " 'list list pct of britt intend multiculturalism is a nonstarter i infer the other pct are felicitous with their muzzie passkey there no not bad in great britain any longer before long cock a hoop ben will be commute into a minaret',\n",
       " 'number number percent of brits think multiculturalism is a failure i guess the other percent are happy with their muzzie master there no great in britain anymore soon big ben will be converted into a minaret',\n",
       " 'tariq nasheed beat out the lie with out of that grind away dearest lmao someone assign a cooky in that nigra verbalise already',\n",
       " 'tariq nasheed outwit the piece of ass out of that tympan darling lmao person couch a cooky in that coon rima oris already',\n",
       " 'tariq nasheed beating the fuck out of that drum beloved lmao somebody put a biscuit in that niggas mouth already',\n",
       " 'tariq nasheed beating the fuck out back talk of that drum beloved lmao somebody put a biscuit in piece of tail that niggas mouth already',\n",
       " 'tariq nasheed beating the fuck beloved of that in out lmao somebody put a biscuit drum that niggas mouth already',\n",
       " 'tariq the beating fuck nasheed out of that drum beloved lmao somebody put a biscuit in that niggas mouth already',\n",
       " 'tariq nasheed beating the back talk fuck out of that drum beloved atomic number lmao somebody put a biscuit in that niggas mouth already',\n",
       " 'tariq nasheed beating the fuck out of that drum beloved lmao somebody put a biscuit in that niggas mouth already',\n",
       " 'percent cotton thigh highs to avoid contact with any gay cotton fiber chemicals',\n",
       " 'percentage cotton wool second joint highs to obviate impinging with any merry chemical substance',\n",
       " 'percent cotton thigh highs with avoid contact to any gay chemicals',\n",
       " 'percent cotton thigh highs to avoid contact with any gay chemicals',\n",
       " 'percent chemical substance cotton thigh highs to avoid contact with any gay chemicals',\n",
       " 'percent cotton thigh to avoid contact with any gay chemicals',\n",
       " 'pct cotton fiber second joint highs to deflect inter group communication with any brave chemical substance',\n",
       " 'percent cotton thigh highs to avoid contact with any gay chemicals',\n",
       " 'oomf a bit yearl former cupboard jolly and haunted with me person service',\n",
       " 'oomf a number yearl old closet gay and obsessed with me someone loo help',\n",
       " 'oomf a number yearl old closet somebody gay and obsessed with me someone help',\n",
       " 'oomf a number yearl old closet gay with obsessed and me someone help',\n",
       " 'oomf number yearl old closet gay and obsessed with me someone help',\n",
       " 'oomf closet number yearl old a gay and obsessed with me someone help',\n",
       " 'oomf a phone number yearl quondam wc homosexual and haunted with me person help oneself',\n",
       " 'oomf a number yearl old closet gay and obsessed with me someone help',\n",
       " 'all of my ex wife were cunning but they were hoe i opine i only pull fly front wait thots',\n",
       " 'all of my exes were cute but they were thots i guess i only attract fly looking hoes',\n",
       " 'all of my ex husband were precious but they were hoe i reckon i only draw in pilot attend thots',\n",
       " 'all of my exes were cute but they were be hoes i guess i only attract fly looking thots',\n",
       " 'all of my exes were cute but they hoes guess i only attract fly looking thots',\n",
       " 'all of my exes were exclusively cute but they were hoes i guess i only attract fly looking thots',\n",
       " 'all of my exes cute but they were hoes i guess i only attract fly looking thots',\n",
       " 'all of my exes were cute but they were hoes i guess i only attract fly looking thots ',\n",
       " 'chap be thrifty she texting other nigra',\n",
       " 'fellas be careful she texting other niggas',\n",
       " 'fellas be careful texting she other niggas',\n",
       " 'fellas be careful she niggas other texting',\n",
       " 'fellas be careful she texting other jigaboo niggas',\n",
       " 'fellas be careful cost she texting other niggas',\n",
       " 'be careful she other niggas',\n",
       " 'fellas be careful she texting other niggas',\n",
       " 'call niggas italian they dick the poozingi',\n",
       " 'italian niggas call they jigaboo dick the poozingi',\n",
       " 'italian niggas call they dick the hollo poozingi',\n",
       " 'italian poozingi call they dick the niggas',\n",
       " 'italian niggas call they dick the poozingi',\n",
       " 'italian niggas call they dick the poozingi',\n",
       " 'italian nigra name they putz the poozingi',\n",
       " 'italian niggas call they dick the poozingi',\n",
       " 'user what did old lady do was she a nazi white supremacist',\n",
       " 'user what did the old lady do fare was she a nazi or white supremacist',\n",
       " 'exploiter what did the erstwhile noblewoman do was she a german nazi or andrew dickson white supremacist',\n",
       " 'substance abuser what did the honest to god madam do was she a national socialist or andrew d white supremacist',\n",
       " 'user what did the old lady do nazi she a was or white supremacist',\n",
       " 'user what did the old do was she a nazi or white supremacist',\n",
       " 'old what did the user lady do was she a nazi or white supremacist',\n",
       " 'user what did the old lady do was she a nazi or white supremacist',\n",
       " 'user user user user user he married a negress because white women did not want him but black all over america love nobama',\n",
       " 'exploiter exploiter exploiter exploiter exploiter he espouse a negress because ovalbumin adult female did not neediness him but total darkness female person all over the states have it off nobama',\n",
       " 'drug user atomic number user user user user user he married a negress because white women did not want him but black females all over america love nobama',\n",
       " 'user user user user non user he married a negress because white women did not want him but black females all over terminated america love nobama',\n",
       " 'substance abuser substance abuser substance abuser substance abuser substance abuser he conjoin a negress because patrick victor martindale white cleaning lady did not lack him but dim female person all over the states sexual love nobama',\n",
       " 'user user user user user he married a negress because love women did but want him not black females all over america white nobama',\n",
       " 'user user user user user married a negress because white women did not want him but black females over america love nobama',\n",
       " 'user user user user user he married a negress because white women did not want him but black females all over america love nobama',\n",
       " 'user for drug use not kike at all thanks condoning that disclosure',\n",
       " 'user condoning drug use not at all thanks for that disclosure',\n",
       " 'substance abuser excuse dose practice not sheeny at all give thanks for that revealing',\n",
       " 'user condoning drug use not kike at all thanks for that disclosure',\n",
       " 'user condoning drug use not purpose kike at all thanks for that disclosure',\n",
       " 'drug user condone do drugs utilisation not sheeny at all thank for that revealing',\n",
       " 'user thanks drug use not kike at all condoning for that disclosure',\n",
       " 'user condoning drug use not kike at all thanks for that disclosure',\n",
       " 'suddenly user people act as if you can not say the all about the states americans not same obviously are pro guns not all americans support their government treatment of immigrants and user but when it comes to israel foreigners the logic changes',\n",
       " 'user user people act as if you can not say the same about the states obviously not all americans are pro guns not all americans their government treatment of immigrants and foreigners but it comes to israel suddenly the logic changes',\n",
       " 'user user people act as accompaniment if you can not say the same about the states obviously not hoi polloi all americans are pro guns not all americans support their government treatment of allege immigrants and foreigners but when it comes allege to israel suddenly the logic changes',\n",
       " 'substance abuser substance abuser mass behave as if you can not sound out the same about the put forward evidently not all american are professional accelerator pedal not all american patronize their politics discussion of immigrant and foreigner but when it number to state of israel dead the system of logic change',\n",
       " 'user user people act as if you can not say the same about the states obviously not americans are pro guns not all americans support their government treatment immigrants and foreigners but when it comes to suddenly the logic changes',\n",
       " 'the user people act same if you can not say the as about the states obviously not all americans are but guns not all americans support their government treatment of immigrants and foreigners pro when changes comes to israel suddenly user logic it',\n",
       " 'user user people act as if evidently you can not say the same about the states obviously lapplander not switch all americans are pro guns not all completely americans support their government treatment of immigrants and foreigners but when it comes to israel suddenly the logic changes',\n",
       " 'user user people act as if you can not say the same about the states obviously not all americans are pro guns not all americans support their government treatment of immigrants and foreigners but when it comes to israel suddenly the logic changes',\n",
       " 'drug user drug user they travel to assist ply food for thought to those kp while muhammadanism degree centigrade terrorist butured despoiled and storm them to bequeath their own domain',\n",
       " 'patch user user they visited helped provided food to those kps while islam c terrorist butured raped and forced them to possess leave their own land',\n",
       " 'user user they visited helped provided food to those kps while islam c butured raped and forced them to leave their own land',\n",
       " 'user user they visited helped raped food to those kps forced islam c terrorist butured provided and while them to leave their own land',\n",
       " 'user they visited helped provided food to those kps while islam c terrorist butured raped and forced them to leave their own land',\n",
       " 'substance abuser substance abuser they confab assist allow for solid food to those kitchen police while islamism one hundred terrorist butured ravish and storm them to leave of absence their own nation',\n",
       " 'user user they visited helped provided food tap to those kps while islam c terrorist butured raped and forced them to leave their own drug user land',\n",
       " 'user user they visited helped provided food to those kps while islam c terrorist butured raped and forced them to leave their own land',\n",
       " 'anyways the fact that her outfit directly violates france law abt no face coverings veils but is still headlined in paris fashion week shows that the law was never abt obscured facial identification but abt white supremacy',\n",
       " 'anyways the fact that her outfit directly violates france law abt no hebdomad face coverings veils but headline is still headline headlined in paris fashion week shows that the law was never abt obscured facial identification but abt white supremacy and islamophobia',\n",
       " 'anyways the directly that her outfit fact obscured france law abt no face coverings veils but is still headlined in paris fashion week shows that the law was never abt violates facial and but abt white supremacy identification islamophobia',\n",
       " 'anyways the fact that her outfit directly violates france law abt no face coverings veils but is still headlined in paris fashion week aspect shows that the law was never abt obscured at once facial identification but abt anyhow white supremacy and islamophobia',\n",
       " 'anyways the fact that her outfit directly violates france law abt no facial coverings veils but is still paris in headlined fashion week shows that the law was never abt obscured abt identification but face white supremacy and islamophobia',\n",
       " 'anyways the fact that outfit directly violates france law abt no face coverings veils but is still headlined in paris fashion week shows that the law was abt obscured facial identification but abt supremacy and islamophobia',\n",
       " 'in any case the fact that her rig immediately dishonor jacques anatole francois thibault jurisprudence abt no fount cover caul but is hush up headline in genus paris mode hebdomad usher that the jurisprudence was neer abt veil seventh cranial nerve designation but abt stanford white mastery and islamophobia',\n",
       " 'anyways the fact that her outfit directly violates france law abt no face coverings veils but is still headlined in paris fashion week shows that the law was never abt obscured facial identification but abt white supremacy and islamophobia',\n",
       " 'it funny how people offended by the job word nigger have no problem calling people nazis what the difference',\n",
       " 'it suspect how masses scandalize by the logos coon have no job name masses german nazi what the conflict',\n",
       " 'it funny how people offended by the information technology word nigger have no problem calling people nazis what the difference',\n",
       " 'it funny how people offended by the nazis nigger have no problem calling people word what the difference',\n",
       " 'it funny offended by the word nigger have no problem calling people nazis what the difference',\n",
       " 'it suspect how masses go against by the christian bible jigaboo have no job career masses nazi what the dispute',\n",
       " 'it funny how people offended by the have no problem calling people nazis what difference',\n",
       " 'it funny how people offended by the word nigger have no problem calling people nazis what the difference',\n",
       " 'as much as i appreciate a really of open discussion i want just format a facebook that i can say beaner on',\n",
       " 'as much as i appreciate a format of open discussion i really want a facebook that can say beaner on',\n",
       " 'as a lot as i prize a arrange of open air discourse i very just require a facebook that i can allege beanball on',\n",
       " 'as as appreciate a of open discussion i really just want a that i can say beaner on',\n",
       " 'as much axerophthol as i appreciate a format of open discussion i practically really just want a facebook that i can say beaner on',\n",
       " 'as much beanball as i appreciate a format of open discussion i really just want a facebook that i can say beaner on',\n",
       " 'as much say i appreciate a format want open discussion i really just of a facebook that i can as beaner on',\n",
       " 'as much as i appreciate a format of open discussion i really just want a facebook that i can say beaner on',\n",
       " 'that was associate in nursing just a photo look up rhyan moody she was killed on thanksgiving by an illegal spic',\n",
       " 'that killed just a photo look up rhyan moody she was was on thanksgiving by an illegal spic',\n",
       " 'that was just a photo up rhyan moody she was killed on by an illegal spic',\n",
       " 'that was just a exposure flavor up rhyan dwight lyman moody she was toss off on grace by an illegal spic and span',\n",
       " 'that was just a photo look up rhyan moody she was killed on thanksgiving by an illegal spic',\n",
       " 'that was just a aspect photo look up rhyan moody she was killed on thanksgiving by an illegal spic',\n",
       " 'that was just a photograph tone up rhyan sour she was obliterate on grace by an illegal spic and span',\n",
       " 'that was just a photo look up rhyan moody she was killed on thanksgiving by an illegal spic',\n",
       " 'this sounds like a kike national socialist',\n",
       " 'this sounds like vocalize a kike national socialist',\n",
       " 'this sounds care a hymie interior socialistic',\n",
       " 'this kike like a sounds national socialist',\n",
       " 'this sounds socialist a kike national like',\n",
       " 'this hymie sounds like a kike national socialist',\n",
       " 'this vocalize ilk a kike interior socialistic',\n",
       " 'this sounds like a kike national socialist',\n",
       " 'i saw a couple heel baums information and steins in the victim list but that about it ya got more info i thought the school was half spic though',\n",
       " 'i saw type a a couple baums and steins in the victim list but that about it ya got more info i thought the school was half spic though',\n",
       " 'though saw a couple baums and steins in the victim list but that about it ya got i info i thought the school was half spic more',\n",
       " 'i saw school couple baums and steins in the victim list but i about it ya got more info that thought the a was half spic though',\n",
       " 'i construe a duet frank baum and stein in the dupe tilt but that about it ya arrest more information i think the school day was one half spick though',\n",
       " 'i saw a couple baums and steins in the victim list but that about it ya got more the school was half spic though',\n",
       " 'i see a mate lyman frank brown and beer mug in the dupe inclination but that about it ya get down more information i guess the train was one half spick and span though',\n",
       " 'i saw a couple baums and steins in the victim list but that about it ya got more info i thought the school was half spic though',\n",
       " 'only elite group freebooter are enrich when they moment a intelligence quotient islamic onto wellbeing incision bit homeless person ex serviceman would not want taxpayer make up year on how to manipulation john in devoid household',\n",
       " 'not elite looters are enriched taxpayer they import a iq moslem onto welfare section number only vets would homeless need when paid classes on how to use toilets in free homes',\n",
       " 'only elite looters are enriched when they import a iq along moslem onto welfare section number islamic homeless vets would not need taxpayer paid classes on how to use toilets in free enrich homes',\n",
       " 'only elite enriched when import iq moslem section number vets would not need taxpayer paid classes on how to use toilets free homes',\n",
       " 'only elite to are enriched when they toilets a iq moslem onto welfare section number homeless vets would not need taxpayer paid classes free how looters use import in on homes',\n",
       " 'only elect spoiler are enrich when they implication a intelligence quotient islamic onto public assistance department figure homeless person ex serviceman would not take taxpayer make up family on how to purpose stool in innocent base',\n",
       " 'looters are enriched when they import a iq moslem onto welfare section number homeless would not taxpayer paid classes how to use toilets in free homes',\n",
       " 'only elite looters are enriched when they import a iq moslem onto welfare section number homeless vets would not need taxpayer paid classes on how to use toilets in free homes',\n",
       " 'anyway princess sapphire of silverland is a dyke and threw the first brick dike at stonewall',\n",
       " 'in any event princess sky blue of silverland is a butch and throw off the first of all brick at stonewall',\n",
       " 'anyway princess sapphire of silverland is a dyke and threw the first brick at stonewall',\n",
       " 'anyway princess sapphire brick silverland is a dyke and threw the first of at stonewall',\n",
       " 'at any rate princess azure of silverland is a dike and fuddle the number one brick at stonewall',\n",
       " 'anyway princess sapphire of silverland a dyke and threw the first brick at stonewall',\n",
       " 'anyway princess sapphire of atomic number silverland is a dyke and threw the first brick at stonewall',\n",
       " 'anyway princess sapphire of silverland is a dyke and threw the first brick at stonewall',\n",
       " 'if we could instruct a camelopard to key that would be unmatched w c handy sumbitch',\n",
       " 'if we could teach a giraffe to paint that would be one sumbitch',\n",
       " 'if we could teach giraffe to paint that be one handy sumbitch',\n",
       " 'if sumbitch could teach a giraffe to paint that would be one handy we',\n",
       " 'if we could teach a giraffe to paint giraffa camelopardalis that would be one handy sumbitch',\n",
       " 'if we could giraffa camelopardalis teach a giraffe to paint that would be one handy sumbitch',\n",
       " 'if we could teach handy giraffe to paint that would be one a sumbitch',\n",
       " 'if we could teach a giraffe to paint that would be one handy sumbitch',\n",
       " 'she wanna meet carti that bitch is a receive barbie',\n",
       " 'she wanna meet carti that bitch is a barbie',\n",
       " 'she wanna receive carti that grouse is a barbie',\n",
       " 'she wanna contact carti that bellyache is a barbie',\n",
       " 'she wanna meet bitch that carti is a barbie',\n",
       " 'she beef wanna meet carti that bitch is a barbie',\n",
       " 'she wanna meet carti that bitch is a barbie',\n",
       " 'she wanna meet carti that bitch is a barbie ',\n",
       " 'smiling cuz i am young black deep rich and i am handsome',\n",
       " 'smiling cuz i am young black rich and am i handsome',\n",
       " 'beamish cuz i am offspring bleak robust and i am bountiful',\n",
       " 'i cuz i am young black rich and smiling am handsome',\n",
       " 'smiling cuz i grinning am young black rich and i am handsome',\n",
       " 'grinning cuz i am unseasoned melanise deep and i am well favored',\n",
       " 'smiling cuz i am young black rich and i am',\n",
       " 'smiling cuz i am young black rich and i am handsome',\n",
       " 'sex be slow good a bitch be so stroking and crying',\n",
       " 'excite be so thoroughly a bellyache be irksome stroke and exigent',\n",
       " 'sex be so good stroke a bitch be slow stroking and crying',\n",
       " 'sex be so good a bitch be slow stroking and crying',\n",
       " 'turn on be so thoroughly a cunt be sluggish stroke and weep',\n",
       " 'stroke sex be so good a bitch be slow stroking and crying',\n",
       " 'stroking be so good a bitch be slow sex and crying',\n",
       " 'sex be so good a bitch be slow stroking and crying',\n",
       " 'crab be so ok and develop the cheek to the likes of coon',\n",
       " 'bitches be so fine and the got nerve to like niggas',\n",
       " 'bitches be so fine and got the nerve to develop like niggas',\n",
       " 'beef be so all right and drive the spunk to same coon',\n",
       " 'bitches be so mulct fine and got the nerve to like niggas',\n",
       " 'bitches be so and got nerve to like',\n",
       " 'bitches be so fine and got the nerve to like',\n",
       " 'bitches be so fine and got the nerve to like niggas ',\n",
       " 'user user the shoe babies on the would foot would mean that blacks and jews other pay high taxes to subsidies the birth of white being',\n",
       " 'user user the shoe being on the other foot would along mean that blacks and jews would pay high taxes to parturition subsidies the birth of white babies',\n",
       " 'drug user drug user the horseshoe being on the other animal foot would have in mind that blackamoor and jew would pay off high gear tax to subsidy the giving birth of e b white cocker',\n",
       " 'user user the shoe being on the other foot bear would mean that blacks and jews would pay high cosset taxes to subsidies the birth of white babies',\n",
       " 'drug user drug user the horseshoe being on the other groundwork would entail that blackness and hebrew would bear gamey taxation to subsidy the nativity of edward white babe',\n",
       " 'user user the shoe being on the other foot would mean that blacks and jews would pay high taxes to subsidies the birth of white babies',\n",
       " 'user user the shoe being on the other foot taxes mean that blacks and jews would to high would pay subsidies the birth of white babies',\n",
       " 'user user the shoe being on the other foot would mean that blacks and jews would pay high taxes to subsidies the birth of white babies',\n",
       " 'user hillbilly is a scheming fraud who fronts a user cult',\n",
       " 'user user is a scheming fraud who fronts a hillbilly cult',\n",
       " 'user user is a scheming fraud who fronts a hillbilly furor cult',\n",
       " 'drug user drug user is a calculating put on who social movement a bushwhacker fad',\n",
       " 'scheming user is a user fraud who fronts a hillbilly cult',\n",
       " 'type a user user is a scheming fraud who fronts a hillbilly cult',\n",
       " 'drug user drug user is a shrewd sham who straw man a bushwhacker craze',\n",
       " 'user user is a scheming fraud who fronts a hillbilly cult',\n",
       " 'user no idea who these women are they who all the credit for they on after the women job smears calling for impeachment take the hits and been and told to go back to where jumping come from get well done unknown white congress women',\n",
       " 'user back idea who these women get they are all the done for jumping on after the women who been calling for impeachment take the hits and smears and told to they no to where go come from job well credit unknown white congress women',\n",
       " 'user no idea completely who these women are they get all the contract credit for jumping on after the women who been calling defame for impeachment take be the hits and smears and told to go back to where they come from job well done unknown white congress women',\n",
       " 'substance abuser no estimation who these cleaning woman are they draw all the mention for stand out on after the cleaning woman who been forebode for impeachment fill the impinge on and vilification and distinguish to conk out rearward to where they issue forth from farm out intimately cause unnamed elwyn brooks white sexual intercourse cleaning woman',\n",
       " 'user no idea women are they get all the credit for jumping on after the women who been for impeachment take the hits and and told to go back to where they come from job done unknown white congress women',\n",
       " 'drug user no approximation who these charwoman are they begin all the credit rating for climb up on after the charwoman who been yell for impeachment exact the shoot and vilification and recite to crack indorse to where they descend from caper fountainhead coiffure unidentified bloodless carnal knowledge charwoman',\n",
       " 'user no idea who these women are they get all work jump the credit be for jumping on after the women who been calling for impeachment take the hits and smears and told along to go back to where they come from job well done unknown white congress women',\n",
       " 'user no idea who these women are they get all the credit for jumping on after the women who been calling for impeachment take the hits and smears and told to go back to where they come from job well done unknown white congress women ',\n",
       " 'y is big baby davis a faggot on shameless doe',\n",
       " 'y faggot big baby davis a is on shameless doe',\n",
       " 'y is big baby davis unblushing a faggot on shameless doe',\n",
       " 'y is big baby davis shameless faggot on a doe',\n",
       " 'y is big baby davis a faggot unblushing on shameless doe',\n",
       " 'atomic number is braggy babe john davis a fag on unblushing energy',\n",
       " 'y is big baby davis faggot shameless doe',\n",
       " 'y is big baby davis a faggot on shameless doe',\n",
       " 'i do not blame orlando pie rats for loosing like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'i do not blessed orlando proto indo european tell on for unloosen comparable this they are wassail from that blackamoor mark mtn sec diski wafa wafa',\n",
       " 'i do not blame orlando pie tag rats for loosing non like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'i do not blame orlando pie are diski loosing like this they rats drunk from that black label mtn ss for wafa wafa',\n",
       " 'i do pie blame orlando not loosing for rats like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'i do not blame tag orlando pie rats for loosing like this they are drunk from that black label mtn non ss diski wafa wafa',\n",
       " 'i do not fault orlando proto indo european stinkpot for loosen the likes of this they are wino from that shirley temple black pronounce mtn usss diski wafa wafa',\n",
       " 'i do not blame orlando pie rats for loosing like this they are drunk from that black label mtn ss diski wafa wafa',\n",
       " 'related instagram tags for jewelry fashionable designer trendy hairstyle blog gram fashion fashion menswear men style trend',\n",
       " 'related instagram tags for jewelry touch fashionable designer trendy hairstyle fashion gram fashion blog menswear men style trend',\n",
       " 'interrelate instagram label for jewellery fashionable fashion designer voguish hairdo manner gm manner web log menswear work force way trend',\n",
       " 'related instagram tags for jewelry fashionable forge designer trendy hairstyle fashion gram fashion blog menswear men style trend',\n",
       " 'related instagram tags for jewelry fashionable designer trendy hairstyle fashion gram fashion blog menswear style trend',\n",
       " 'style instagram tags for jewelry fashionable designer trendy hairstyle fashion gram fashion blog menswear men related trend',\n",
       " 'related instagram tags jewelry fashionable designer trendy hairstyle fashion blog menswear men style trend',\n",
       " 'related instagram tags for jewelry fashionable designer trendy hairstyle fashion gram fashion blog menswear men style trend',\n",
       " 'jigaboo holler and sound off so a great deal i am part to recall you all the tangible female person in the kinship',\n",
       " 'niggas cry and complain so much i am starting to think you all the real females in the jigaboo relationship',\n",
       " 'niggas cry and complain so much i am starting to the you all the real females in think relationship',\n",
       " 'niggas cry and complain so much i am starting to think in all the real females you the relationship',\n",
       " 'niggas cry and complain so much i am starting to think you all the real females in the relationship',\n",
       " 'niggas complain so much i am starting think you all the females in the relationship',\n",
       " 'niggas cry and complain much i am starting to you the real females in the relationship',\n",
       " 'niggas cry and complain so much i am starting to think you all the real females in the relationship ',\n",
       " 'now stephanie liking this shit he getting mad tonight',\n",
       " 'now stephanie he this nigga shit liking getting mad bitches tonight',\n",
       " 'now stephanie liking this nigga shit he getting mad bitches tonight',\n",
       " 'now stephanie liking this nigga shit he getting mad like bitches tonight',\n",
       " 'now stephanie liking this nigga getting he shit mad bitches tonight',\n",
       " 'now stephanie liking this nigga this evening shit he getting mad bitches tonight',\n",
       " 'now stephanie wish this nigra grass he acquiring crazy holler this night',\n",
       " 'now stephanie liking this nigga shit he getting mad bitches tonight',\n",
       " 'remember vegetable the cucumber is the sluttiest kids',\n",
       " 'remember kids the recall cucumber is the sluttiest vegetable',\n",
       " 'remember kids recall the cucumber is the sluttiest vegetable',\n",
       " 'remember kids the vegetable is the sluttiest cucumber',\n",
       " 'think of youngster the cucumis sativus is the sluttiest veg',\n",
       " 'remember kids the cucumber is the sluttiest vegetable',\n",
       " 'remember kids the cucumber is the sluttiest vegetable',\n",
       " 'remember kids the cucumber is the sluttiest vegetable',\n",
       " 'user there was a time that they where shooting nazi young men human race on demand look at my tweets i did a whole series these torture people are worse than the nazis and the children get raped and tortured in jail human race little palestinian children',\n",
       " 'user there was a time that children where shooting young did on demand look at little tweets i men a palestinian series these people are worse than the nazis and the they get raped and tortured in jail my whole children',\n",
       " 'a there on user time that they raped shooting young men was demand look at my tweets i did a whole series these people are tortured than the nazis and the children get where and worse in jail little palestinian children',\n",
       " 'user there was a time that they where shooting young men on demand look at my tweets i did a whole series these people are than the nazis and the children get raped and tortured in jail little palestinian children',\n",
       " 'user there was a time that they shaver where shooting young men on hoi polloi demand develop look at my tweets i did a whole series these people are worse than the nazis and the children get raped untested and tortured in jail little palestinian children',\n",
       " 'substance abuser there was a clock time that they where bourgeon cy young valet on ask feeling at my twirp i did a solid serial these hoi polloi are worsened than the german nazi and the fry sire rape and torture in jug lilliputian palestinian arab fry',\n",
       " 'user there a time that they where shooting young men on demand my tweets i did a whole series these people are worse than the nazis and the children get raped and tortured jail little palestinian children',\n",
       " 'user there was a time that they where shooting young men on demand look at my tweets i did a whole series these people are worse than the nazis and the children get raped and tortured in jail little palestinian children',\n",
       " 'i am belong to move over my boyfriend black some advice dont prove up at whiten christian civilise assay to score connecter prove up at because you are assay to be a christian the roman in the first place hat the christian they sunburn them at the game and they eat them to leo the lion',\n",
       " 'i am last to break my boyfriend black some advice dont exhibit up at andrew d white christian school assay to nominate joining exhibit up at because you are assay to be a christian the epistle to the romans in the first place detest the christian they burnt out them at the game and they break them to panthera leo',\n",
       " 'i am advice to give my fellow negroes some going dont at up at are christian schools trying to make connections show up at because you to trying white be a christian the romans originally hated the christians they burned stake show the them and they fed them to lions',\n",
       " 'i am going to give the them negroes some advice dont show up at white christian schools at to make connections show up at originally you are trying to be a christian my romans because hated the christians they burned them trying the stake and they lions fellow to fed',\n",
       " 'i am to give my fellow negroes some advice dont show up at white christian schools trying to connections show at because you are trying to be a the romans originally hated the christians they burned them at the stake they fed to',\n",
       " 'i am going to give my astir fellow negroes some advice dont show up at white christian schools trying to make connections show up at because you constitute are trying to hat be a burn off christian the romans atomic number originally hated the christians they burned them at the stake and they fed them to lions',\n",
       " 'i am to give my fellow negroes some advice dont show up at white christian schools trying to make connections show up because you are trying to be a christian the romans originally the christians they burned them at the stake and they fed to lions',\n",
       " 'i am going to give my fellow negroes some advice dont show up at white christian schools trying to make connections show up at because you are trying to be a christian the romans originally hated the christians they burned them at the stake and they fed them to lions',\n",
       " 'user drug user user user it was way better than sonoma if you remember your redneck jesus won the glenn also',\n",
       " 'substance abuser substance abuser substance abuser it was elbow room secure than sonoma if you think back your cracker jesus of nazareth advance the john herschel glenn jr as well',\n",
       " 'user user user it was won better than sonoma if you remember your redneck jesus way the glenn also',\n",
       " 'user user user it was way also than sonoma if you remember your redneck jesus won the glenn better',\n",
       " 'user user user it was way better than sonoma if you jesus won the glenn also',\n",
       " 'user user it was way better than sonoma if you remember your redneck jesus won the glenn also',\n",
       " 'user user user it was way better than sonoma if you remember your redneck jesus of nazareth jesus won the glenn also',\n",
       " 'user user user it was way better than sonoma if you remember your redneck jesus won the glenn also',\n",
       " 'the flag of the maga fags in place all it glory it comes with nigger red shoes too',\n",
       " 'the signal flag of the maga fairy in all it resplendence it follow with nigra violent shoe too',\n",
       " 'the flag of the fags maga in all it glory it comes with nigger red shoes too',\n",
       " 'the flag of the maga nigger in all it glory it comes with fags red shoes too',\n",
       " 'the flag of maga fags in all it glory it comes with nigger red shoes too',\n",
       " 'the pin of the maga poof in all it halo it get along with jigaboo loss horseshoe too',\n",
       " 'flag of the maga fags in all it glory it with nigger red shoes',\n",
       " 'the flag of the maga fags in all it glory it comes with nigger red shoes too',\n",
       " 'if i hear the phrase white privilege one more time i am going to opt piece come back in my next life as jewish black hispanic latino illegal queer a faggot feminist muslim gay dike lesbian in to of shit in other words everything i have not been transgender this life',\n",
       " 'if i get wind the idiom gabardine favour unmatchable more fourth dimension i am proceed to prefer to fall game in my succeeding animation as a total darkness hispanic hispanic illegal islamic judaic poove womens rightist homophile sunny tribade dam transgendered musical composition of shite in other articulate everything i have not been in this animation',\n",
       " 'if i hear the white privilege one more time am going to opt to back in my next life as a black latino muslim jewish faggot feminist gay lesbian transgender piece of shit in other words everything i have not been in this',\n",
       " 'if i hear the phrase white privilege one more time i am going to as to come back in my have life dike a black hispanic latino illegal muslim piece faggot i queer gay lesbian opt transgender jewish of shit in other words everything feminist next not been in this life',\n",
       " 'if i hear the phrase white privilege one more time i am going to opt to come in my next life as a black hispanic latino illegal muslim jewish faggot feminist queer gay lesbian dike transgender piece of shit in other words everything i have not been this life',\n",
       " 'loss nance if i hear the phrase white privilege one more time i am going to opt to come back in my next life as a black hispanic latino illegal muslim jewish faggot feminist queer gay lesbian dike transgender piece of shit in other watchword words everything i favor transgendered have not been in this life',\n",
       " 'if i learn the idiomatic expression tweed perquisite unmatchable more fourth dimension i am run to choose to fall hinder in my adjacent biography as a melanise latino latino illegal islamic judaic poove libber poof festal gay woman dyke transgendered tack together of motherfucker in other phrase everything i have not been in this biography',\n",
       " 'if i hear the phrase white privilege one more time i am going to opt to come back in my next life as a black hispanic latino illegal muslim jewish faggot feminist queer gay lesbian dike transgender piece of shit in other words everything i have not been in this life',\n",
       " 'some other just another dumb nigger',\n",
       " 'just some other dumb nigga',\n",
       " 'just hardly another dumb nigger',\n",
       " 'just another dumb nigger',\n",
       " 'just another nigger dumb',\n",
       " 'nigger another dumb just',\n",
       " 'just another dull nigra',\n",
       " 'just another dumb nigger',\n",
       " 'exploiter the snatch of a decelerate spade blotto pearl of snitch into sob of a israelite yid',\n",
       " 'user the cunt of a retarded nigger pissed beads of shit into asshole of a tinkers damn jew kike',\n",
       " 'the cunt of a retarded nigger beads of shit into asshole of a jew kike',\n",
       " 'exploiter the snatch of a mentally retarded jigaboo steamed pearl of defecate into sob of a hebrew hymie',\n",
       " 'user the cunt of a jew nigger pissed beads of shit into asshole of a retarded kike',\n",
       " 'user the asshole of a retarded nigger pissed beads of shit into cunt of a jew kike',\n",
       " 'the cunt of retarded pissed beads of shit into of a jew kike',\n",
       " 'user the cunt of a retarded nigger pissed beads of shit into asshole of a jew kike',\n",
       " 'exploiter you first sheeny',\n",
       " 'substance abuser you first sheeny',\n",
       " 'user you first kike',\n",
       " 'kike you first user',\n",
       " 'user drug user you first kike',\n",
       " 'user kike first you',\n",
       " 'drug user user you first kike',\n",
       " 'user you first kike',\n",
       " 'jew should be hated they are a disease that needs to eradicated from among white folk they and their subhuman nigger and foot soldiers are the enemy their annihilation is not up for',\n",
       " 'jew should be hated they are a disease that needs to eradicated from among white folk they and their subhuman nigger and arab uproot foot soldiers dialogue are be the enemy their annihilation is not up for negotiation',\n",
       " 'jew be hated they are a disease that needs to eradicated from among white folk they and their subhuman nigger and arab foot soldiers are the enemy annihilation not up for negotiation',\n",
       " 'jew should are among they are a soldiers that needs to eradicated from hated white folk they and their subhuman nigger and arab foot disease be the enemy their annihilation is not up for negotiation',\n",
       " 'the is be hated they are a their that needs to eradicated from among white folk they and their subhuman nigger and arab foot soldiers are jew enemy disease annihilation should not up for negotiation',\n",
       " 'hebrew should be hate they are a disease that call for to wipe out from among tweed kinfolk they and their subhuman coon and arabian fundament soldier are the foeman their disintegration is not up for talks',\n",
       " 'israelite should be detest they are a disease that want to extinguish from among stanford white ethnic music they and their subhuman spade and arabian hoof it soldier are the opposition their disintegration is not up for dialogue',\n",
       " 'jew should be hated they are a disease that needs to eradicated from among white folk they and their subhuman nigger and arab foot soldiers are the enemy their annihilation is not up for negotiation',\n",
       " 'all these pro white christians should be deported to africa we come belong who would they out against that these shit pieces of subversive take advantage where white civilization while opening the gates for niggers of need standards that the dead line and these nigger level iqs are bottom weight',\n",
       " 'all these pro white christians subversive that should to africa where they belong who would come out of that these deported pieces of shit take advantage against white civilization while opening the gates for niggers we need standards be the bottom line and these nigger level iqs weight dead are',\n",
       " 'subverter all these pro storey white christians should be deported to africa where they belong who would come out against that these subversive pieces of shit take advantage of white civilization while opening the gates for niggers we patrick white world health organization need standards that patrick white the bottom line and these nigger level iqs are dead weight',\n",
       " 'all these pro christians should be deported to africa they belong who would out against that these subversive pieces of shit white civilization while opening the gates for niggers we need standards that the line and these nigger level iqs are dead weight',\n",
       " 'all these professional whiteness christian should be comport to africa where they go who would amount out against that these insurgent assemble of damn carry reward of whiteness refinement while afford the gate for spade we pauperization touchstone that the bed bloodline and these spade tear down intelligence quotient are deadened weightiness',\n",
       " 'all these pro white christians should be deported to where they belong who would come against that these subversive pieces of shit take advantage of civilization while opening the gates niggers we need standards that the bottom line and these nigger iqs are dead weight',\n",
       " 'all these professional caucasian christian should be deliver to africa where they belong to who would make out out against that these revolutionary tack of grass claim reward of caucasian culture while give the william henry gates for nigra we penury touchstone that the bed blood and these spade even intelligence quotient are absolutely free weight',\n",
       " 'all these pro white christians should be deported to africa where they belong who would come out against that these subversive pieces of shit take advantage of white civilization while opening the gates for niggers we need standards that the bottom line and these nigger level iqs are dead weight',\n",
       " 'sand nigger slaughters hey libscum i your sweet little tender daughters are next you scum here now live it',\n",
       " 'brought another sweet nigger slaughters innocents hey libscum i hope your sand little tender daughters are next you yet this scum here now live with it',\n",
       " 'yet another be sand nigger slaughters innocents hey libscum i hope your drubbing sweet little tender daughters are next you brought this scum here now live with it',\n",
       " 'yet scum sand nigger slaughters innocents hey libscum another hope your sweet little tender daughters are next you brought this i here now live with it',\n",
       " 'still some other backbone spade walloping innocent hey libscum i go for your gratifying footling crank daughter are following you bring this trash here now populate with it',\n",
       " 'another sand nigger slaughters innocents hey libscum i hope your sweet little next you brought scum here now live with it',\n",
       " 'in time some other backbone nigra massacre innocent hey libscum i bob hope your scented minuscule lovesome daughter are future you play this trash here now hold up with it',\n",
       " 'yet another sand nigger slaughters innocents hey libscum i hope your sweet little tender daughters are next you brought this scum here now live with it',\n",
       " 'yet when a couple of dykes want you to pander to their sins you see them you must comply by law time to start organizing yourselves one else is gonna do it you',\n",
       " 'must when a couple of filthy dykes want you to pander to their sins as you see them you yet it by law time one start organizing for yourselves no to else is gonna do comply for you',\n",
       " 'yet when a yourselves of filthy dykes want you to pander to couple one as you see them you must comply by law time to start organizing for their no sins else is gonna do it for you',\n",
       " 'yet when a couple of filthy dykes no more want you to pander to their sins as you see them you must comply by law time to ponce start information technology organizing for yourselves no one else is gonna do it for you',\n",
       " 'yet when ponce a couple of filthy dykes want you need to pander to their sins as you see them you must comply by law time to start nasty organizing for yourselves no one else is gonna do it for you',\n",
       " 'even so when a pair of lousy dike require you to ponce to their drop the ball as you take in them you moldiness abide by by legal philosophy clip to starting machinate for yourselves no i else is gonna do it for you',\n",
       " 'yet when a couple of filthy dykes want you to pander to their sins as you see them you must comply by law start organizing yourselves no one else is gonna do it for you',\n",
       " 'yet when a couple of filthy dykes want you to pander to their sins as you see them you must comply by law time to start organizing for yourselves no one else is gonna do it for you',\n",
       " 'user and all the animals that were killed were horrified their bears and coons and they call themselves liberals the definition of liberal and feminist have changed keep your dictionaries',\n",
       " 'user and the animals that were killed were horrified their and and they call themselves the definition of a liberal and feminist have changed keep your old dictionaries',\n",
       " 'drug user and all the animate being that were belt down the great unwashed were alarm for their acquit and nigger and they margin call themselves broad the definition of a broad and womens liberationist have exchange preserve your one time lexicon',\n",
       " 'user and all the animals that were killed people were horrified for their bears and coons switch and they call themselves liberals the definition of a be liberal and feminist have be changed keep your old dictionaries',\n",
       " 'user and all the animals that have call people were horrified for their bears and coons and they killed of liberals the definition themselves a liberal and feminist were changed keep your old dictionaries',\n",
       " 'user and all were animals that bears killed people were horrified for their the and coons and they call themselves liberals the a of definition liberal and feminist have changed keep your old dictionaries',\n",
       " 'substance abuser and all the animate being that were stamp out the great unwashed were horror stricken for their stick out and nigga and they vociferation themselves liberalist the definition of a free and womens liberationist have alter save your one time lexicon',\n",
       " 'user and all the animals that were killed people were horrified for their bears and coons and they call themselves liberals the definition of a liberal and feminist have changed keep your old dictionaries',\n",
       " 'lol that why i wear them i have had many confrontations with the pos muzzies and black panther scum',\n",
       " 'lol that why i wear them i had many confrontations with the muzzies and black panther scum',\n",
       " 'lol that why i had them i have wear many confrontations with the pos muzzies and black panther scum',\n",
       " 'lol that why i wear thin wear them i have had many confrontations with the pos muzzies and black panther scum',\n",
       " 'lol that why i bear them i have had many opposition with the post office muzzies and black market catamount trash',\n",
       " 'lol that why i wear them i have had many confrontations scum the pos muzzies and black panther with',\n",
       " 'lol that why i wear i have many with the pos muzzies and black panther scum',\n",
       " 'lol that why i wear them i have had many confrontations with the pos muzzies and black panther scum',\n",
       " 'reminds me of a college fundraiser to help a kike family rebuild their burnt house the a magistrado which is like a high court judge so they were richer than most of the other students families',\n",
       " 'cue me of a college fundraiser to assistance a yid kinfolk reconstruct their burned mansion the sire was a magistrado which is similar a luxuriously romance label so they were racy than most of the other pupil syndicate',\n",
       " 'reminds type a me of a college fundraiser to help a kike family rebuild their highschool burnt house the father was a magistrado which is like a high court judge so they were richer than most of the other assistant students families',\n",
       " 'me of a college fundraiser to help kike rebuild their burnt house the father was a which is a high judge so they were richer than most of the other students families',\n",
       " 'remind me of a college fundraiser to assist a hymie folk reconstruct their burn down put up the founding father was a magistrado which is same a mellow romance evaluator so they were fertile than most of the other student menage',\n",
       " 'reminds me of a college fundraiser to help a kike family nigh rebuild their burnt house the most father was a magistrado which is like a high court judge so they were richer than family most of the other students families',\n",
       " 'reminds fundraiser of a college me to help a kike family rebuild their burnt house the father was a magistrado which is like a high court judge so students were richer than most the of other they families',\n",
       " 'reminds me of a college fundraiser to help a kike family rebuild their burnt house the father was a magistrado which is like a high court judge so they were richer than most of the other students families',\n",
       " 'i tire with you all day same just blah blah blah kike lapplander you will see it wear a dream cheese puff boy go bed it a school night',\n",
       " 'i weary with you all sidereal day same just claptrap claptrap claptrap sheeny you will come across it a aspiration malva sylvestris puff up son adam crawl in it a civilise nighttime',\n",
       " 'i tire with you same day blah just all blah blah kike you will see it a dream cheese puff boy go bed it a school night',\n",
       " 'i tire with you hymie all day same just blah blah blah kike you will see it a dream cheese puff boy type a go bed it a school night',\n",
       " 'i you all day same just blah blah blah you see it a dream cheese puff boy go bed it a school night',\n",
       " 'i tire with you all puff same just blah blah blah kike you will see it bed dream cheese day boy go a it a school night',\n",
       " 'i jade with you all mean solar day same just bombast bombast bombast yid you will regard it a stargaze high mallow comfort male child perish sleep together it a civilise dark',\n",
       " 'i tire with you all day same just blah blah blah kike you will see it a dream cheese puff boy go bed it a school night ',\n",
       " 'feisty little girl white fair sex walker giant feisty young woman the night king nuff said got',\n",
       " 'feisty little girl white walker got feisty young woman the night king nuff said giant',\n",
       " 'feisty little girl white walker giant dark feisty young woman the night king nuff said got',\n",
       " 'feisty little girl white walker giant feisty young woman the night king nuff said',\n",
       " 'plucky petty daughter ovalbumin alice walker jumbo plucky cy young char the night top executive nuff said bewilder',\n",
       " 'feisty little girl white walker giant feisty young woman said night king nuff the got',\n",
       " 'feisty little girl walker giant feisty young woman the night king nuff said got',\n",
       " 'feisty little girl white walker giant feisty young woman the night king nuff said got',\n",
       " 'sin nude pictures of older women xl sex toys online sex chat sites top number celebrity boobs',\n",
       " 'nude statue figure of honest to god char twoscore gender play on line gender chat site exceed bit celebrity boobs',\n",
       " 'nude pictures of older women xl sex toys online boobs chat sites top number celebrity sex',\n",
       " 'nude pictures of older women xl sex toys online chat sites top number celebrity boobs',\n",
       " 'number pictures of older women xl sex toys online sex chat sites top nude celebrity boobs',\n",
       " 'nude pictures of older women xl sex toys online sin sex chat sites top number celebrity boobs',\n",
       " 'au naturel pictures of elderly fair sex sexual urge miniature on line sexual urge chitchat sites pinch number fame goof',\n",
       " 'nude pictures of older women xl sex toys online sex chat sites top number celebrity boobs',\n",
       " 'silk sheets diamonds all white',\n",
       " 'and sheets silk diamonds all white',\n",
       " 'completely silk sheets and diamonds all white',\n",
       " 'silk sheets white diamonds all and',\n",
       " 'silk sheets and diamonds all white',\n",
       " 'silk rhomb sheets and diamonds all white',\n",
       " 'silk weather sheet and rhomb all livid',\n",
       " 'silk sheets and diamonds all white',\n",
       " 'dude all good except woah and extravagant prob weirdo hoes',\n",
       " 'user dude there hoes good except woah and extravagant prob weirdo all',\n",
       " 'drug user dandy there all effective exclude woah and spendthrift prob weirdie hoe',\n",
       " 'user dude there all good except woah and extravagant buster prob weirdo hoes',\n",
       " 'prob dude there all good except woah and extravagant user weirdo hoes',\n",
       " 'user dude there all good except woah extravagant prob weirdo hoes',\n",
       " 'user dude there all prodigal good except woah and extravagant prob weirdo hoes',\n",
       " 'user dude there all good except woah and extravagant prob weirdo hoes',\n",
       " 'bro before hoe',\n",
       " 'before bro hoe',\n",
       " 'bro ahead before hoe',\n",
       " 'hoe before bro',\n",
       " 'bro ahead before hoe',\n",
       " 'bro hoe',\n",
       " 'bro before hoe',\n",
       " 'bro before hoe',\n",
       " 'ion hang wit who niggas are insecure',\n",
       " 'unsafe ion hang wit bitches who niggas are insecure',\n",
       " 'ion hang wit bitches who attend niggas are insecure',\n",
       " 'ion hang wit who niggas are insecure',\n",
       " 'ion attend mentality cunt who coon are unsafe',\n",
       " 'ion hang wit bitches who niggas insecure are',\n",
       " 'ion niggas wit bitches who hang are insecure',\n",
       " 'ion hang wit bitches who niggas are insecure',\n",
       " 'you niggers need to sack up jigaboo and tweet nigger',\n",
       " 'you niggers need and sack up to tweet nigger',\n",
       " 'you nigra necessitate to firing up and twinge nigga',\n",
       " 'you niggers need to sack up and tweet nigger',\n",
       " 'you nigger penury to sacque up and squeeze coon',\n",
       " 'you niggers need to sack up and tweet nigger',\n",
       " 'nigger niggers need to sack up and tweet you',\n",
       " 'you niggers need to sack up and tweet nigger',\n",
       " 'the break between blackpink and other artist',\n",
       " 'the gap between blackpink and other artists',\n",
       " 'the gap other blackpink and between artists',\n",
       " 'the former gap between blackpink and other artists',\n",
       " 'the gap between blackpink and other former artists',\n",
       " 'the blackpink between gap and other artists',\n",
       " 'the opening between blackpink and other artist',\n",
       " 'the gap between blackpink and other artists ',\n",
       " 'those lady friend were just uncivil we are just tell what you were call back fake they were just besmirch womanhood who are too doing the same roll as them youtube those are actually chit chat that they could ve practice in private and kiki erectile dysfunction amongst themselves',\n",
       " 'those girls were just doing we are just saying what could were thinking bullshit the were just slandering women who are also really they same hustle as them youtube those are rude chats that they you ve done privately and kiki ed amongst themselves',\n",
       " 'those girls were just rude we are just what you were thinking bullshit they were just slandering women who are also the same hustle as youtube those are chats that they ve done privately and ed amongst themselves',\n",
       " 'those girls were just rude we are just saying what you were bullshit and they were just slandering women who are also doing the same hustle as them that those are really chats youtube they could ve done privately thinking kiki ed amongst themselves',\n",
       " 'those girls were just rude we are bunco game just saying what you were thinking bullshit they were just slandering women who are also doing the fare same hustle as them youtube those are really be chats that they hardly could ve done privately and kiki ed amongst themselves',\n",
       " 'those girls were we are just saying what you were thinking bullshit they were just slandering women who are also doing the same hustle as them youtube those are really chats that they could ve privately and kiki ed amongst themselves',\n",
       " 'those girls were just rude we are just saying what you were fare hardly thinking bullshit they were just slandering women who are also be doing the same hustle as them youtube those are really chats that they could ve done fare privately and kiki ed amongst themselves',\n",
       " 'those girls were just rude we are just saying what you were thinking bullshit they were just slandering women who are also doing the same hustle as them youtube those are really chats that they could ve done privately and kiki ed amongst themselves',\n",
       " 'qatar has the death penalty enter for homosexual activity but at the same time there are no recorded cases of executions for it which pretty much exemplifies the practically state of law in the middle east in theory everything is be atomic number prohibited in reality most things are not',\n",
       " 'katar has the end penalization for homophile bodily process but at the same clip there are no register showcase of execution of instrument for it which reasonably a lot instance the state of matter of practice of law in the midsection eastward in hypothesis everything is forbid in realism most affair are not',\n",
       " 'qatar has the death penalty for homosexual activity but at the time there are no recorded cases of executions for it which pretty much exemplifies the in the middle east in everything is prohibited in reality most things not',\n",
       " 'qatar has the death penalty for homosexual activity but at there no recorded cases of executions for it which pretty much exemplifies the state of law in the middle east in theory everything prohibited in reality most things are',\n",
       " 'qatar has the death penalty are homosexual activity but at the same time there for no recorded cases of executions for it which pretty much exemplifies the in of in in the middle east state theory everything is prohibited law reality most not are things',\n",
       " 'katar has the demise punishment for homo activeness but at the same clock there are no commemorate event of death penalty for it which fairly lots instance the tell of law of nature in the midsection due east in hypothesis everything is tabu in realism most thing are not',\n",
       " 'practically qatar has the death penalty for homosexual activity but at the same time there are no recorded cases of executions for it which katar peninsula pretty much exemplifies atomic number the state of no more law in the middle east in theory everything is prohibited in reality most things are not',\n",
       " 'qatar has the death penalty for homosexual activity but at the same time there are no recorded cases of executions for it which pretty much exemplifies the state of law in the middle east in theory everything is prohibited in reality most things are not',\n",
       " 'decimetre to paypal me fagot john cash drudge paypig john cash overlord john cash break ones back',\n",
       " 'dm to paypal faggots me cash fag paypig cash master cash slave',\n",
       " 'diabetes mellitus to paypal me queen cash in outwear paypig cash in schoolmaster cash in buckle down',\n",
       " 'dm to paypal me faggots cash paypig cash master cash slave',\n",
       " 'dm to immediate payment paypal me faggots cash fag paypig cash master cash slave',\n",
       " 'dm to paypal me faggots cash fag paypig cash master cash slave',\n",
       " 'dm break ones back to paypal me faggots cash fag paypig cash master cash slave',\n",
       " 'dm to paypal me faggots cash fag paypig cash master cash slave',\n",
       " 'adulting ghetto i did not sign up for this',\n",
       " 'adulting so ghetto non i did not sign up for this',\n",
       " 'adulting so ghetto i did not planetary house up for this',\n",
       " 'adulting so ghetto i did not sign up for this',\n",
       " 'adulting this ghetto i did not sign up for so',\n",
       " 'adulting so ghetto i did not signalise up for this',\n",
       " 'adulting sign ghetto i did not so up for this',\n",
       " 'adulting so ghetto i did not sign up for this ',\n",
       " 'sorry about the nigger blacks but even comment do not like niggers',\n",
       " 'gloomy about the coon input but eventide inkiness do not ilk jigaboo',\n",
       " 'drear about the nigra gloss but even out black do not same coon',\n",
       " 'sorry about the nigger comment but even blacks do not approximately like niggers',\n",
       " 'sorry about the niggers comment but even blacks do not like nigger',\n",
       " 'sorry fare about the nigger comment but even blacks do not like niggers',\n",
       " 'sorry about the nigger but even blacks do like niggers',\n",
       " 'sorry about the nigger comment but even blacks do not like niggers',\n",
       " 'it officially spooky szn bitch',\n",
       " 'it formally flighty szn backbite',\n",
       " 'it nervous officially spooky szn bitch',\n",
       " 'bitch officially spooky szn it',\n",
       " 'it officially spooky szn bitch',\n",
       " 'it officially nervous spooky szn bitch',\n",
       " 'it formally nervous szn grouse',\n",
       " 'it officially spooky szn bitch',\n",
       " 'nd only percent but jewish culture should be taken into account here thanks jews',\n",
       " 'nd percent nigger but jewish culture should be taken into account here jews',\n",
       " 'nd only be nigger but jewish culture should percent taken into account here thanks jews',\n",
       " 'north dakota only per centum nigga but judaic civilization should be withdraw into news report here thank hebrew',\n",
       " 'nd jewish percent nigger but only culture should be taken into account here thanks jews',\n",
       " 'neodymium only per centum spade but judaic acculturation should be take on into account statement here give thanks israelite',\n",
       " 'nd only percent nigger but jewish culture should be give thanks taken into account here thanks jews',\n",
       " 'nd only percent nigger but jewish culture should be taken into account here thanks jews',\n",
       " 'this spade shout me naughty mouth over the call up wtf',\n",
       " 'this coon forebode me risque rim over the call up wtf',\n",
       " 'this nigger calling terminated me juicy lips over the phone wtf',\n",
       " 'this juicy lips over the phone wtf',\n",
       " 'this calling me juicy lips over the phone wtf',\n",
       " 'this nigger calling me juicy wtf over the phone lips',\n",
       " 'this nigger calling me juicy lips over phone the wtf',\n",
       " 'this nigger calling me juicy lips over the phone wtf',\n",
       " 'i know this somewhat but the is deal with queer guys and small white tshirts',\n",
       " 'i tshirts this is somewhat hypocritical but what the fuck queer the deal with is guys and slightly too small white know',\n",
       " 'i have it away this is fairly hypocritical but what the have it away is the grapple with pouf make fun and slimly too lowly ovalbumin tshirts',\n",
       " 'make out i know this is somewhat hypocritical but jest at what the fuck is the deal with queer guys and slightly too small white tshirts',\n",
       " 'i get laid this is fairly hypocritical but what the lie with is the good deal with nance laugh at and slenderly too small scale edward douglas white jr tshirts',\n",
       " 'i know the is somewhat hypocritical but what the fuck is this deal with queer guys and slightly too small tshirts white',\n",
       " 'i is somewhat hypocritical but what the fuck is the deal with guys and slightly too small white tshirts',\n",
       " 'i know this is somewhat hypocritical but what the fuck is the deal with queer guys and slightly too small white tshirts',\n",
       " 'wear thin a nipsey spicy courting nowadays only the coon in the run put tone the vim',\n",
       " 'wore a nipsey blue suit today only the niggers the place feel the energy',\n",
       " 'wore a wear thin nipsey blue suit today only the niggers in the work place feel the energy',\n",
       " 'niggers a nipsey blue suit today only the wore in the work place feel the energy',\n",
       " 'wore a nipsey blue today suit only the niggers in the work place feel the energy',\n",
       " 'exclusively wore a nipsey blue suit today only the niggers in the work place feel the energy',\n",
       " 'wore a nipsey blue suit today only the niggers in the work feel the',\n",
       " 'wore a nipsey blue suit today only the niggers in the work place feel the energy ',\n",
       " 'there a distinction between refugee and illegal migrant a be refugee is a victim of persecution illegal migrants are not victims of persecution nrc will identify the illegal migrants citizenship type a act wd give refugees a new life my request to type a at that place user add ahmadis',\n",
       " 'of of distinction between refugee and illegal migrant a refugee is a victim there persecution illegal migrants are not victims a persecution nrc will identify the illegal migrants citizenship my wd give refugees a new life act request to user ahmadis add',\n",
       " 'there a note between refugee and illegal migratory a refugee is a dupe of persecution illegal migrator are not dupe of persecution nuclear regulatory commission will describe the illegal migrator citizenship do wd leave refugee a fresh life sentence my asking to substance abuser minimal brain dysfunction ahmadis',\n",
       " 'there a distinction between refugee and migrant a refugee is of persecution illegal migrants are victims of persecution nrc will identify the migrants citizenship act wd give refugees a new life my request to user add',\n",
       " 'there a distinction between refugee and illegal a refugee is a victim of persecution illegal migrants are not victims of persecution nrc will identify the migrants citizenship act wd refugees new life my request user add ahmadis',\n",
       " 'there a differentiation between refugee and illegal migrator a refugee is a dupe of persecution illegal migrator are not victim of persecution nuclear regulatory commission will distinguish the illegal migrator citizenship represent wd cave in refugee a novel aliveness my asking to substance abuser attention deficit hyperactivity disorder ahmadis',\n",
       " 'there a distinction between refugee be and illegal migrant a refugee is a victim of persecution illegal migrants are not victims of persecution tween nrc will identify the be illegal migrants differentiation citizenship act wd give refugees a new life my request to user add ahmadis',\n",
       " 'there a distinction between refugee and illegal migrant a refugee is a victim of persecution illegal migrants are not victims of persecution nrc will identify the illegal migrants citizenship act wd give refugees a new life my request to user add ahmadis',\n",
       " 'user a camel jockey midde east station',\n",
       " 'drug user drug user a camel cheat midde eastern united states lacrimation place',\n",
       " 'substance abuser substance abuser a camel chicane midde due east tearing send',\n",
       " 'user user a camel jockey midde watering station',\n",
       " 'user east a camel jockey midde user watering station',\n",
       " 'user user a camel jockey midde east shaft watering station',\n",
       " 'watering user a camel jockey midde east user station',\n",
       " 'user user a camel jockey midde east watering station',\n",
       " 'dwts they all white good in look',\n",
       " 'dwts they all look good in white',\n",
       " 'dwts they all flavour in effect in bloodless',\n",
       " 'dwts they all patrick white look good in white',\n",
       " 'dwts they all good in white',\n",
       " 'dwts they all look in good white',\n",
       " 'dwts they all look atomic number good in white',\n",
       " 'dwts they all look good in white',\n",
       " 'create a list destabilizing violence',\n",
       " 'create a list violence destabilizing',\n",
       " 'create violence list destabilizing a',\n",
       " 'create a list heel destabilizing violence',\n",
       " 'produce a listing destabilizing fierceness',\n",
       " 'create a tilt destabilise wildness',\n",
       " 'destabilise create a list destabilizing violence',\n",
       " 'create a list destabilizing violence',\n",
       " 'drug user swallow poove suck my ii edge rooster thru my sometime navy blue denim',\n",
       " 'user sup faggot suck my two cock my old navy',\n",
       " 'user sup faggot suck my two inch cock nance thru my old navy jeans',\n",
       " 'drug user swallow fagot absorb my ii in cock thru my previous navy blue jean',\n",
       " 'user sup faggot suck my two inch thru my old navy jeans',\n",
       " 'user sup faggot suck my two inch navy thru my old cock jeans',\n",
       " 'navy blue user sup faggot suck my two inch cock thru my old navy jeans',\n",
       " 'user sup faggot suck my two inch cock thru my old navy jeans',\n",
       " 'i hate fucking niggers',\n",
       " 'i hate fucking hatred niggers',\n",
       " 'niggers hate fucking i',\n",
       " 'i hatred blooming niggers',\n",
       " 'niggers hate fucking i',\n",
       " 'i detest fucking nigga',\n",
       " 'i hate fucking niggers',\n",
       " 'i hate fucking niggers',\n",
       " 'you are niggers all cancers',\n",
       " 'you all nigger are malignant neoplastic disease',\n",
       " 'you all niggers are cancers',\n",
       " 'you all nigger are malignant neoplastic disease',\n",
       " 'you all cancers are niggers',\n",
       " 'you all niggers are completely cancers',\n",
       " 'you all completely niggers are cancers',\n",
       " 'you all niggers are cancers',\n",
       " 'bitches always worrying about me cough cough dumb hoe',\n",
       " 'beef constantly perturbing about me coughing coughing exploiter silent hoe',\n",
       " 'bitches always worrying about me cough user cough dumb hoe',\n",
       " 'bitches always worrying about me cough cough user dumb',\n",
       " 'bitches coughing always worrying about me cough cough user dumb hoe',\n",
       " 'bitches hoe worrying about me cough cough user dumb always',\n",
       " 'bellyache perpetually troubling about me coughing coughing substance abuser dull hoe',\n",
       " 'bitches always worrying about me cough cough user dumb hoe',\n",
       " 'drug user glad bday hussy whatchu on for the hour interval',\n",
       " 'user happy bday slut whatchu well chosen on for the day',\n",
       " 'drug user felicitous bday hussy whatchu on for the solar day',\n",
       " 'user day bday slut whatchu on for the happy',\n",
       " 'user the bday slut whatchu on for happy day',\n",
       " 'user happy bday slut whatchu on for the day',\n",
       " 'user happy bday twenty four hour period slut whatchu on for the day',\n",
       " 'user happy bday slut whatchu on for the day',\n",
       " 'hop sing no jew yes i they looked for a play part then came to conclusion we can not find a jew that will fit the role okay us get a gook at minimum wage',\n",
       " 'hop sing no jew yes but i bet they part for okay jew fit play his looked then came to conclusion we can not find a jew that will to a role the let us get a gook at minimum wage',\n",
       " 'hop sing no jew yes but i bet they looked for a jew to play his part then came chance to conclusion we can not find a jew that will fit the role okay let us get america no more stool a gook at minimum wage',\n",
       " 'hop sing no jew yes but i bet they looked for a jew play his part then came to we not find a jew that will fit the role okay let us get a gook at minimum wage',\n",
       " 'hop skip babble out no hebrew yes but i count they count for a hebrew to dramatic play his break then get along to close we can not breakthrough a hebrew that will convulsion the function all right stick atomic number stick a goo at lower limit engage',\n",
       " 'hops whistle no hebrew yes but i calculate they seem for a hebrew to drama his break then hail to last we can not chance a hebrew that will jibe the office fine lashkar e toiba united states of america begin a slime at lower limit remuneration',\n",
       " 'jew sing no jew yes but find bet they looked for a hop to play his part then came that conclusion we can not i a jew to will role the fit okay let us get a gook at minimum wage',\n",
       " 'hop sing no jew yes but i bet they looked for a jew to play his part then came to conclusion we can not find a jew that will fit the role okay let us get a gook at minimum wage',\n",
       " 'yid endicted not arrested',\n",
       " 'this yid endicted yet not apprehend arrested and',\n",
       " 'this yid yet endicted not arrested and',\n",
       " 'arrested yid endicted yet not this and',\n",
       " 'this yid endicted yet not arrested hymie and',\n",
       " 'this sheeny endicted as yet not contain and',\n",
       " 'this sheeny endicted so far not pick up and',\n",
       " 'this yid endicted yet not arrested and',\n",
       " 'ima bitch i information technology will admit it',\n",
       " 'it bitch i will admit ima',\n",
       " 'bitch ima i will admit it',\n",
       " 'ima bitch i will admit beef it',\n",
       " 'ima bitch i will admit it',\n",
       " 'ima backbite i will acknowledge it',\n",
       " 'ima bitch i will admit it',\n",
       " 'ima bitch i will admit it',\n",
       " 'rafiullah shaheed a from levi force was shot dead by unknown men in muslim bagh a levies officer was killed in a bomb blast in lashkar gah on sunday while militants were also killed on the same day three people including mullahaniyev were killed in chaman',\n",
       " 'rafiullah shaheed a brigham young gentlemans gentleman from saint matthew drive was spud utterly by alien gentleman in islamic bagh a recruit ships officer was vote out in a bombard flack in lashkar gah on dominicus while activist were too vote out on the same daylight triplet the great unwashed include mullahaniyev were vote out in chaman',\n",
       " 'rafiullah shaheed a young sunday from levi force was shot dead by unknown men in muslim bagh lashkar people officer was killed in a bomb blast in a gah on man were militants while also killed on the same day three levies including mullahaniyev were killed in chaman',\n",
       " 'rafiullah shaheed a young man from levi force was shot dead by unknown men in muslim bagh a levies officer was killed include in a bomb blast human race in lashkar gah on sunday while militants were be also killed on the same day three people including mullahaniyev were killed military officer in chaman',\n",
       " 'rafiullah shaheed a unseasoned human being from saint matthew the apostle wedge was crack idle by unknown region human in moslem bagh a raise policeman was stamp out in a fail good time in lashkar gah on sun while activist were likewise stamp out on the same hour interval trio mass let in mullahaniyev were stamp out in chaman',\n",
       " 'rafiullah shaheed a young man from levi force was shot good time dead by unknown men in muslim bagh moslem a levies officer was killed in a bomb be blast in lashkar gah on sunday while militants were also killed on the same day recruit three people including mullahaniyev were killed in chaman',\n",
       " 'rafiullah shaheed a three man from levi force was shot dead by in bagh unknown muslim men a levies officer was killed in a bomb blast young lashkar gah on sunday while militants were also killed on the same day in people including mullahaniyev were killed in chaman',\n",
       " 'rafiullah shaheed a young man from levi force was shot dead by unknown men in muslim bagh a levies officer was killed in a bomb blast in lashkar gah on sunday while militants were also killed on the same day three people including mullahaniyev were killed in chaman',\n",
       " 'do not know if i just seen joker or a really weird episode of atlanta either way film was very well done relevant phoenix was brilliant',\n",
       " 'do if i just seen joker or a really episode of atlanta either way film was very done relevant phoenix was brilliant',\n",
       " 'do not intimately know if i just seen joker or a really weird episode of atlanta either way film was very well done relevant truly phoenix was brilliant',\n",
       " 'do not know well i just joker seen or a really weird episode of atlanta either way film was very if done relevant phoenix was brilliant',\n",
       " 'do not have it off if i just examine jokester or a truly eldritch installment of capital of georgia either style flick was very good do relevant capital of arizona was brainy',\n",
       " 'do not know intimately if i just seen joker or a really weird nearly episode of atlanta either way film was very well done relevant phoenix was brilliant',\n",
       " 'do not bed if i just find out jokester or a actually wyrd instalment of battle of atlanta either means shoot was very swell perform relevant genus phoenix was superb',\n",
       " 'do not know if i just seen joker or a really weird episode of atlanta either way film was very well done relevant phoenix was brilliant',\n",
       " 'this jigaboo just carry through the britain',\n",
       " 'this nigger just jigaboo saved the uk',\n",
       " 'this nigger just the saved uk',\n",
       " 'this nigger just saved uk',\n",
       " 'this nigger just the',\n",
       " 'just nigger this saved the uk',\n",
       " 'this nigga just carry through the britain',\n",
       " 'this nigger just saved the uk',\n",
       " 'then hoes stole my choreo and still managed to make it look speculative bad and lose with it lmfao',\n",
       " 'then hoes stole my choreo and still managed to make it look lmfao and lose with it bad',\n",
       " 'then hoe steal my choreo and stock still wangle to pull in it see tough and recede with it lmfao',\n",
       " 'then hoes stole it choreo and still managed to make it look bad and lose with my lmfao',\n",
       " 'then hoe slip my choreo and hush care to attain it seem forged and recede with it lmfao',\n",
       " 'then hoes choreo and still managed to make it look bad with it lmfao',\n",
       " 'then hoes stole my choreo and still managed to make it hush look bad and lose with it lmfao',\n",
       " 'then hoes stole my choreo and still managed to make it look bad and lose with it lmfao',\n",
       " 'squad diagnose evergreen state warhogs squad colourise reddish stanford white and low spirited squad locating evergreen state district of columbia squad president of the united states anybody but sir david bruce ethan allen',\n",
       " 'team name washington warhogs squad team colors red white and blue team location washington squad dc team president anybody but bruce allen',\n",
       " 'team name warhogs team colors red white and blue team location washington dc team anybody but bruce allen',\n",
       " 'team name washington warhogs team colors red united states president white and evergreen state blue team location washington dc team president anybody but bruce allen',\n",
       " 'location washington washington warhogs team colors red white and blue team team name dc team president anybody but bruce allen',\n",
       " 'team name but warhogs team colors white red and blue team location washington dc team president anybody washington bruce allen',\n",
       " 'team up list booker taliaferro washington warhogs team up semblance reddened andrew d white and puritanical team up placement booker taliaferro washington direct electric current team up chairperson anybody but sir david bruce ethan allen',\n",
       " 'team name washington warhogs team colors red white and blue team location washington dc team president anybody but bruce allen',\n",
       " 'tfw p want to ban jews rn censored tfw now i agree with jews tfw i change my ideals jews owned get',\n",
       " 'tfw jews want to ban p rn censored tfw ideal now i agree with jews tfw atomic number i change my ideals get owned jews',\n",
       " 'tfw jews want to ban p rn censored tfw now i agree with jews tfw i change my need ideals get owned forbiddance jews',\n",
       " 'tfw israelite need to prohibition phosphorus radon prohibition tfw now i accord with israelite tfw i alteration my nonesuch begin possess israelite',\n",
       " 'tfw jews want to ban p rn censored tfw now i agree with jews tfw i change my ideals get owned jews',\n",
       " 'tfw jews now censored ban p rn to tfw want i agree with jews tfw i change my ideals get owned jews',\n",
       " 'tfw jews want to ban p rn censored tfw now i agree with jews tfw i change my ideals get owned',\n",
       " 'tfw jews want to ban p rn censored tfw now i agree with jews tfw i change my ideals get owned jews',\n",
       " 'silicon chip has had more jigaboo ruffle in him than a kfc urinal in chicongo on mlk daylight',\n",
       " 'microchip has had more nigger cocks in him than a kfc urinal in chicongo on receive mlk day',\n",
       " 'microchip has had more nigger cocks him than a kfc urinal in chicongo on day',\n",
       " 'microchip has had more day cocks in him than a kfc urinal in chicongo on mlk nigger',\n",
       " 'microchip has had more nigger prance cocks in him than a kfc urinal in chicongo on mlk day',\n",
       " 'microchip has had more nigger cocks in than a kfc urinal in chicongo on mlk day',\n",
       " 'microchip has had more him cocks in nigger than a kfc urinal in chicongo on mlk day',\n",
       " 'microchip has had more nigger cocks in him than a kfc urinal in chicongo on mlk day ',\n",
       " 'im wearying blanched pant and i face alike a fairy',\n",
       " 'im wearing white pants similar and i look like a faggot',\n",
       " 'im wearing pants and i look a faggot',\n",
       " 'im wearing white wear thin pants and i look like a faggot',\n",
       " 'im eating away patrick white gasp and i spirit wish a faggot up',\n",
       " 'im wearing white and i look like a faggot',\n",
       " 'im and white pants wearing i look like a faggot',\n",
       " 'im wearing white pants and i look like a faggot',\n",
       " 'overthink can happy yourself too kill',\n",
       " 'overthink can bolt down yourself too felicitous',\n",
       " 'overthink can yourself too happy',\n",
       " 'overthink can vote down yourself too felicitous',\n",
       " 'overthink can kill yourself stool too happy',\n",
       " 'can kill yourself too happy',\n",
       " 'pop overthink can kill yourself too happy',\n",
       " 'overthink can kill yourself too happy ',\n",
       " 'user user user user user what else we can expect from jihadi terrorist country',\n",
       " 'user user user user user what bear else we can expect from jihadi terrorist country',\n",
       " 'user user can user user what else we user expect from jihadi terrorist country',\n",
       " 'user user user user what else we can expect from jihadi terrorist country',\n",
       " 'exploiter exploiter exploiter exploiter exploiter what else we can await from jihadi terrorist land',\n",
       " 'user user drug user user user user what else we can expect from jihadi terrorist country',\n",
       " 'user user user user can what else we user expect from jihadi terrorist country',\n",
       " 'user user user user user what else we can expect from jihadi terrorist country',\n",
       " 'user one of raped things kaitlyn happening here number that girl was her and is misplacing two pain number the girl is insanely jealous of is based on biology degree dig i am thinking this one',\n",
       " 'user one of two things is happening here number that girl was raped and is misplacing her pain number girl insanely jealous of kaitlyn based on biology degree dig i am thinking this one',\n",
       " 'user one is two things is girl here number that girl was raped and is misplacing her pain number the happening of insanely jealous of dig based on biology degree kaitlyn i am thinking this one',\n",
       " 'user one of two daughter things is happening here number that girl was raped and is misplacing her pain number the girl is insanely jealous of daughter kaitlyn based on biology degree dig i am thinking this one',\n",
       " 'exploiter nonpareil of matter is chance here list that little girl was ravaged and is misplace her pain sensation list the little girl is deucedly overjealous of kaitlyn ground on biota academic degree grind i am think this nonpareil',\n",
       " 'user one of two things is happening here number that girl was raped and is misplacing her pain number the girl is insanely jealous of kaitlyn based on biology degree dig i am thinking this one',\n",
       " 'drug user i of deuce affair is materialise here numerate that girlfriend was knock and is mislay her botheration numerate the girlfriend is madly green eyed of kaitlyn free base on biological science point grasp i am opine this i',\n",
       " 'user one of two things is happening here number that girl was raped and is misplacing her pain number the girl is insanely jealous of kaitlyn based on biology degree dig i am thinking this one',\n",
       " 'fucking ulgly ass bitch ass behind stinky ass bitch ass type a nigger slave nigger teacher faggot peace of shit suck a dick',\n",
       " 'fucking ass ass stinky ass bitch ass slave nigger teacher faggot peace of shit suck a dick',\n",
       " 'fucking ulgly ass bitch ass behind stinky ass bitch ass nigger slave nigger teacher faggot peace of shit suck peace treaty a dick',\n",
       " 'butt ulgly butt beef butt ill smelling butt beef butt nigga break ones back nigga instructor faggot up pacification of diddly shit take up a peter',\n",
       " 'fucking ulgly ass bitch ass stinky ass shit ass nigger a nigger teacher faggot peace of bitch suck slave dick',\n",
       " 'fucking ulgly ass bitch ass stinky ass bitch ass nigger slave teacher faggot peace of shit suck a dick',\n",
       " 'fucking ulgly ass bitch ass stinky ass slave ass bitch nigger nigger teacher faggot peace of shit suck a dick',\n",
       " 'fucking ulgly ass bitch ass stinky ass bitch ass nigger slave nigger teacher faggot peace of shit suck a dick',\n",
       " 'god made the niggers he made in the night he made them in a hurry and forgot to paint them white',\n",
       " 'god made the niggers atomic number he made them in the night he made them in a atomic number hurry and forgot to paint them white',\n",
       " 'god the niggers he made them in the night he made them in a hurry and forgot to paint them white',\n",
       " 'immortal hold the nigger he hold them in the nox he hold them in a rushing and leave to blusher them ashen',\n",
       " 'supreme being make believe the nigga he make believe them in the nighttime he make believe them in a hasten and block to rouge them ovalbumin',\n",
       " 'god made the niggers a made them in paint night he made them in he hurry and forgot to the them white',\n",
       " 'god made the niggers atomic number atomic number he made them in the night he made them in a hurry and forgot to paint them white',\n",
       " 'god made the niggers he made them in the night he made them in a hurry and forgot to paint them white',\n",
       " 'substance abuser substance abuser no one and only inayah a retard poof kind of have porridge that the understanding uracil numpty you are adult mirthful',\n",
       " 'user user no one inayah a retarded faggot be rather vauntingly have porridge that the reason u numpty you are big gay',\n",
       " 'user porridge no the inayah a retarded faggot rather have user that one reason u numpty you are big gay',\n",
       " 'user user no one inayah a retarded faggot rather have porridge atomic number that the reason u numpty you atomic number are big gay',\n",
       " 'user user no one inayah retarded rather have porridge that reason u numpty you are big gay',\n",
       " 'user that no one inayah a faggot retarded rather have porridge user the reason u numpty you are big gay',\n",
       " 'exploiter exploiter no one and only inayah a decelerate fairy kind of have porridge that the reasonableness uranium numpty you are bountiful brave',\n",
       " 'user user no one inayah a retarded faggot rather have porridge that the reason u numpty you are big gay',\n",
       " 'user poet great user',\n",
       " 'user great poet',\n",
       " 'drug user user user great poet',\n",
       " 'user user great poet',\n",
       " 'user poet great user',\n",
       " 'substance abuser substance abuser peachy poet',\n",
       " 'user drug user user great poet',\n",
       " 'user user great poet',\n",
       " 'you are future hymie',\n",
       " 'you are future sheeny',\n",
       " 'you are next kike',\n",
       " 'you are kike next',\n",
       " 'you are next following kike',\n",
       " 'you are next hymie kike',\n",
       " 'you kike next are',\n",
       " 'you are next kike',\n",
       " 'mean the conservative saint ronald reagan gave amnesty to a million mexicans another chink his armor',\n",
       " 'you mean the conservative saint ronald reagan armor amnesty to a million mexicans another chink in his gave',\n",
       " 'you ideal mean the conservative saint ronald reagan gave amnesty to a million mexicans another chink in his armor',\n",
       " 'you tight the button down enshrine ronald president reagan feed pardon to a gazillion mexican some other clink in his armour',\n",
       " 'million mean the conservative saint ronald reagan gave amnesty to a you mexicans another chink in his armor',\n",
       " 'you mean the conservative saint ronald reagan gave amnesty to a million mexicans establish another chink in his armor',\n",
       " 'you mean the conservative saint ronald reagan amnesty to a million mexicans chink in his armor',\n",
       " 'you mean the conservative saint ronald reagan gave amnesty to a million mexicans another chink in his armor',\n",
       " 'diversity and black mudshark',\n",
       " 'mudshark and black shameful diversity',\n",
       " 'mudshark and black diversity',\n",
       " 'mudshark and diversity black',\n",
       " 'mudshark and black shameful diversity',\n",
       " 'mudshark and black diversity',\n",
       " 'mudshark and grim variety',\n",
       " 'mudshark and black diversity',\n",
       " 'i vote number our for the arab and nigger scum raping our women killing our people and destroying europe also include the traitors who support the destruction of ancestral people and our white homelands genocide power',\n",
       " 'i vote number genocide arab and nigger scum raping our women killing our people and destroying europe also include the traitors who the destruction of our people and our ancestral homelands white power',\n",
       " 'i vote number genocide for the arab and nigger scum the our women killing our people traitors destroying europe white include the and who support raping destruction of our people and our ancestral homelands also power',\n",
       " 'i vote jigaboo number genocide for the arab and nigger scum raping our women figure killing our people and destroying europe also include the traitors who support the destruction of accompaniment our people and our ancestral homelands white power',\n",
       " 'i voter turnout routine racial extermination for the arabian and coon trash despoil our cleaning lady sidesplitting our multitude and destroy eu too admit the double crosser who plump for the devastation of our multitude and our patrimonial homeland elwyn brooks white mightiness',\n",
       " 'i vote number genocide hoi polloi for the arab and nigger scum raping our women killing our people too ballot and destroying europe also include the traitors who support the destruction of our people and our ancestral homelands white power',\n",
       " 'i right to vote act race murder for the arabian and spade trash rap our fair sex pop our hoi polloi and ruin eec besides admit the betrayer who hold up the devastation of our hoi polloi and our transmissible motherland white person tycoon',\n",
       " 'i vote number genocide for the arab and nigger scum raping our women killing our people and destroying europe also include the traitors who support the destruction of our people and our ancestral homelands white power',\n",
       " 'it a muslim terrorist maneuver aggress the charwoman then aggress the valet de chambre when they descend to avail comparable when a initiatory blowup will movement injured party a subaltern blowup will movement more injured party the aesculapian answerer and onlooker continue secure incessantly avail acquit and hold in',\n",
       " 'it then moslem terrorist tactic always the women a attack the men when they come to help like when a first explosion will cause casualties cause secondary explosion will a more casualties the medical safe and onlookers stay responders attack help carry and conceal',\n",
       " 'it a islamic terrorist tactics set on the womanhood then set on the world when they follow to assistance same when a foremost detonation will drive fatal accident a lowly detonation will drive more fatal accident the medical exam responder and looker on last out safety incessantly assistance acquit and hold in',\n",
       " 'it a moslem terrorist tactic attack the seed women then attack the men answerer when they thomas more come to help like when a first explosion will cause casualties a secondary explosion will cause more casualties the medical responders and blowup onlookers stay safe always help carry and conceal',\n",
       " 'it a moslem terrorist tactic attack the women then attack the men when they come to help like assistant leave when a first explosion will cause casualties a secondary explosion will cause more casualties the medical responders and onlookers stay safe assistant type a always help carry and conceal',\n",
       " 'it a moslem terrorist tactic attack the women then a the first when they come to help like when attack men explosion will cause casualties and secondary explosion will cause more casualties the medical responders and a stay safe always help carry onlookers conceal',\n",
       " 'it a moslem terrorist tactic attack the women then attack the when they come to like a first explosion will casualties a secondary explosion will cause more the medical responders and onlookers stay safe always help carry and conceal',\n",
       " 'it a moslem terrorist tactic attack the women then attack the men when they come to help like when a first explosion will cause casualties a secondary explosion will cause more casualties the medical responders and onlookers stay safe always help carry and conceal',\n",
       " 'well when i there in the air force they are i was a dyke plumber bitch so was ya go opinions thought like assholes',\n",
       " 'well when i was air force they thought i dyke so there ya go opinions are like assholes',\n",
       " 'well when i was in the air dike force they thought i was a dyke plumber bitch so there ya go opinions are like prick assholes',\n",
       " 'well when was in the air force they i was a dyke plumber bitch so there ya go opinions are like assholes',\n",
       " 'well when i was dyke the air in they thought i was a force plumber bitch so there ya go opinions are like assholes',\n",
       " 'well when i was in be the recall air force they thought i was a dyke plumber bitch so there ya go opinions are like assholes',\n",
       " 'wellspring when i was in the air travel squeeze they idea i was a butch pipe fitter gripe so there ya hug drug thought are alike sob',\n",
       " 'well when i was in the air force they thought i was a dyke plumber bitch so there ya go opinions are like assholes',\n",
       " 'that his sheboon friend melissa is apparently dating blonde dude',\n",
       " 'that buster his sister sheboon friend melissa is apparently dating some blonde dude',\n",
       " 'that his babe sheboon acquaintance genus melissa is patently geological dating some light haired fashion plate',\n",
       " 'that his sister sheboon supporter friend melissa is apparently dating some blonde dude',\n",
       " 'that his sister sheboon friend apparently is melissa dating some blonde dude',\n",
       " 'that his sister sheboon friend blonde is apparently dating some melissa dude',\n",
       " 'that his baby sheboon quaker genus melissa is plain go out some blond gallant',\n",
       " 'that his sister sheboon friend melissa is apparently dating some blonde dude',\n",
       " 'the bbi will the circle of violence and tension after every five years then bring it on',\n",
       " 'if the bbi will tenseness end the circle of violence and tension after every five years then bring it on',\n",
       " 'if the bbi will end the circle of violence and tension after leave every five years then bring it on',\n",
       " 'if the bbi will end the circle of tension and violence after every five years then bring it on',\n",
       " 'if the bbi will end the circle of violence and tension after bring five years then every it on',\n",
       " 'if the bbi will terminate the roach of fierceness and stress after every five spot old age then bestow it on',\n",
       " 'if the bbi will end the circle of violence and tension after every five years then it',\n",
       " 'if the bbi will end the circle of violence and tension after every five years then bring it on',\n",
       " 'if ya nigra ever so tell that grouse own t yo quaker you unspoiled consider him',\n",
       " 'if ya nigga ever say that bitch yo t ain friend you better believe him',\n",
       " 'if ya nigga ever say that ain t yo friend you better believe him',\n",
       " 'if ya supporter nigga ever say that bitch ain t yo friend you better believe him',\n",
       " 'if ya spade ever so aver that kick own t yo ally you effective think him',\n",
       " 'if ya nigga ever that ain t yo friend you better believe him',\n",
       " 'if ya nigga ever say that bitch ain t tonne yo friend you better believe him',\n",
       " 'if ya nigga ever say that bitch ain t yo friend you better believe him ',\n",
       " 'common blacked on get em high',\n",
       " 'common blacked on get em develop high',\n",
       " 'common blacked develop on get em high',\n",
       " 'common em on get blacked high',\n",
       " 'vulgar black on grow em senior high school',\n",
       " 'common blacked get high',\n",
       " 'vulgar melanise on get em quad heights',\n",
       " 'common blacked on get em high',\n",
       " 'exploiter milklike spore we recollect we have breakwater and the milklike spore will killing their intellectual nourishment origin mooch',\n",
       " 'user milky spores we think we have moles and the milky spores will grubs their food source kill',\n",
       " 'substance abuser milklike spore we opine we have gram molecule and the milklike spore will belt down their intellectual nourishment root sponge',\n",
       " 'user milky kill we think we have moles and the milky spores will spores their food source grubs',\n",
       " 'user milky groyne spores we think we have moles and the milky spores will kill their food source grubs',\n",
       " 'user milky spores leave we think we have moles and the milky spores will kill their food source grubs',\n",
       " 'user milky spores we think we have moles and the milky will kill their food source grubs',\n",
       " 'user milky spores we think we have moles and the milky spores will kill their food source grubs',\n",
       " 'system superman retards all of a cattery cats toast be able to make to explode',\n",
       " 'system superman retards all of a cats to be able to make toast explode',\n",
       " 'organization acid slow down all of a cattery barf to be able bodied to wee drink irrupt',\n",
       " 'system retards all of a cattery cats to be able to toast explode',\n",
       " 'system superman retards all of a cattery cats toast be able to make to explode',\n",
       " 'system superman retards all of a cattery cats to be completely able to make toast explode',\n",
       " 'organisation battery acid slow all of a cattery retch to be able bodied to build goner detonate',\n",
       " 'system superman retards all of a cattery cats to be able to make toast explode',\n",
       " 'all these niggas is',\n",
       " 'all these niggas parrots',\n",
       " 'all these nigga is parrot',\n",
       " 'all niggas these is parrots',\n",
       " 'all these niggas be is parrots',\n",
       " 'all these jigaboo is parrot',\n",
       " 'all these niggas parrots is',\n",
       " 'all these niggas is parrots',\n",
       " 'i pink a sheep because it sneeze at a sus scrofa',\n",
       " 'i ravish a sheep because it sneeze at a guttle',\n",
       " 'i raped a sheep because it tap sneezed at a pig',\n",
       " 'raped a sheep because it sneezed at a pig',\n",
       " 'i at a sheep because it sneezed raped a pig',\n",
       " 'a raped a sheep because it sneezed at i pig',\n",
       " 'i raped a sheep because it information technology sneezed at a pig',\n",
       " 'i raped a sheep because it sneezed at a pig',\n",
       " 'i am so corporate america i am only years old and i feel like i have been in for number years',\n",
       " 'i am so tired of corporate america i am only number feel old in i years like i have been and this bitch for number years',\n",
       " 'i am so hackneyed of collective us i am only add up year previous and i smell alike i have been in this bellyache for add up year',\n",
       " 'i tired of corporate america i am only number years old and i feel like i been in this bitch for years',\n",
       " 'i am so play out of incorporated usa i am only phone number old age older and i tactile property the likes of i have been in this cunt for phone number old age',\n",
       " 'i am so tired of corporate america i am only number years old and i feel like i have united states been in this bitch for experience number years',\n",
       " 'i am so tired of corporate america i am only number thusly years old and i feel like experience i have been in this bitch for number years',\n",
       " 'i am so tired of corporate america i am only number years old and i feel like i have been in this bitch for number years',\n",
       " 'pop someone took my fucking dyke pin i am going to kill',\n",
       " 'someone going my fucking dyke pin i am took to kill',\n",
       " 'someone took my fucking i pin dyke am going to kill',\n",
       " 'individual use up my bloody butch pin number i am run to defeat',\n",
       " 'someone took my fucking dyke contract pin i am going to kill',\n",
       " 'someone my fucking dyke pin i am going to kill',\n",
       " 'mortal demand my have intercourse dike immobilize i am loss to belt down',\n",
       " 'someone took my fucking dyke pin i am going to kill',\n",
       " 'a get lol load of this kike',\n",
       " 'lol take a payload of this yid',\n",
       " 'lol a get load of this kike',\n",
       " 'lol get a load of hymie this kike',\n",
       " 'lol get a load hymie of this kike',\n",
       " 'lol a load of this kike',\n",
       " 'lol capture a loading of this hymie',\n",
       " 'lol get a load of this kike',\n",
       " 'pls scream this nigger out for the of wiped out blks dwell on he threshold while he and his clowngressional cutting carcase complete blood count habituate every boulevard to perturb from their fearful execution',\n",
       " 'pls call this coon out for the of impoverished blks living on he brink carcase while he and public presentation cutting his clowngressional bleak carcass cbc use every avenue to distract from their cowardly performances',\n",
       " 'pls prognosticate this procyon lotor out for the of necessitous blks support on he threshold while he and his clowngressional dim carcase complete blood count economic consumption every boulevard to disorder from their fearful public presentation',\n",
       " 'pls call living coon out for the of impoverished blks this on he brink while he and his clowngressional bleak carcass cbc use every avenue performances to from their cowardly distract',\n",
       " 'pls call this coon out for the of impoverished blks living on brink while he and clowngressional bleak carcass cbc use every avenue to distract from cowardly performances',\n",
       " 'call this coon out for the of impoverished blks living on brink while he and his clowngressional bleak carcass use every avenue to from cowardly performances',\n",
       " 'pls call public presentation this coon out for the of impoverished blks living on he brink while he boulevard and his clowngressional bleak carcass cbc use every avenue to distract from verge their cowardly performances',\n",
       " 'pls call this coon out for the of impoverished blks living on he brink while he and his clowngressional bleak carcass cbc use every avenue to distract from their cowardly performances',\n",
       " 'is tarique a fucking actor',\n",
       " 'tarique is a fucking actor',\n",
       " 'tarique is a bonk doer',\n",
       " 'tarique is a shag role player',\n",
       " 'tarique be is a fucking actor',\n",
       " 'tarique is a crashing fucking actor',\n",
       " 'tarique is fucking',\n",
       " 'tarique is a fucking actor ',\n",
       " 'arab user user to what the israeli government does they white so wrong and even gal has spoken up being netanyahu anti user racism but even poc white uphold could supremacy while still against targeted by white supremacists many non are latinx jews arabs etc can uphold white supremacy',\n",
       " 'user user user to what the israeli not government does they stool are so wrong and even gal has spoken up against netanyahu anti arab racism but even poc could uphold evening white supremacy while still being targeted by white supremacists many non white latinx maintain jews arabs etc can uphold white supremacy',\n",
       " 'user user white to what the israeli government does they are so wrong and even gal has spoken up against netanyahu anti arab user but even poc could uphold white supremacy while still being targeted by white can many non racism latinx jews arabs etc supremacists uphold white supremacy',\n",
       " 'exploiter exploiter exploiter to what the israeli governance does they are so untimely and regular gallon has mouth up against netanyahu anti arabian racial discrimination but regular poc could bear on bloodless domination while quiet being point by bloodless supremacist many not bloodless latinx hebrew arabian etc can bear on bloodless domination',\n",
       " 'user user to what the israeli government does they so wrong and even gal has spoken up against netanyahu anti arab racism but even poc could uphold white supremacy while still being targeted white supremacists many white latinx arabs etc can uphold white',\n",
       " 'user user user to what the israeli government does they are so stool wrong and even gal has spoken up against netanyahu anti arab racism but even poc could uphold white supremacy while still drug user being targeted by white supremacists many evening non speak white latinx jews arabs etc can uphold white supremacy',\n",
       " 'drug user drug user drug user to what the israeli politics does they are so haywire and fifty fifty gallon has address up against netanyahu anti arabian racialism but fifty fifty poc could carry on whiten mastery while nevertheless being place by whiten supremacist many not whiten latinx jew arab etc can carry on whiten mastery',\n",
       " 'user user user to what the israeli government does they are so wrong and even gal has spoken up against netanyahu anti arab racism but even poc could uphold white supremacy while still being targeted by white supremacists many non white latinx jews arabs etc can uphold white supremacy',\n",
       " 'user bernardo just is a white honky',\n",
       " 'user bernardo is just a white drug user honky',\n",
       " 'drug user bernardo is just a theodore harold white whitey',\n",
       " 'exploiter bernardo is just a albumen honkie',\n",
       " 'user just is bernardo a white honky',\n",
       " 'user bernardo drug user is just a white honky',\n",
       " 'user bernardo is just a white honky',\n",
       " 'user bernardo is just a white honky',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_sr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "\n",
    "def bert_tokenize(train_set, dev_set, test_set, max_length):\n",
    "    \n",
    "    train = tokenizer(train_set, max_length=max_length, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    dev = tokenizer(dev_set, max_length=max_length, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    test = tokenizer(test_set, max_length=max_length, truncation=True, padding='max_length', return_tensors='tf')\n",
    "    \n",
    "    return train, dev, test\n",
    "\n",
    "X_train_orig, X_dev_orig, X_test_orig = bert_tokenize(X_train_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_sr, X_dev_aug_sr, X_test_aug_sr = bert_tokenize(aug_sr_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_ri, X_dev_aug_ri, X_test_aug_ri = bert_tokenize(aug_ri_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_rs, X_dev_aug_rs, X_test_aug_rs = bert_tokenize(aug_rs_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_aug_rd, X_dev_aug_rd, X_test_aug_rd = bert_tokenize(aug_rd_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_all_1, X_dev_all_1, X_test_all_1 = bert_tokenize(aug_all_1_text, X_dev_text, X_test_text, max_length)\n",
    "\n",
    "X_train_all_5, X_dev_all_5, X_test_all_5 = bert_tokenize(aug_all_5_text, X_dev_text, X_test_text, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.save_pretrained(\"./Tokenizer_ALL_EDA_BERT_base_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(123064, 128), dtype=int32, numpy=\n",
       "array([[  101,  1045,  2123, ...,     0,     0,     0],\n",
       "       [  101,  1045,  2123, ...,     0,     0,     0],\n",
       "       [  101,  1045,  2123, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1996, 18414, ...,     0,     0,     0],\n",
       "       [  101,  1996,  3644, ...,     0,     0,     0],\n",
       "       [  101,  1996,  3644, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug_sr.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1646722395812,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "-OSiJNKUTYB5",
    "outputId": "3d0dbbf7-ab1f-4aec-84b4-77335d135479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(123064, 128), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug_ri.token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516,
     "referenced_widgets": [
      "12bf3b8f0bab4586847a07e8c438dafa",
      "8039ef2f59ee482781f325f5a91b93e8",
      "e67ba177d3744ea4bcc652774cd13abd",
      "43eb8a62436a4c149e25f98f49a7c68d",
      "3723a8c5f8eb47efa71e50a5ef924123",
      "9e9b4804607046678d3d132528486b0b",
      "e567a77fb29d47c98fe19c440b2d31e8",
      "5d2efc2c1758475c9d1cd51cdc7edf0a",
      "7942944ae43141c0aa83ec76fc0deafa",
      "c26d9b9e910a43febfd588927c3e7756",
      "1b1a083fc8e643a78f055105960b523e",
      "4656eb21ff2245b7be51f82c1e2c7e6b",
      "ab8f5f020c76459aad12d4cab6a36a72",
      "2af599ea5c3d4874aff863303c5b5703",
      "c64b940afcc94ee3b2b88c582b54d97f",
      "8a798f3e801d47df8771840991f7cfa3",
      "263134a33eaa4345926dd786256c08eb",
      "b473e96d36604d71ae5d3d8e69cc01c3",
      "3dfc3ee445f2403a8ed7b4e6f5a8b3d3",
      "e35113cc44f34a1fbb22f109f49f7bdd",
      "c4792815ec0d4591bcaea2e7a0539e6b",
      "047bcb706b304be09200793be7524708",
      "02d7e8c53bf94bf48c06cea9abbd9aba",
      "d57bc505733b4c738cf84db24feba360",
      "bf38f0560d3e493ca2b97fd974d00462",
      "8a60b779e7d749d284b791b9e5126a62",
      "2e51f1cad2b84893b537beb7e4ebf67c",
      "7d3ff64481b64406aadb34439d2ad02b",
      "feb0fac998144444bfd9373ce537bbc3",
      "70f68856bdb64c30aa57e6046468b3d6",
      "0c234fac6d10482089dacd2c03a5bbde",
      "b8b44bed109443fd9bba63a7039f3c93",
      "c3df12951362451685bea68b7091c69f",
      "7d77d8f8c129400d9f61b60da03891b3",
      "971c955528914b05afe5d12e9c626cf1",
      "98efd1135c4f438c8b8dd5c130cc667c",
      "9aca8f0c4013472c8514d2d57f9ea3e8",
      "807b39071d354a1ab7af51a05f1ef3b1",
      "acd4639a73904507b7884adc96512dc5",
      "b575b556bb9445ceb5c662b9d224e171",
      "f9a30d0d10744d14a47b500251c1973c",
      "d2803d4a8a794a83a2ebcf61ce3097ff",
      "5e02a09e9fe24718a8f1f4167c42d099",
      "fc6b1e6a0e254b82b6c7277f10a5d542",
      "071ca09b48bf4d9989852d66f8d57642",
      "15db3b4b336b41cdb973852bb3fef72f",
      "8aa487d37b284b2ba88903923a0086d9",
      "b3ba42a7365d418f9cbf7f68ede3b65a",
      "c7e4cea875eb41c8950f97350c237730",
      "e88a61936e0949c490366d0619869b6c",
      "ee76f1517ed64f4fa49d998d2448f9c2",
      "45b7612393254fe19709bdae7d7bbbe6",
      "d12cbe52662546d1be82cfd4536dfdfc",
      "ee89c9881c75441fbc9ec827d623134e",
      "d7abb004da9d42b787717cfdb3657f4e"
     ]
    },
    "executionInfo": {
     "elapsed": 19947,
     "status": "error",
     "timestamp": 1646722519680,
     "user": {
      "displayName": "Evan Chan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgGKtlehGoFssPGs4v0Yns-qfVPjW1FuloVAn-GMw=s64",
      "userId": "16754265128573798261"
     },
     "user_tz": 360
    },
    "id": "DCaUJQymTWeJ",
    "outputId": "990e4e3f-4544-4c6c-ab2c-b365d72242af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(123064, 128), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all_1.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(123064, 128), dtype=int32, numpy=\n",
       "array([[  101,  2317,  2317, ...,     0,     0,     0],\n",
       "       [  101,  3944,  1045, ...,     0,     0,     0],\n",
       "       [  101,  1046,  2317, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  9467,  3993, ...,     0,     0,     0],\n",
       "       [  101,  1996, 18414, ...,     0,     0,     0],\n",
       "       [  101,  1996,  3644, ...,     0,     0,     0]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all_5.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def balanced_recall(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced recall metric\n",
    "    recall = TP / (TP + FN)\n",
    "    \"\"\"\n",
    "    recall_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true_class, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        recall_by_class = recall_by_class + recall\n",
    "    return recall_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_precision(y_true, y_pred):\n",
    "    \"\"\"This function calculates the balanced precision metric\n",
    "    precision = TP / (TP + FP)\n",
    "    \"\"\"\n",
    "    precision_by_class = 0\n",
    "    # iterate over each predicted class to get class-specific metric\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        y_pred_class = y_pred[:, i]\n",
    "        y_true_class = y_true[:, i]\n",
    "        true_positives = K.sum(K.round(K.clip(y_true_class * y_pred_class, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred_class, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        precision_by_class = precision_by_class + precision\n",
    "    # return average balanced metric for each class\n",
    "    return precision_by_class / y_pred.shape[1]\n",
    "\n",
    "def balanced_f1_score(y_true, y_pred):\n",
    "    \"\"\"This function calculates the F1 score metric\"\"\"\n",
    "    precision = balanced_precision(y_true, y_pred)\n",
    "    recall = balanced_recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(bert_model, hidden_size = 5, \n",
    "                                train_layers = -1, \n",
    "                                optimizer=tf.keras.optimizers.Adam()):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Let's keep it simple and don't add dropout, layer norms, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                  'token_type_ids': token_type_ids,\n",
    "                  'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "\n",
    "\n",
    "    bert_out = bert_model(bert_inputs)\n",
    "    \n",
    "    net = bert_out[0]\n",
    "    \n",
    "    classification_token = tf.keras.layers.Lambda(lambda x: x[:,0,:], name='get_first_vector')(net)\n",
    "    \n",
    "    dropout1 = tf.keras.layers.Dropout(0.4, name=\"dropout1\")(classification_token)\n",
    "    \n",
    "    hidden = tf.keras.layers.Dense(hidden_size, name='hidden_layer')(dropout1)\n",
    "    \n",
    "    dropout2 = tf.keras.layers.Dropout(0.4, name=\"dropout2\")(hidden)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(3, activation='sigmoid',name='classification_layer')(dropout2)\n",
    "\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], \n",
    "                                          outputs=[classification])\n",
    "    \n",
    "    METRICS = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), \n",
    "               balanced_recall, \n",
    "               balanced_precision, \n",
    "               balanced_f1_score,\n",
    "               tf.keras.metrics.AUC(curve='ROC', name=\"auc_roc\")]\n",
    "    \n",
    "    \n",
    "    classification_model.compile(optimizer=optimizer,\n",
    "                            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                            metrics= METRICS)\n",
    "\n",
    "\n",
    "    return classification_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     classification_model.compile(optimizer=optimizer,\n",
    "#                             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#                             metrics=tf.keras.metrics.CategoricalAccuracy('accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_BERT(x_train, x_dev, x_test, y_train, y_dev, y_test, name, learning_rate = 5e-05, \n",
    "                   epsilon=1e-08, train_layers = -1, epochs = 10, batch_size = 16):\n",
    "    ''' Fine tunes BERT base uncased with given data, allows your to set some hyperparameters\n",
    "        returns test set accuracy, f1 score, and AUC_ROC score\n",
    "    '''\n",
    "    try:\n",
    "        del classification_model\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del bert_model\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # early stopping callback\n",
    "    \n",
    "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', \n",
    "                                                      patience = 4,\n",
    "                                                      restore_best_weights = True)\n",
    "    \n",
    "    # Create a callback that saves the model's weights\n",
    "    \n",
    "    path_name = './Saved_Models/EDA_b_7aug/' + name + '/' + name\n",
    "\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=path_name, \n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1,\n",
    "                                                     monitor='val_accuracy',\n",
    "                                                     save_best_only=True)\n",
    "    \n",
    "    # create classification model\n",
    "    classification_model = create_classification_model(bert_model, \n",
    "                                                       optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon),\n",
    "                                                       train_layers=train_layers)    \n",
    "    \n",
    "    model_fit = classification_model.fit([x_train.input_ids, x_train.token_type_ids, x_train.attention_mask],\n",
    "                         y_train,\n",
    "                         validation_data=([x_dev.input_ids, x_dev.token_type_ids, x_dev.attention_mask],\n",
    "                         y_dev),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks = [earlystop_callback, cp_callback])\n",
    "    \n",
    "    y_preds_array = classification_model.predict([x_test.input_ids, x_test.token_type_ids, x_test.attention_mask])\n",
    "\n",
    "    # convert to predicted one-hot encoding\n",
    "\n",
    "    from keras.utils.np_utils import to_categorical\n",
    "    y_preds = to_categorical(np.argmax(y_preds_array, 1), dtype = \"int64\")\n",
    "\n",
    "    # convert back to labels\n",
    "\n",
    "    y_test_cat = np.argmax(y_test, axis=1)\n",
    "    y_preds_cat = np.argmax(y_preds, axis=1)\n",
    "    \n",
    "    # calculate metrics\n",
    "    Accuracy = accuracy_score(y_test_cat, y_preds_cat)\n",
    "\n",
    "    Macro_F1 = f1_score(y_test_cat, y_preds_cat, average='macro')\n",
    "\n",
    "    ROC_AUC = roc_auc_score(y_test, y_preds, multi_class='ovo',average='macro')\n",
    "    \n",
    "    metrics_history = model_fit.history\n",
    "    \n",
    "    return Accuracy, Macro_F1, ROC_AUC, metrics_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "241/241 [==============================] - 61s 212ms/step - loss: 1.2338 - accuracy: 0.4309 - balanced_recall: 0.6037 - balanced_precision: 0.3946 - balanced_f1_score: 0.4770 - auc_roc: 0.6007 - val_loss: 0.9359 - val_accuracy: 0.5413 - val_balanced_recall: 0.7386 - val_balanced_precision: 0.4750 - val_balanced_f1_score: 0.5767 - val_auc_roc: 0.7256\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54134, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 2/30\n",
      "241/241 [==============================] - 48s 196ms/step - loss: 1.0920 - accuracy: 0.4888 - balanced_recall: 0.6728 - balanced_precision: 0.4383 - balanced_f1_score: 0.5305 - auc_roc: 0.6679 - val_loss: 0.8822 - val_accuracy: 0.5803 - val_balanced_recall: 0.7674 - val_balanced_precision: 0.5071 - val_balanced_f1_score: 0.6096 - val_auc_roc: 0.7630\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.54134 to 0.58034, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 3/30\n",
      "241/241 [==============================] - 47s 194ms/step - loss: 1.0058 - accuracy: 0.5372 - balanced_recall: 0.7158 - balanced_precision: 0.4668 - balanced_f1_score: 0.5647 - auc_roc: 0.7074 - val_loss: 0.8415 - val_accuracy: 0.6022 - val_balanced_recall: 0.8272 - val_balanced_precision: 0.5104 - val_balanced_f1_score: 0.6297 - val_auc_roc: 0.7768\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.58034 to 0.60218, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 4/30\n",
      "241/241 [==============================] - 46s 189ms/step - loss: 0.9598 - accuracy: 0.5548 - balanced_recall: 0.7463 - balanced_precision: 0.4823 - balanced_f1_score: 0.5856 - auc_roc: 0.7255 - val_loss: 0.8222 - val_accuracy: 0.6219 - val_balanced_recall: 0.7974 - val_balanced_precision: 0.5207 - val_balanced_f1_score: 0.6287 - val_auc_roc: 0.7870\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.60218 to 0.62194, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 5/30\n",
      "241/241 [==============================] - 48s 198ms/step - loss: 0.9267 - accuracy: 0.5778 - balanced_recall: 0.7621 - balanced_precision: 0.4916 - balanced_f1_score: 0.5973 - auc_roc: 0.7393 - val_loss: 0.8118 - val_accuracy: 0.6167 - val_balanced_recall: 0.8394 - val_balanced_precision: 0.5158 - val_balanced_f1_score: 0.6375 - val_auc_roc: 0.7903\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62194\n",
      "Epoch 6/30\n",
      "241/241 [==============================] - 54s 225ms/step - loss: 0.8997 - accuracy: 0.5879 - balanced_recall: 0.7727 - balanced_precision: 0.4975 - balanced_f1_score: 0.6051 - auc_roc: 0.7505 - val_loss: 0.8039 - val_accuracy: 0.6334 - val_balanced_recall: 0.8100 - val_balanced_precision: 0.5321 - val_balanced_f1_score: 0.6411 - val_auc_roc: 0.7995\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.62194 to 0.63339, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 7/30\n",
      "241/241 [==============================] - 50s 205ms/step - loss: 0.8934 - accuracy: 0.5940 - balanced_recall: 0.7778 - balanced_precision: 0.4989 - balanced_f1_score: 0.6076 - auc_roc: 0.7527 - val_loss: 0.7845 - val_accuracy: 0.6401 - val_balanced_recall: 0.8296 - val_balanced_precision: 0.5209 - val_balanced_f1_score: 0.6385 - val_auc_roc: 0.8033\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.63339 to 0.64015, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 8/30\n",
      "241/241 [==============================] - 46s 190ms/step - loss: 0.8743 - accuracy: 0.6030 - balanced_recall: 0.7841 - balanced_precision: 0.5034 - balanced_f1_score: 0.6128 - auc_roc: 0.7618 - val_loss: 0.7852 - val_accuracy: 0.6433 - val_balanced_recall: 0.8356 - val_balanced_precision: 0.5308 - val_balanced_f1_score: 0.6478 - val_auc_roc: 0.8009\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.64015 to 0.64327, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 9/30\n",
      "241/241 [==============================] - 46s 189ms/step - loss: 0.8539 - accuracy: 0.6166 - balanced_recall: 0.7926 - balanced_precision: 0.5087 - balanced_f1_score: 0.6193 - auc_roc: 0.7698 - val_loss: 0.7705 - val_accuracy: 0.6511 - val_balanced_recall: 0.8441 - val_balanced_precision: 0.5280 - val_balanced_f1_score: 0.6482 - val_auc_roc: 0.8050\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.64327 to 0.65107, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 10/30\n",
      "241/241 [==============================] - 46s 189ms/step - loss: 0.8348 - accuracy: 0.6241 - balanced_recall: 0.8049 - balanced_precision: 0.5149 - balanced_f1_score: 0.6277 - auc_roc: 0.7761 - val_loss: 0.7713 - val_accuracy: 0.6563 - val_balanced_recall: 0.8514 - val_balanced_precision: 0.5183 - val_balanced_f1_score: 0.6428 - val_auc_roc: 0.8078\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.65107 to 0.65627, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 11/30\n",
      "241/241 [==============================] - 46s 189ms/step - loss: 0.8340 - accuracy: 0.6289 - balanced_recall: 0.8100 - balanced_precision: 0.5146 - balanced_f1_score: 0.6290 - auc_roc: 0.7767 - val_loss: 0.7658 - val_accuracy: 0.6578 - val_balanced_recall: 0.8293 - val_balanced_precision: 0.5263 - val_balanced_f1_score: 0.6426 - val_auc_roc: 0.8143\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.65627 to 0.65783, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 12/30\n",
      "241/241 [==============================] - 46s 192ms/step - loss: 0.8265 - accuracy: 0.6335 - balanced_recall: 0.8112 - balanced_precision: 0.5175 - balanced_f1_score: 0.6316 - auc_roc: 0.7812 - val_loss: 0.7599 - val_accuracy: 0.6615 - val_balanced_recall: 0.8419 - val_balanced_precision: 0.5268 - val_balanced_f1_score: 0.6467 - val_auc_roc: 0.8138\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.65783 to 0.66147, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 13/30\n",
      "241/241 [==============================] - 46s 188ms/step - loss: 0.8146 - accuracy: 0.6343 - balanced_recall: 0.8185 - balanced_precision: 0.5211 - balanced_f1_score: 0.6365 - auc_roc: 0.7852 - val_loss: 0.7603 - val_accuracy: 0.6651 - val_balanced_recall: 0.8386 - val_balanced_precision: 0.5238 - val_balanced_f1_score: 0.6434 - val_auc_roc: 0.8164\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.66147 to 0.66511, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 14/30\n",
      "241/241 [==============================] - 45s 188ms/step - loss: 0.8129 - accuracy: 0.6400 - balanced_recall: 0.8180 - balanced_precision: 0.5200 - balanced_f1_score: 0.6355 - auc_roc: 0.7856 - val_loss: 0.7556 - val_accuracy: 0.6734 - val_balanced_recall: 0.8420 - val_balanced_precision: 0.5231 - val_balanced_f1_score: 0.6438 - val_auc_roc: 0.8167\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.66511 to 0.67343, saving model to ./Saved_Models/EDA_b_7aug/orig_data_7aug\\orig_data_7aug\n",
      "Epoch 15/30\n",
      "241/241 [==============================] - 46s 189ms/step - loss: 0.7966 - accuracy: 0.6473 - balanced_recall: 0.8283 - balanced_precision: 0.5256 - balanced_f1_score: 0.6429 - auc_roc: 0.7925 - val_loss: 0.7500 - val_accuracy: 0.6615 - val_balanced_recall: 0.8442 - val_balanced_precision: 0.5339 - val_balanced_f1_score: 0.6527 - val_auc_roc: 0.8177\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67343\n",
      "Epoch 16/30\n",
      "241/241 [==============================] - 44s 181ms/step - loss: 0.7905 - accuracy: 0.6481 - balanced_recall: 0.8271 - balanced_precision: 0.5238 - balanced_f1_score: 0.6411 - auc_roc: 0.7932 - val_loss: 0.7536 - val_accuracy: 0.6620 - val_balanced_recall: 0.8542 - val_balanced_precision: 0.5210 - val_balanced_f1_score: 0.6457 - val_auc_roc: 0.8142\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67343\n",
      "Epoch 17/30\n",
      "241/241 [==============================] - 44s 184ms/step - loss: 0.7825 - accuracy: 0.6527 - balanced_recall: 0.8324 - balanced_precision: 0.5255 - balanced_f1_score: 0.6440 - auc_roc: 0.7953 - val_loss: 0.7486 - val_accuracy: 0.6693 - val_balanced_recall: 0.8353 - val_balanced_precision: 0.5330 - val_balanced_f1_score: 0.6494 - val_auc_roc: 0.8209\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67343\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 44s 182ms/step - loss: 0.7755 - accuracy: 0.6572 - balanced_recall: 0.8371 - balanced_precision: 0.5315 - balanced_f1_score: 0.6499 - auc_roc: 0.7999 - val_loss: 0.7530 - val_accuracy: 0.6625 - val_balanced_recall: 0.8510 - val_balanced_precision: 0.5259 - val_balanced_f1_score: 0.6486 - val_auc_roc: 0.8186\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67343\n",
      "Wall time: 15min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# original data set\n",
    "Accuracy_orig, Macro_F1_orig, ROC_AUC_orig, metrics_orig = fine_tune_BERT(X_train_orig, X_dev_orig, X_test_orig, \n",
    "                                                            y_train_orig, y_dev_orig, y_test_orig, 'orig_data_7aug',\n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1923/1923 [==============================] - 337s 171ms/step - loss: 1.0654 - accuracy: 0.5058 - balanced_recall: 0.6817 - balanced_precision: 0.4377 - balanced_f1_score: 0.5327 - auc_roc: 0.6720 - val_loss: 0.7992 - val_accuracy: 0.6526 - val_balanced_recall: 0.8225 - val_balanced_precision: 0.5266 - val_balanced_f1_score: 0.6408 - val_auc_roc: 0.7984\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65263, saving model to ./Saved_Models/EDA_b_7aug/EDA_sr_7aug\\EDA_sr_7aug\n",
      "Epoch 2/30\n",
      "1923/1923 [==============================] - 320s 166ms/step - loss: 0.9039 - accuracy: 0.5821 - balanced_recall: 0.7552 - balanced_precision: 0.4837 - balanced_f1_score: 0.5893 - auc_roc: 0.7412 - val_loss: 0.7635 - val_accuracy: 0.6661 - val_balanced_recall: 0.8243 - val_balanced_precision: 0.5435 - val_balanced_f1_score: 0.6539 - val_auc_roc: 0.8175\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65263 to 0.66615, saving model to ./Saved_Models/EDA_b_7aug/EDA_sr_7aug\\EDA_sr_7aug\n",
      "Epoch 3/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.8587 - accuracy: 0.6107 - balanced_recall: 0.7862 - balanced_precision: 0.4992 - balanced_f1_score: 0.6102 - auc_roc: 0.7618 - val_loss: 0.7511 - val_accuracy: 0.6765 - val_balanced_recall: 0.8265 - val_balanced_precision: 0.5458 - val_balanced_f1_score: 0.6563 - val_auc_roc: 0.8229\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66615 to 0.67655, saving model to ./Saved_Models/EDA_b_7aug/EDA_sr_7aug\\EDA_sr_7aug\n",
      "Epoch 4/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.8258 - accuracy: 0.6294 - balanced_recall: 0.8030 - balanced_precision: 0.5107 - balanced_f1_score: 0.6240 - auc_roc: 0.7763 - val_loss: 0.7275 - val_accuracy: 0.6885 - val_balanced_recall: 0.8566 - val_balanced_precision: 0.5433 - val_balanced_f1_score: 0.6635 - val_auc_roc: 0.8283\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67655 to 0.68851, saving model to ./Saved_Models/EDA_b_7aug/EDA_sr_7aug\\EDA_sr_7aug\n",
      "Epoch 5/30\n",
      "1923/1923 [==============================] - 320s 166ms/step - loss: 0.7981 - accuracy: 0.6453 - balanced_recall: 0.8192 - balanced_precision: 0.5186 - balanced_f1_score: 0.6347 - auc_roc: 0.7868 - val_loss: 0.7245 - val_accuracy: 0.6937 - val_balanced_recall: 0.8592 - val_balanced_precision: 0.5454 - val_balanced_f1_score: 0.6659 - val_auc_roc: 0.8287\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.68851 to 0.69371, saving model to ./Saved_Models/EDA_b_7aug/EDA_sr_7aug\\EDA_sr_7aug\n",
      "Epoch 6/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.7744 - accuracy: 0.6578 - balanced_recall: 0.8309 - balanced_precision: 0.5244 - balanced_f1_score: 0.6426 - auc_roc: 0.7944 - val_loss: 0.7313 - val_accuracy: 0.6947 - val_balanced_recall: 0.8663 - val_balanced_precision: 0.5398 - val_balanced_f1_score: 0.6638 - val_auc_roc: 0.8259\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.69371 to 0.69475, saving model to ./Saved_Models/EDA_b_7aug/EDA_sr_7aug\\EDA_sr_7aug\n",
      "Epoch 7/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.7459 - accuracy: 0.6718 - balanced_recall: 0.8469 - balanced_precision: 0.5291 - balanced_f1_score: 0.6509 - auc_roc: 0.8042 - val_loss: 0.7359 - val_accuracy: 0.6859 - val_balanced_recall: 0.8660 - val_balanced_precision: 0.5327 - val_balanced_f1_score: 0.6592 - val_auc_roc: 0.8238\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.69475\n",
      "Epoch 8/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.7212 - accuracy: 0.6845 - balanced_recall: 0.8539 - balanced_precision: 0.5357 - balanced_f1_score: 0.6580 - auc_roc: 0.8120 - val_loss: 0.7634 - val_accuracy: 0.6838 - val_balanced_recall: 0.8575 - val_balanced_precision: 0.5346 - val_balanced_f1_score: 0.6571 - val_auc_roc: 0.8258\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.69475\n",
      "Epoch 9/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.6915 - accuracy: 0.6986 - balanced_recall: 0.8687 - balanced_precision: 0.5397 - balanced_f1_score: 0.6655 - auc_roc: 0.8204 - val_loss: 0.7774 - val_accuracy: 0.6875 - val_balanced_recall: 0.8647 - val_balanced_precision: 0.5387 - val_balanced_f1_score: 0.6624 - val_auc_roc: 0.8248\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69475\n",
      "Epoch 10/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.6634 - accuracy: 0.7125 - balanced_recall: 0.8774 - balanced_precision: 0.5457 - balanced_f1_score: 0.6726 - auc_roc: 0.8282 - val_loss: 0.8107 - val_accuracy: 0.6849 - val_balanced_recall: 0.8598 - val_balanced_precision: 0.5355 - val_balanced_f1_score: 0.6585 - val_auc_roc: 0.8197\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.69475\n",
      "Wall time: 54min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# augmented with sr = 0.1\n",
    "Accuracy_aug_sr, Macro_F1_aug_sr, ROC_AUC_aug_sr, metrics_sr = fine_tune_BERT(X_train_aug_sr, X_dev_aug_sr, X_test_aug_sr, \n",
    "                                                            y_train_aug_sr, y_dev_orig, y_test_orig, 'EDA_sr_7aug', \n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1923/1923 [==============================] - 331s 168ms/step - loss: 1.1106 - accuracy: 0.4924 - balanced_recall: 0.6263 - balanced_precision: 0.4299 - balanced_f1_score: 0.5094 - auc_roc: 0.6563 - val_loss: 0.8174 - val_accuracy: 0.6433 - val_balanced_recall: 0.7299 - val_balanced_precision: 0.5296 - val_balanced_f1_score: 0.6129 - val_auc_roc: 0.7798\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64327, saving model to ./Saved_Models/EDA_b_7aug/EDA_ri_7aug\\EDA_ri_7aug\n",
      "Epoch 2/30\n",
      "1923/1923 [==============================] - 320s 166ms/step - loss: 0.9249 - accuracy: 0.5825 - balanced_recall: 0.6968 - balanced_precision: 0.4871 - balanced_f1_score: 0.5729 - auc_roc: 0.7312 - val_loss: 0.7719 - val_accuracy: 0.6672 - val_balanced_recall: 0.7478 - val_balanced_precision: 0.5352 - val_balanced_f1_score: 0.6235 - val_auc_roc: 0.7973\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.64327 to 0.66719, saving model to ./Saved_Models/EDA_b_7aug/EDA_ri_7aug\\EDA_ri_7aug\n",
      "Epoch 3/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.8616 - accuracy: 0.6169 - balanced_recall: 0.7302 - balanced_precision: 0.5095 - balanced_f1_score: 0.5998 - auc_roc: 0.7583 - val_loss: 0.7584 - val_accuracy: 0.6734 - val_balanced_recall: 0.7626 - val_balanced_precision: 0.5470 - val_balanced_f1_score: 0.6369 - val_auc_roc: 0.8011\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66719 to 0.67343, saving model to ./Saved_Models/EDA_b_7aug/EDA_ri_7aug\\EDA_ri_7aug\n",
      "Epoch 4/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.8191 - accuracy: 0.6403 - balanced_recall: 0.7526 - balanced_precision: 0.5263 - balanced_f1_score: 0.6190 - auc_roc: 0.7770 - val_loss: 0.7605 - val_accuracy: 0.6791 - val_balanced_recall: 0.7808 - val_balanced_precision: 0.5634 - val_balanced_f1_score: 0.6537 - val_auc_roc: 0.7872\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67343 to 0.67915, saving model to ./Saved_Models/EDA_b_7aug/EDA_ri_7aug\\EDA_ri_7aug\n",
      "Epoch 5/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.7860 - accuracy: 0.6583 - balanced_recall: 0.7753 - balanced_precision: 0.5384 - balanced_f1_score: 0.6351 - auc_roc: 0.7902 - val_loss: 0.7592 - val_accuracy: 0.6911 - val_balanced_recall: 0.7827 - val_balanced_precision: 0.5459 - val_balanced_f1_score: 0.6430 - val_auc_roc: 0.8003\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67915 to 0.69111, saving model to ./Saved_Models/EDA_b_7aug/EDA_ri_7aug\\EDA_ri_7aug\n",
      "Epoch 6/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.7533 - accuracy: 0.6753 - balanced_recall: 0.7915 - balanced_precision: 0.5495 - balanced_f1_score: 0.6482 - auc_roc: 0.8033 - val_loss: 0.7590 - val_accuracy: 0.6932 - val_balanced_recall: 0.7950 - val_balanced_precision: 0.5504 - val_balanced_f1_score: 0.6502 - val_auc_roc: 0.8006\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.69111 to 0.69319, saving model to ./Saved_Models/EDA_b_7aug/EDA_ri_7aug\\EDA_ri_7aug\n",
      "Epoch 7/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.7230 - accuracy: 0.6912 - balanced_recall: 0.8081 - balanced_precision: 0.5568 - balanced_f1_score: 0.6589 - auc_roc: 0.8139 - val_loss: 0.7866 - val_accuracy: 0.6833 - val_balanced_recall: 0.7892 - val_balanced_precision: 0.5490 - val_balanced_f1_score: 0.6473 - val_auc_roc: 0.7936\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.69319\n",
      "Epoch 8/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.6914 - accuracy: 0.7065 - balanced_recall: 0.8253 - balanced_precision: 0.5664 - balanced_f1_score: 0.6713 - auc_roc: 0.8257 - val_loss: 0.8019 - val_accuracy: 0.6828 - val_balanced_recall: 0.7863 - val_balanced_precision: 0.5469 - val_balanced_f1_score: 0.6448 - val_auc_roc: 0.7968\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.69319\n",
      "Epoch 9/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.6616 - accuracy: 0.7218 - balanced_recall: 0.8396 - balanced_precision: 0.5735 - balanced_f1_score: 0.6811 - auc_roc: 0.8350 - val_loss: 0.8430 - val_accuracy: 0.6786 - val_balanced_recall: 0.7865 - val_balanced_precision: 0.5496 - val_balanced_f1_score: 0.6466 - val_auc_roc: 0.7905\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69319\n",
      "Epoch 10/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.6288 - accuracy: 0.7379 - balanced_recall: 0.8519 - balanced_precision: 0.5798 - balanced_f1_score: 0.6896 - auc_roc: 0.8433 - val_loss: 0.8831 - val_accuracy: 0.6755 - val_balanced_recall: 0.7820 - val_balanced_precision: 0.5440 - val_balanced_f1_score: 0.6413 - val_auc_roc: 0.7891\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.69319\n",
      "Wall time: 54min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# augmented with ri = 0.1\n",
    "Accuracy_aug_ri, Macro_F1_aug_ri, ROC_AUC_aug_ri, metrics_ri = fine_tune_BERT(X_train_aug_ri, X_dev_aug_ri, X_test_aug_ri, \n",
    "                                                            y_train_aug_ri, y_dev_orig, y_test_orig, 'EDA_ri_7aug', \n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1923/1923 [==============================] - 331s 168ms/step - loss: 0.9771 - accuracy: 0.5296 - balanced_recall: 0.6080 - balanced_precision: 0.3666 - balanced_f1_score: 0.4559 - auc_roc: 0.5736 - val_loss: 0.7984 - val_accuracy: 0.6422 - val_balanced_recall: 0.6110 - val_balanced_precision: 0.3549 - val_balanced_f1_score: 0.4476 - val_auc_roc: 0.6092\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64223, saving model to ./Saved_Models/EDA_b_7aug/EDA_rs_7aug\\EDA_rs_7aug\n",
      "Epoch 2/30\n",
      "1923/1923 [==============================] - 320s 167ms/step - loss: 0.8616 - accuracy: 0.6068 - balanced_recall: 0.6311 - balanced_precision: 0.3737 - balanced_f1_score: 0.4684 - auc_roc: 0.5876 - val_loss: 0.7601 - val_accuracy: 0.6682 - val_balanced_recall: 0.5978 - val_balanced_precision: 0.3489 - val_balanced_f1_score: 0.4394 - val_auc_roc: 0.6177\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.64223 to 0.66823, saving model to ./Saved_Models/EDA_b_7aug/EDA_rs_7aug\\EDA_rs_7aug\n",
      "Epoch 3/30\n",
      "1923/1923 [==============================] - 320s 166ms/step - loss: 0.8118 - accuracy: 0.6362 - balanced_recall: 0.6435 - balanced_precision: 0.3806 - balanced_f1_score: 0.4774 - auc_roc: 0.5991 - val_loss: 0.7461 - val_accuracy: 0.6828 - val_balanced_recall: 0.5983 - val_balanced_precision: 0.3545 - val_balanced_f1_score: 0.4439 - val_auc_roc: 0.6196\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66823 to 0.68279, saving model to ./Saved_Models/EDA_b_7aug/EDA_rs_7aug\\EDA_rs_7aug\n",
      "Epoch 4/30\n",
      "1923/1923 [==============================] - 319s 166ms/step - loss: 0.7717 - accuracy: 0.6588 - balanced_recall: 0.6371 - balanced_precision: 0.3897 - balanced_f1_score: 0.4826 - auc_roc: 0.6132 - val_loss: 0.7458 - val_accuracy: 0.6802 - val_balanced_recall: 0.6026 - val_balanced_precision: 0.3576 - val_balanced_f1_score: 0.4476 - val_auc_roc: 0.6336\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68279\n",
      "Epoch 5/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.7357 - accuracy: 0.6793 - balanced_recall: 0.6507 - balanced_precision: 0.3990 - balanced_f1_score: 0.4937 - auc_roc: 0.6282 - val_loss: 0.7525 - val_accuracy: 0.6776 - val_balanced_recall: 0.6245 - val_balanced_precision: 0.3579 - val_balanced_f1_score: 0.4538 - val_auc_roc: 0.6344\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68279\n",
      "Epoch 6/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.6957 - accuracy: 0.7021 - balanced_recall: 0.6574 - balanced_precision: 0.4078 - balanced_f1_score: 0.5024 - auc_roc: 0.6425 - val_loss: 0.7803 - val_accuracy: 0.6807 - val_balanced_recall: 0.6256 - val_balanced_precision: 0.3622 - val_balanced_f1_score: 0.4576 - val_auc_roc: 0.6460\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68279\n",
      "Epoch 7/30\n",
      "1923/1923 [==============================] - 316s 164ms/step - loss: 0.6611 - accuracy: 0.7199 - balanced_recall: 0.6714 - balanced_precision: 0.4144 - balanced_f1_score: 0.5115 - auc_roc: 0.6541 - val_loss: 0.8133 - val_accuracy: 0.6713 - val_balanced_recall: 0.6265 - val_balanced_precision: 0.3586 - val_balanced_f1_score: 0.4550 - val_auc_roc: 0.6443\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68279\n",
      "Wall time: 37min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# augmented with rs = 0.1\n",
    "Accuracy_aug_rs, Macro_F1_aug_rs, ROC_AUC_aug_rs, metrics_rs = fine_tune_BERT(X_train_aug_rs, X_dev_aug_rs, X_test_aug_rs, \n",
    "                                                            y_train_aug_rs, y_dev_orig, y_test_orig, 'EDA_rs_7aug',\n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1923/1923 [==============================] - 326s 165ms/step - loss: 0.9840 - accuracy: 0.5101 - balanced_recall: 0.6312 - balanced_precision: 0.3999 - balanced_f1_score: 0.4882 - auc_roc: 0.6279 - val_loss: 0.7872 - val_accuracy: 0.6495 - val_balanced_recall: 0.6911 - val_balanced_precision: 0.5134 - val_balanced_f1_score: 0.5882 - val_auc_roc: 0.7540\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64951, saving model to ./Saved_Models/EDA_b_7aug/EDA_rd_7aug\\EDA_rd_7aug\n",
      "Epoch 2/30\n",
      "1923/1923 [==============================] - 316s 164ms/step - loss: 0.8886 - accuracy: 0.5830 - balanced_recall: 0.6143 - balanced_precision: 0.4209 - balanced_f1_score: 0.4980 - auc_roc: 0.6548 - val_loss: 0.7538 - val_accuracy: 0.6771 - val_balanced_recall: 0.6319 - val_balanced_precision: 0.4928 - val_balanced_f1_score: 0.5524 - val_auc_roc: 0.7331\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.64951 to 0.67707, saving model to ./Saved_Models/EDA_b_7aug/EDA_rd_7aug\\EDA_rd_7aug\n",
      "Epoch 3/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.8486 - accuracy: 0.6094 - balanced_recall: 0.6036 - balanced_precision: 0.4243 - balanced_f1_score: 0.4969 - auc_roc: 0.6578 - val_loss: 0.7477 - val_accuracy: 0.6838 - val_balanced_recall: 0.6434 - val_balanced_precision: 0.4986 - val_balanced_f1_score: 0.5608 - val_auc_roc: 0.7398\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67707 to 0.68383, saving model to ./Saved_Models/EDA_b_7aug/EDA_rd_7aug\\EDA_rd_7aug\n",
      "Epoch 4/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.8189 - accuracy: 0.6268 - balanced_recall: 0.6046 - balanced_precision: 0.4291 - balanced_f1_score: 0.5004 - auc_roc: 0.6663 - val_loss: 0.7388 - val_accuracy: 0.6937 - val_balanced_recall: 0.6378 - val_balanced_precision: 0.4952 - val_balanced_f1_score: 0.5562 - val_auc_roc: 0.7425\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.68383 to 0.69371, saving model to ./Saved_Models/EDA_b_7aug/EDA_rd_7aug\\EDA_rd_7aug\n",
      "Epoch 5/30\n",
      "1923/1923 [==============================] - 316s 164ms/step - loss: 0.7893 - accuracy: 0.6422 - balanced_recall: 0.5897 - balanced_precision: 0.4337 - balanced_f1_score: 0.4984 - auc_roc: 0.6716 - val_loss: 0.7457 - val_accuracy: 0.6890 - val_balanced_recall: 0.6026 - val_balanced_precision: 0.5087 - val_balanced_f1_score: 0.5505 - val_auc_roc: 0.7500\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.69371\n",
      "Epoch 6/30\n",
      "1923/1923 [==============================] - 315s 164ms/step - loss: 0.7654 - accuracy: 0.6544 - balanced_recall: 0.6037 - balanced_precision: 0.4385 - balanced_f1_score: 0.5065 - auc_roc: 0.6796 - val_loss: 0.7616 - val_accuracy: 0.6843 - val_balanced_recall: 0.6263 - val_balanced_precision: 0.5118 - val_balanced_f1_score: 0.5618 - val_auc_roc: 0.7519\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.69371\n",
      "Epoch 7/30\n",
      "1923/1923 [==============================] - 314s 163ms/step - loss: 0.7372 - accuracy: 0.6709 - balanced_recall: 0.6103 - balanced_precision: 0.4419 - balanced_f1_score: 0.5112 - auc_roc: 0.6860 - val_loss: 0.7923 - val_accuracy: 0.6807 - val_balanced_recall: 0.6125 - val_balanced_precision: 0.5211 - val_balanced_f1_score: 0.5617 - val_auc_roc: 0.7579\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.69371\n",
      "Epoch 8/30\n",
      "1923/1923 [==============================] - 313s 163ms/step - loss: 0.7098 - accuracy: 0.6834 - balanced_recall: 0.6191 - balanced_precision: 0.4478 - balanced_f1_score: 0.5182 - auc_roc: 0.6946 - val_loss: 0.8348 - val_accuracy: 0.6750 - val_balanced_recall: 0.6138 - val_balanced_precision: 0.5119 - val_balanced_f1_score: 0.5565 - val_auc_roc: 0.7528\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.69371\n",
      "Wall time: 42min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# augmented with rd = 0.1\n",
    "Accuracy_aug_rd, Macro_F1_aug_rd, ROC_AUC_aug_rd, metrics_rd = fine_tune_BERT(X_train_aug_rd, X_dev_aug_rd, X_test_aug_rd, \n",
    "                                                            y_train_aug_rd, y_dev_orig, y_test_orig, 'EDA_rd_7aug',\n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1923/1923 [==============================] - 326s 165ms/step - loss: 1.0363 - accuracy: 0.5265 - balanced_recall: 0.6921 - balanced_precision: 0.4581 - balanced_f1_score: 0.5509 - auc_roc: 0.6998 - val_loss: 0.7945 - val_accuracy: 0.6365 - val_balanced_recall: 0.7896 - val_balanced_precision: 0.5438 - val_balanced_f1_score: 0.6429 - val_auc_roc: 0.8135\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63651, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_1_7aug\\EDA_all_1_7aug\n",
      "Epoch 2/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.8652 - accuracy: 0.6077 - balanced_recall: 0.7669 - balanced_precision: 0.5107 - balanced_f1_score: 0.6127 - auc_roc: 0.7761 - val_loss: 0.7558 - val_accuracy: 0.6719 - val_balanced_recall: 0.8198 - val_balanced_precision: 0.5463 - val_balanced_f1_score: 0.6545 - val_auc_roc: 0.8276\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.63651 to 0.67187, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_1_7aug\\EDA_all_1_7aug\n",
      "Epoch 3/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.8159 - accuracy: 0.6365 - balanced_recall: 0.7944 - balanced_precision: 0.5292 - balanced_f1_score: 0.6349 - auc_roc: 0.8000 - val_loss: 0.7421 - val_accuracy: 0.6791 - val_balanced_recall: 0.8177 - val_balanced_precision: 0.5572 - val_balanced_f1_score: 0.6616 - val_auc_roc: 0.8357\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67187 to 0.67915, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_1_7aug\\EDA_all_1_7aug\n",
      "Epoch 4/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.7789 - accuracy: 0.6562 - balanced_recall: 0.8147 - balanced_precision: 0.5404 - balanced_f1_score: 0.6495 - auc_roc: 0.8158 - val_loss: 0.7321 - val_accuracy: 0.6864 - val_balanced_recall: 0.8092 - val_balanced_precision: 0.5652 - val_balanced_f1_score: 0.6651 - val_auc_roc: 0.8427\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67915 to 0.68643, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_1_7aug\\EDA_all_1_7aug\n",
      "Epoch 5/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.7442 - accuracy: 0.6741 - balanced_recall: 0.8353 - balanced_precision: 0.5492 - balanced_f1_score: 0.6623 - auc_roc: 0.8279 - val_loss: 0.7521 - val_accuracy: 0.6885 - val_balanced_recall: 0.8414 - val_balanced_precision: 0.5498 - val_balanced_f1_score: 0.6637 - val_auc_roc: 0.8316\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.68643 to 0.68851, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_1_7aug\\EDA_all_1_7aug\n",
      "Epoch 6/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.7113 - accuracy: 0.6888 - balanced_recall: 0.8500 - balanced_precision: 0.5572 - balanced_f1_score: 0.6728 - auc_roc: 0.8388 - val_loss: 0.7623 - val_accuracy: 0.6849 - val_balanced_recall: 0.8526 - val_balanced_precision: 0.5494 - val_balanced_f1_score: 0.6668 - val_auc_roc: 0.8329\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68851\n",
      "Epoch 7/30\n",
      "1923/1923 [==============================] - 314s 163ms/step - loss: 0.6738 - accuracy: 0.7092 - balanced_recall: 0.8675 - balanced_precision: 0.5662 - balanced_f1_score: 0.6849 - auc_roc: 0.8508 - val_loss: 0.7944 - val_accuracy: 0.6859 - val_balanced_recall: 0.8395 - val_balanced_precision: 0.5511 - val_balanced_f1_score: 0.6648 - val_auc_roc: 0.8352\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68851\n",
      "Epoch 8/30\n",
      "1923/1923 [==============================] - 313s 163ms/step - loss: 0.6343 - accuracy: 0.7256 - balanced_recall: 0.8839 - balanced_precision: 0.5737 - balanced_f1_score: 0.6955 - auc_roc: 0.8610 - val_loss: 0.8364 - val_accuracy: 0.6682 - val_balanced_recall: 0.8516 - val_balanced_precision: 0.5432 - val_balanced_f1_score: 0.6620 - val_auc_roc: 0.8196\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68851\n",
      "Epoch 9/30\n",
      "1923/1923 [==============================] - 314s 163ms/step - loss: 0.5992 - accuracy: 0.7440 - balanced_recall: 0.8935 - balanced_precision: 0.5830 - balanced_f1_score: 0.7053 - auc_roc: 0.8707 - val_loss: 0.8802 - val_accuracy: 0.6765 - val_balanced_recall: 0.8484 - val_balanced_precision: 0.5490 - val_balanced_f1_score: 0.6652 - val_auc_roc: 0.8230\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68851\n",
      "Wall time: 48min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# augmented with all = 0.1\n",
    "Accuracy_aug_all_1, Macro_F1_aug_all_1, ROC_AUC_aug_all_1, metrics_all_1 = fine_tune_BERT(X_train_all_1, X_dev_all_1, X_test_all_1, \n",
    "                                                            y_train_all_1, y_dev_orig, y_test_orig, 'EDA_all_1_7aug',\n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1923/1923 [==============================] - 328s 164ms/step - loss: 1.0732 - accuracy: 0.4818 - balanced_recall: 0.6030 - balanced_precision: 0.4094 - balanced_f1_score: 0.4868 - auc_roc: 0.6305 - val_loss: 0.8607 - val_accuracy: 0.6167 - val_balanced_recall: 0.7372 - val_balanced_precision: 0.5039 - val_balanced_f1_score: 0.5974 - val_auc_roc: 0.7549\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61674, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_5_7aug\\EDA_all_5_7aug\n",
      "Epoch 2/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.9501 - accuracy: 0.5557 - balanced_recall: 0.6791 - balanced_precision: 0.4418 - balanced_f1_score: 0.5345 - auc_roc: 0.6882 - val_loss: 0.7975 - val_accuracy: 0.6635 - val_balanced_recall: 0.7958 - val_balanced_precision: 0.5103 - val_balanced_f1_score: 0.6204 - val_auc_roc: 0.7956\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.61674 to 0.66355, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_5_7aug\\EDA_all_5_7aug\n",
      "Epoch 3/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.9146 - accuracy: 0.5802 - balanced_recall: 0.6935 - balanced_precision: 0.4464 - balanced_f1_score: 0.5423 - auc_roc: 0.6982 - val_loss: 0.7708 - val_accuracy: 0.6667 - val_balanced_recall: 0.7958 - val_balanced_precision: 0.5180 - val_balanced_f1_score: 0.6260 - val_auc_roc: 0.8036\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.66355 to 0.66667, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_5_7aug\\EDA_all_5_7aug\n",
      "Epoch 4/30\n",
      "1923/1923 [==============================] - 317s 165ms/step - loss: 0.8867 - accuracy: 0.5964 - balanced_recall: 0.7161 - balanced_precision: 0.4550 - balanced_f1_score: 0.5556 - auc_roc: 0.7092 - val_loss: 0.7577 - val_accuracy: 0.6745 - val_balanced_recall: 0.8191 - val_balanced_precision: 0.5096 - val_balanced_f1_score: 0.6265 - val_auc_roc: 0.8030\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66667 to 0.67447, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_5_7aug\\EDA_all_5_7aug\n",
      "Epoch 5/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.8681 - accuracy: 0.6077 - balanced_recall: 0.7239 - balanced_precision: 0.4598 - balanced_f1_score: 0.5615 - auc_roc: 0.7175 - val_loss: 0.7410 - val_accuracy: 0.6911 - val_balanced_recall: 0.8204 - val_balanced_precision: 0.5088 - val_balanced_f1_score: 0.6263 - val_auc_roc: 0.8047\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67447 to 0.69111, saving model to ./Saved_Models/EDA_b_7aug/EDA_all_5_7aug\\EDA_all_5_7aug\n",
      "Epoch 6/30\n",
      "1923/1923 [==============================] - 318s 165ms/step - loss: 0.8482 - accuracy: 0.6186 - balanced_recall: 0.7334 - balanced_precision: 0.4682 - balanced_f1_score: 0.5707 - auc_roc: 0.7276 - val_loss: 0.7321 - val_accuracy: 0.6854 - val_balanced_recall: 0.8320 - val_balanced_precision: 0.5090 - val_balanced_f1_score: 0.6298 - val_auc_roc: 0.8098\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.69111\n",
      "Epoch 7/30\n",
      "1923/1923 [==============================] - 329s 171ms/step - loss: 0.8333 - accuracy: 0.6257 - balanced_recall: 0.7450 - balanced_precision: 0.4703 - balanced_f1_score: 0.5759 - auc_roc: 0.7331 - val_loss: 0.7369 - val_accuracy: 0.6911 - val_balanced_recall: 0.8607 - val_balanced_precision: 0.4982 - val_balanced_f1_score: 0.6291 - val_auc_roc: 0.8028\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.69111\n",
      "Epoch 8/30\n",
      "1923/1923 [==============================] - 338s 176ms/step - loss: 0.8180 - accuracy: 0.6334 - balanced_recall: 0.7455 - balanced_precision: 0.4767 - balanced_f1_score: 0.5807 - auc_roc: 0.7395 - val_loss: 0.7351 - val_accuracy: 0.6864 - val_balanced_recall: 0.8250 - val_balanced_precision: 0.5181 - val_balanced_f1_score: 0.6349 - val_auc_roc: 0.8081\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.69111\n",
      "Epoch 9/30\n",
      "1923/1923 [==============================] - 331s 172ms/step - loss: 0.8074 - accuracy: 0.6394 - balanced_recall: 0.7524 - balanced_precision: 0.4821 - balanced_f1_score: 0.5869 - auc_roc: 0.7460 - val_loss: 0.7336 - val_accuracy: 0.6906 - val_balanced_recall: 0.8474 - val_balanced_precision: 0.5113 - val_balanced_f1_score: 0.6360 - val_auc_roc: 0.8125\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.69111\n",
      "Wall time: 49min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# augmented with all = 0.5\n",
    "Accuracy_aug_all_5, Macro_F1_aug_all_5, ROC_AUC_aug_all_5, metrics_all_5 = fine_tune_BERT(X_train_all_5, X_dev_all_5, X_test_all_5, \n",
    "                                                            y_train_all_5, y_dev_orig, y_test_orig, 'EDA_all_5_7aug',\n",
    "                                                            learning_rate = 2e-05, epsilon=1e-08, \n",
    "                                                            train_layers = 1, epochs = 30, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6895475819032761,\n",
       " 0.6615269965582669,\n",
       " 0.7559446883730452,\n",
       " {'loss': [1.233755350112915,\n",
       "   1.0920292139053345,\n",
       "   1.0057977437973022,\n",
       "   0.9597842693328857,\n",
       "   0.926659345626831,\n",
       "   0.8996855020523071,\n",
       "   0.8933510780334473,\n",
       "   0.8742587566375732,\n",
       "   0.8538693785667419,\n",
       "   0.8348292112350464,\n",
       "   0.8340325951576233,\n",
       "   0.8265409469604492,\n",
       "   0.814570426940918,\n",
       "   0.8129034638404846,\n",
       "   0.7966391444206238,\n",
       "   0.7905299663543701,\n",
       "   0.7824797630310059,\n",
       "   0.7754675149917603],\n",
       "  'accuracy': [0.4309302568435669,\n",
       "   0.4887863099575043,\n",
       "   0.5371513962745667,\n",
       "   0.5547682642936707,\n",
       "   0.5778456926345825,\n",
       "   0.5879217386245728,\n",
       "   0.594032347202301,\n",
       "   0.6030033230781555,\n",
       "   0.6165897250175476,\n",
       "   0.6240655183792114,\n",
       "   0.6289410591125488,\n",
       "   0.6334915161132812,\n",
       "   0.6343365907669067,\n",
       "   0.6399921774864197,\n",
       "   0.6473379731178284,\n",
       "   0.6480530500411987,\n",
       "   0.652733564376831,\n",
       "   0.6572189927101135],\n",
       "  'balanced_recall': [0.6036643981933594,\n",
       "   0.6728057265281677,\n",
       "   0.7158060669898987,\n",
       "   0.7463438510894775,\n",
       "   0.7621448040008545,\n",
       "   0.7727009057998657,\n",
       "   0.7778017520904541,\n",
       "   0.7841472625732422,\n",
       "   0.7926307916641235,\n",
       "   0.8048518896102905,\n",
       "   0.8100273013114929,\n",
       "   0.8111585378646851,\n",
       "   0.8185217976570129,\n",
       "   0.8180351853370667,\n",
       "   0.8283040523529053,\n",
       "   0.8270633816719055,\n",
       "   0.8324074149131775,\n",
       "   0.8370798230171204],\n",
       "  'balanced_precision': [0.39463719725608826,\n",
       "   0.4382593631744385,\n",
       "   0.466766357421875,\n",
       "   0.48231661319732666,\n",
       "   0.4915640354156494,\n",
       "   0.4975433051586151,\n",
       "   0.4989011883735657,\n",
       "   0.5033618807792664,\n",
       "   0.5087081789970398,\n",
       "   0.5148508548736572,\n",
       "   0.5145539045333862,\n",
       "   0.5175142884254456,\n",
       "   0.5210898518562317,\n",
       "   0.520020067691803,\n",
       "   0.5256425738334656,\n",
       "   0.52382892370224,\n",
       "   0.5255411267280579,\n",
       "   0.5314828753471375],\n",
       "  'balanced_f1_score': [0.4769686758518219,\n",
       "   0.5305219888687134,\n",
       "   0.5647439956665039,\n",
       "   0.5856393575668335,\n",
       "   0.5973176956176758,\n",
       "   0.6050616502761841,\n",
       "   0.6076288223266602,\n",
       "   0.612820029258728,\n",
       "   0.6193395853042603,\n",
       "   0.627667248249054,\n",
       "   0.6290473937988281,\n",
       "   0.6315956115722656,\n",
       "   0.6364811062812805,\n",
       "   0.6355425119400024,\n",
       "   0.6428622007369995,\n",
       "   0.6410872936248779,\n",
       "   0.6439727544784546,\n",
       "   0.6499030590057373],\n",
       "  'auc_roc': [0.6007298827171326,\n",
       "   0.6678574681282043,\n",
       "   0.7073854207992554,\n",
       "   0.7254568338394165,\n",
       "   0.7393214106559753,\n",
       "   0.7504900097846985,\n",
       "   0.7526634335517883,\n",
       "   0.7617715001106262,\n",
       "   0.7698334455490112,\n",
       "   0.7760724425315857,\n",
       "   0.7766548991203308,\n",
       "   0.7812309265136719,\n",
       "   0.7851773500442505,\n",
       "   0.7856469750404358,\n",
       "   0.79253089427948,\n",
       "   0.7932345867156982,\n",
       "   0.7952783107757568,\n",
       "   0.7999367713928223],\n",
       "  'val_loss': [0.9359428286552429,\n",
       "   0.8821693658828735,\n",
       "   0.8415187001228333,\n",
       "   0.8221778273582458,\n",
       "   0.811821460723877,\n",
       "   0.8038743138313293,\n",
       "   0.7844996452331543,\n",
       "   0.7852334976196289,\n",
       "   0.7704788446426392,\n",
       "   0.7713326811790466,\n",
       "   0.765763521194458,\n",
       "   0.7599166035652161,\n",
       "   0.7602778673171997,\n",
       "   0.7556413412094116,\n",
       "   0.7500457167625427,\n",
       "   0.7535986304283142,\n",
       "   0.748571515083313,\n",
       "   0.7529712915420532],\n",
       "  'val_accuracy': [0.5413416624069214,\n",
       "   0.5803431868553162,\n",
       "   0.6021841168403625,\n",
       "   0.6219449043273926,\n",
       "   0.6167446970939636,\n",
       "   0.6333853602409363,\n",
       "   0.6401455998420715,\n",
       "   0.6432657241821289,\n",
       "   0.6510660648345947,\n",
       "   0.6562662720680237,\n",
       "   0.65782630443573,\n",
       "   0.6614664793014526,\n",
       "   0.6651065945625305,\n",
       "   0.6734269261360168,\n",
       "   0.6614664793014526,\n",
       "   0.6619864702224731,\n",
       "   0.6692667603492737,\n",
       "   0.6625065207481384],\n",
       "  'val_balanced_recall': [0.7386443614959717,\n",
       "   0.7674252390861511,\n",
       "   0.8271580934524536,\n",
       "   0.7973744869232178,\n",
       "   0.8394017219543457,\n",
       "   0.810024619102478,\n",
       "   0.829580545425415,\n",
       "   0.8355666995048523,\n",
       "   0.8440794348716736,\n",
       "   0.8513665199279785,\n",
       "   0.8293214440345764,\n",
       "   0.8419390320777893,\n",
       "   0.8385812044143677,\n",
       "   0.8419840335845947,\n",
       "   0.8441981673240662,\n",
       "   0.854173481464386,\n",
       "   0.8353361487388611,\n",
       "   0.8509575724601746],\n",
       "  'val_balanced_precision': [0.4749758541584015,\n",
       "   0.5070887207984924,\n",
       "   0.5103503465652466,\n",
       "   0.520672082901001,\n",
       "   0.5158248543739319,\n",
       "   0.532117486000061,\n",
       "   0.5208525657653809,\n",
       "   0.5308141112327576,\n",
       "   0.5280275940895081,\n",
       "   0.5182564854621887,\n",
       "   0.5263150930404663,\n",
       "   0.5267629027366638,\n",
       "   0.5237748622894287,\n",
       "   0.5231002569198608,\n",
       "   0.5338544249534607,\n",
       "   0.5209718942642212,\n",
       "   0.5330439805984497,\n",
       "   0.525917649269104],\n",
       "  'val_balanced_f1_score': [0.5767278075218201,\n",
       "   0.6095575094223022,\n",
       "   0.6297091245651245,\n",
       "   0.6287218928337097,\n",
       "   0.637493908405304,\n",
       "   0.6411047577857971,\n",
       "   0.6385197043418884,\n",
       "   0.6478124856948853,\n",
       "   0.648192822933197,\n",
       "   0.6427590847015381,\n",
       "   0.6426042914390564,\n",
       "   0.6466532945632935,\n",
       "   0.643352746963501,\n",
       "   0.6438469886779785,\n",
       "   0.6527409553527832,\n",
       "   0.6456890106201172,\n",
       "   0.6494427919387817,\n",
       "   0.648612380027771],\n",
       "  'val_auc_roc': [0.7256067395210266,\n",
       "   0.7630079984664917,\n",
       "   0.7767733931541443,\n",
       "   0.78703773021698,\n",
       "   0.7902854084968567,\n",
       "   0.7994519472122192,\n",
       "   0.8033407330513,\n",
       "   0.8008862137794495,\n",
       "   0.8050089478492737,\n",
       "   0.8077825307846069,\n",
       "   0.814270555973053,\n",
       "   0.8138254880905151,\n",
       "   0.8164063096046448,\n",
       "   0.816679060459137,\n",
       "   0.817719578742981,\n",
       "   0.8141593933105469,\n",
       "   0.8208772540092468,\n",
       "   0.818556547164917]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_orig, Macro_F1_orig, ROC_AUC_orig, metrics_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_aug_sr, Macro_F1_aug_sr, ROC_AUC_aug_sr, metrics_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_aug_ri, Macro_F1_aug_ri, ROC_AUC_aug_ri, metrics_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_aug_rs, Macro_F1_aug_rs, ROC_AUC_aug_rs, metrics_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_aug_rd, Macro_F1_aug_rd, ROC_AUC_aug_rd, metrics_rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_aug_all_1, Macro_F1_aug_all_1, ROC_AUC_aug_all_1, metrics_all_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy_aug_all_5, Macro_F1_aug_all_5, ROC_AUC_aug_all_5, metrics_all_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name_list = ['Original Data', 'Augmented SR 0.1', 'Augmented RI 0.1', \n",
    "                   'Augmented RS 0.1', 'Augmented RD 0.1', 'Augmented All 0.1', 'Augmented All 0.5']\n",
    "\n",
    "acc_list = [Accuracy_orig, Accuracy_aug_sr, Accuracy_aug_ri, Accuracy_aug_rs, \n",
    "            Accuracy_aug_rd, Accuracy_aug_all_1, Accuracy_aug_all_5]\n",
    "\n",
    "macro_f1_list = [Macro_F1_orig, Macro_F1_aug_sr, Macro_F1_aug_ri, Macro_F1_aug_rs, \n",
    "                 Macro_F1_aug_rd, Macro_F1_aug_all_1, Macro_F1_aug_all_5]\n",
    "\n",
    "roc_auc_list = [ROC_AUC_orig, ROC_AUC_aug_sr, ROC_AUC_aug_ri, ROC_AUC_aug_rs, \n",
    "                ROC_AUC_aug_rd, ROC_AUC_aug_all_1, ROC_AUC_aug_all_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'Trial Name' : trial_name_list, 'Test Accuracy Score' : acc_list, \n",
    "               'Test Macro F1 Score' : macro_f1_list, 'Test ROC AUC Score' : roc_auc_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial Name</th>\n",
       "      <th>Test Accuracy Score</th>\n",
       "      <th>Test Macro F1 Score</th>\n",
       "      <th>Test ROC AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Data</td>\n",
       "      <td>0.689548</td>\n",
       "      <td>0.661527</td>\n",
       "      <td>0.755945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Augmented SR 0.1</td>\n",
       "      <td>0.693188</td>\n",
       "      <td>0.674916</td>\n",
       "      <td>0.761387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Augmented RI 0.1</td>\n",
       "      <td>0.706708</td>\n",
       "      <td>0.687033</td>\n",
       "      <td>0.770935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Augmented RS 0.1</td>\n",
       "      <td>0.706708</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.768938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Augmented RD 0.1</td>\n",
       "      <td>0.711908</td>\n",
       "      <td>0.687497</td>\n",
       "      <td>0.772079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Augmented All 0.1</td>\n",
       "      <td>0.703068</td>\n",
       "      <td>0.688082</td>\n",
       "      <td>0.771588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Augmented All 0.5</td>\n",
       "      <td>0.706188</td>\n",
       "      <td>0.680916</td>\n",
       "      <td>0.766816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Trial Name  Test Accuracy Score  Test Macro F1 Score  \\\n",
       "0      Original Data             0.689548             0.661527   \n",
       "1   Augmented SR 0.1             0.693188             0.674916   \n",
       "2   Augmented RI 0.1             0.706708             0.687033   \n",
       "3   Augmented RS 0.1             0.706708             0.681818   \n",
       "4   Augmented RD 0.1             0.711908             0.687497   \n",
       "5  Augmented All 0.1             0.703068             0.688082   \n",
       "6  Augmented All 0.5             0.706188             0.680916   \n",
       "\n",
       "   Test ROC AUC Score  \n",
       "0            0.755945  \n",
       "1            0.761387  \n",
       "2            0.770935  \n",
       "3            0.768938  \n",
       "4            0.772079  \n",
       "5            0.771588  \n",
       "6            0.766816  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(result_dict)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('./Saved_Models/EDA_b_7aug/All_DA_BERT_base_uncased_7aug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_recall</th>\n",
       "      <th>balanced_precision</th>\n",
       "      <th>balanced_f1_score</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_balanced_recall</th>\n",
       "      <th>val_balanced_precision</th>\n",
       "      <th>val_balanced_f1_score</th>\n",
       "      <th>val_auc_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.233755</td>\n",
       "      <td>0.430930</td>\n",
       "      <td>0.603664</td>\n",
       "      <td>0.394637</td>\n",
       "      <td>0.476969</td>\n",
       "      <td>0.600730</td>\n",
       "      <td>0.935943</td>\n",
       "      <td>0.541342</td>\n",
       "      <td>0.738644</td>\n",
       "      <td>0.474976</td>\n",
       "      <td>0.576728</td>\n",
       "      <td>0.725607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.092029</td>\n",
       "      <td>0.488786</td>\n",
       "      <td>0.672806</td>\n",
       "      <td>0.438259</td>\n",
       "      <td>0.530522</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>0.882169</td>\n",
       "      <td>0.580343</td>\n",
       "      <td>0.767425</td>\n",
       "      <td>0.507089</td>\n",
       "      <td>0.609558</td>\n",
       "      <td>0.763008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.005798</td>\n",
       "      <td>0.537151</td>\n",
       "      <td>0.715806</td>\n",
       "      <td>0.466766</td>\n",
       "      <td>0.564744</td>\n",
       "      <td>0.707385</td>\n",
       "      <td>0.841519</td>\n",
       "      <td>0.602184</td>\n",
       "      <td>0.827158</td>\n",
       "      <td>0.510350</td>\n",
       "      <td>0.629709</td>\n",
       "      <td>0.776773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959784</td>\n",
       "      <td>0.554768</td>\n",
       "      <td>0.746344</td>\n",
       "      <td>0.482317</td>\n",
       "      <td>0.585639</td>\n",
       "      <td>0.725457</td>\n",
       "      <td>0.822178</td>\n",
       "      <td>0.621945</td>\n",
       "      <td>0.797374</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>0.628722</td>\n",
       "      <td>0.787038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.926659</td>\n",
       "      <td>0.577846</td>\n",
       "      <td>0.762145</td>\n",
       "      <td>0.491564</td>\n",
       "      <td>0.597318</td>\n",
       "      <td>0.739321</td>\n",
       "      <td>0.811821</td>\n",
       "      <td>0.616745</td>\n",
       "      <td>0.839402</td>\n",
       "      <td>0.515825</td>\n",
       "      <td>0.637494</td>\n",
       "      <td>0.790285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.899686</td>\n",
       "      <td>0.587922</td>\n",
       "      <td>0.772701</td>\n",
       "      <td>0.497543</td>\n",
       "      <td>0.605062</td>\n",
       "      <td>0.750490</td>\n",
       "      <td>0.803874</td>\n",
       "      <td>0.633385</td>\n",
       "      <td>0.810025</td>\n",
       "      <td>0.532117</td>\n",
       "      <td>0.641105</td>\n",
       "      <td>0.799452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.893351</td>\n",
       "      <td>0.594032</td>\n",
       "      <td>0.777802</td>\n",
       "      <td>0.498901</td>\n",
       "      <td>0.607629</td>\n",
       "      <td>0.752663</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.640146</td>\n",
       "      <td>0.829581</td>\n",
       "      <td>0.520853</td>\n",
       "      <td>0.638520</td>\n",
       "      <td>0.803341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.874259</td>\n",
       "      <td>0.603003</td>\n",
       "      <td>0.784147</td>\n",
       "      <td>0.503362</td>\n",
       "      <td>0.612820</td>\n",
       "      <td>0.761772</td>\n",
       "      <td>0.785233</td>\n",
       "      <td>0.643266</td>\n",
       "      <td>0.835567</td>\n",
       "      <td>0.530814</td>\n",
       "      <td>0.647812</td>\n",
       "      <td>0.800886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.853869</td>\n",
       "      <td>0.616590</td>\n",
       "      <td>0.792631</td>\n",
       "      <td>0.508708</td>\n",
       "      <td>0.619340</td>\n",
       "      <td>0.769833</td>\n",
       "      <td>0.770479</td>\n",
       "      <td>0.651066</td>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.528028</td>\n",
       "      <td>0.648193</td>\n",
       "      <td>0.805009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.834829</td>\n",
       "      <td>0.624066</td>\n",
       "      <td>0.804852</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.627667</td>\n",
       "      <td>0.776072</td>\n",
       "      <td>0.771333</td>\n",
       "      <td>0.656266</td>\n",
       "      <td>0.851367</td>\n",
       "      <td>0.518256</td>\n",
       "      <td>0.642759</td>\n",
       "      <td>0.807783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.834033</td>\n",
       "      <td>0.628941</td>\n",
       "      <td>0.810027</td>\n",
       "      <td>0.514554</td>\n",
       "      <td>0.629047</td>\n",
       "      <td>0.776655</td>\n",
       "      <td>0.765764</td>\n",
       "      <td>0.657826</td>\n",
       "      <td>0.829321</td>\n",
       "      <td>0.526315</td>\n",
       "      <td>0.642604</td>\n",
       "      <td>0.814271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.826541</td>\n",
       "      <td>0.633492</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.517514</td>\n",
       "      <td>0.631596</td>\n",
       "      <td>0.781231</td>\n",
       "      <td>0.759917</td>\n",
       "      <td>0.661466</td>\n",
       "      <td>0.841939</td>\n",
       "      <td>0.526763</td>\n",
       "      <td>0.646653</td>\n",
       "      <td>0.813825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.814570</td>\n",
       "      <td>0.634337</td>\n",
       "      <td>0.818522</td>\n",
       "      <td>0.521090</td>\n",
       "      <td>0.636481</td>\n",
       "      <td>0.785177</td>\n",
       "      <td>0.760278</td>\n",
       "      <td>0.665107</td>\n",
       "      <td>0.838581</td>\n",
       "      <td>0.523775</td>\n",
       "      <td>0.643353</td>\n",
       "      <td>0.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.639992</td>\n",
       "      <td>0.818035</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.635543</td>\n",
       "      <td>0.785647</td>\n",
       "      <td>0.755641</td>\n",
       "      <td>0.673427</td>\n",
       "      <td>0.841984</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.643847</td>\n",
       "      <td>0.816679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.796639</td>\n",
       "      <td>0.647338</td>\n",
       "      <td>0.828304</td>\n",
       "      <td>0.525643</td>\n",
       "      <td>0.642862</td>\n",
       "      <td>0.792531</td>\n",
       "      <td>0.750046</td>\n",
       "      <td>0.661466</td>\n",
       "      <td>0.844198</td>\n",
       "      <td>0.533854</td>\n",
       "      <td>0.652741</td>\n",
       "      <td>0.817720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.790530</td>\n",
       "      <td>0.648053</td>\n",
       "      <td>0.827063</td>\n",
       "      <td>0.523829</td>\n",
       "      <td>0.641087</td>\n",
       "      <td>0.793235</td>\n",
       "      <td>0.753599</td>\n",
       "      <td>0.661986</td>\n",
       "      <td>0.854173</td>\n",
       "      <td>0.520972</td>\n",
       "      <td>0.645689</td>\n",
       "      <td>0.814159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.782480</td>\n",
       "      <td>0.652734</td>\n",
       "      <td>0.832407</td>\n",
       "      <td>0.525541</td>\n",
       "      <td>0.643973</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.748572</td>\n",
       "      <td>0.669267</td>\n",
       "      <td>0.835336</td>\n",
       "      <td>0.533044</td>\n",
       "      <td>0.649443</td>\n",
       "      <td>0.820877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.775468</td>\n",
       "      <td>0.657219</td>\n",
       "      <td>0.837080</td>\n",
       "      <td>0.531483</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.799937</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.662507</td>\n",
       "      <td>0.850958</td>\n",
       "      <td>0.525918</td>\n",
       "      <td>0.648612</td>\n",
       "      <td>0.818557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  balanced_recall  balanced_precision  \\\n",
       "0   1.233755  0.430930         0.603664            0.394637   \n",
       "1   1.092029  0.488786         0.672806            0.438259   \n",
       "2   1.005798  0.537151         0.715806            0.466766   \n",
       "3   0.959784  0.554768         0.746344            0.482317   \n",
       "4   0.926659  0.577846         0.762145            0.491564   \n",
       "5   0.899686  0.587922         0.772701            0.497543   \n",
       "6   0.893351  0.594032         0.777802            0.498901   \n",
       "7   0.874259  0.603003         0.784147            0.503362   \n",
       "8   0.853869  0.616590         0.792631            0.508708   \n",
       "9   0.834829  0.624066         0.804852            0.514851   \n",
       "10  0.834033  0.628941         0.810027            0.514554   \n",
       "11  0.826541  0.633492         0.811159            0.517514   \n",
       "12  0.814570  0.634337         0.818522            0.521090   \n",
       "13  0.812903  0.639992         0.818035            0.520020   \n",
       "14  0.796639  0.647338         0.828304            0.525643   \n",
       "15  0.790530  0.648053         0.827063            0.523829   \n",
       "16  0.782480  0.652734         0.832407            0.525541   \n",
       "17  0.775468  0.657219         0.837080            0.531483   \n",
       "\n",
       "    balanced_f1_score   auc_roc  val_loss  val_accuracy  val_balanced_recall  \\\n",
       "0            0.476969  0.600730  0.935943      0.541342             0.738644   \n",
       "1            0.530522  0.667857  0.882169      0.580343             0.767425   \n",
       "2            0.564744  0.707385  0.841519      0.602184             0.827158   \n",
       "3            0.585639  0.725457  0.822178      0.621945             0.797374   \n",
       "4            0.597318  0.739321  0.811821      0.616745             0.839402   \n",
       "5            0.605062  0.750490  0.803874      0.633385             0.810025   \n",
       "6            0.607629  0.752663  0.784500      0.640146             0.829581   \n",
       "7            0.612820  0.761772  0.785233      0.643266             0.835567   \n",
       "8            0.619340  0.769833  0.770479      0.651066             0.844079   \n",
       "9            0.627667  0.776072  0.771333      0.656266             0.851367   \n",
       "10           0.629047  0.776655  0.765764      0.657826             0.829321   \n",
       "11           0.631596  0.781231  0.759917      0.661466             0.841939   \n",
       "12           0.636481  0.785177  0.760278      0.665107             0.838581   \n",
       "13           0.635543  0.785647  0.755641      0.673427             0.841984   \n",
       "14           0.642862  0.792531  0.750046      0.661466             0.844198   \n",
       "15           0.641087  0.793235  0.753599      0.661986             0.854173   \n",
       "16           0.643973  0.795278  0.748572      0.669267             0.835336   \n",
       "17           0.649903  0.799937  0.752971      0.662507             0.850958   \n",
       "\n",
       "    val_balanced_precision  val_balanced_f1_score  val_auc_roc  \n",
       "0                 0.474976               0.576728     0.725607  \n",
       "1                 0.507089               0.609558     0.763008  \n",
       "2                 0.510350               0.629709     0.776773  \n",
       "3                 0.520672               0.628722     0.787038  \n",
       "4                 0.515825               0.637494     0.790285  \n",
       "5                 0.532117               0.641105     0.799452  \n",
       "6                 0.520853               0.638520     0.803341  \n",
       "7                 0.530814               0.647812     0.800886  \n",
       "8                 0.528028               0.648193     0.805009  \n",
       "9                 0.518256               0.642759     0.807783  \n",
       "10                0.526315               0.642604     0.814271  \n",
       "11                0.526763               0.646653     0.813825  \n",
       "12                0.523775               0.643353     0.816406  \n",
       "13                0.523100               0.643847     0.816679  \n",
       "14                0.533854               0.652741     0.817720  \n",
       "15                0.520972               0.645689     0.814159  \n",
       "16                0.533044               0.649443     0.820877  \n",
       "17                0.525918               0.648612     0.818557  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_org_df = pd.DataFrame(metrics_orig)\n",
    "\n",
    "metrics_org_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = [metrics_orig, metrics_sr, metrics_ri, metrics_rs, metrics_rd, metrics_all_1, metrics_all_5]\n",
    "name_list = ['fit_metrics_orig.csv', 'fit_metrics_sr.csv', 'fit_metrics_ri.csv', 'fit_metrics_rs.csv', 'fit_metrics_rd.csv', 'fit_metrics_all_1.csv', 'fit_metrics_all_5.csv']\n",
    "\n",
    "i = 0\n",
    "for m in metrics_list:\n",
    "    df = pd.DataFrame(m)\n",
    "    df.to_csv(name_list[i])\n",
    "    i += 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOeNGBZaTc3vi1iokDn5dgn",
   "collapsed_sections": [],
   "name": "Data_Processing",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02d7e8c53bf94bf48c06cea9abbd9aba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf38f0560d3e493ca2b97fd974d00462",
       "IPY_MODEL_8a60b779e7d749d284b791b9e5126a62",
       "IPY_MODEL_2e51f1cad2b84893b537beb7e4ebf67c"
      ],
      "layout": "IPY_MODEL_d57bc505733b4c738cf84db24feba360"
     }
    },
    "047bcb706b304be09200793be7524708": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "071ca09b48bf4d9989852d66f8d57642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8aa487d37b284b2ba88903923a0086d9",
       "IPY_MODEL_b3ba42a7365d418f9cbf7f68ede3b65a",
       "IPY_MODEL_c7e4cea875eb41c8950f97350c237730"
      ],
      "layout": "IPY_MODEL_15db3b4b336b41cdb973852bb3fef72f"
     }
    },
    "0c234fac6d10482089dacd2c03a5bbde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12bf3b8f0bab4586847a07e8c438dafa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e67ba177d3744ea4bcc652774cd13abd",
       "IPY_MODEL_43eb8a62436a4c149e25f98f49a7c68d",
       "IPY_MODEL_3723a8c5f8eb47efa71e50a5ef924123"
      ],
      "layout": "IPY_MODEL_8039ef2f59ee482781f325f5a91b93e8"
     }
    },
    "15db3b4b336b41cdb973852bb3fef72f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b1a083fc8e643a78f055105960b523e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "263134a33eaa4345926dd786256c08eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2af599ea5c3d4874aff863303c5b5703": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b473e96d36604d71ae5d3d8e69cc01c3",
      "placeholder": "​",
      "style": "IPY_MODEL_263134a33eaa4345926dd786256c08eb",
      "value": "Downloading: 100%"
     }
    },
    "2e51f1cad2b84893b537beb7e4ebf67c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3df12951362451685bea68b7091c69f",
      "placeholder": "​",
      "style": "IPY_MODEL_b8b44bed109443fd9bba63a7039f3c93",
      "value": " 226k/226k [00:00&lt;00:00, 3.21MB/s]"
     }
    },
    "3723a8c5f8eb47efa71e50a5ef924123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b1a083fc8e643a78f055105960b523e",
      "placeholder": "​",
      "style": "IPY_MODEL_c26d9b9e910a43febfd588927c3e7756",
      "value": " 299/299 [00:00&lt;00:00, 5.18kB/s]"
     }
    },
    "3dfc3ee445f2403a8ed7b4e6f5a8b3d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43eb8a62436a4c149e25f98f49a7c68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7942944ae43141c0aa83ec76fc0deafa",
      "max": 299,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d2efc2c1758475c9d1cd51cdc7edf0a",
      "value": 299
     }
    },
    "45b7612393254fe19709bdae7d7bbbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4656eb21ff2245b7be51f82c1e2c7e6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2af599ea5c3d4874aff863303c5b5703",
       "IPY_MODEL_c64b940afcc94ee3b2b88c582b54d97f",
       "IPY_MODEL_8a798f3e801d47df8771840991f7cfa3"
      ],
      "layout": "IPY_MODEL_ab8f5f020c76459aad12d4cab6a36a72"
     }
    },
    "5d2efc2c1758475c9d1cd51cdc7edf0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e02a09e9fe24718a8f1f4167c42d099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70f68856bdb64c30aa57e6046468b3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7942944ae43141c0aa83ec76fc0deafa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d3ff64481b64406aadb34439d2ad02b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d77d8f8c129400d9f61b60da03891b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98efd1135c4f438c8b8dd5c130cc667c",
       "IPY_MODEL_9aca8f0c4013472c8514d2d57f9ea3e8",
       "IPY_MODEL_807b39071d354a1ab7af51a05f1ef3b1"
      ],
      "layout": "IPY_MODEL_971c955528914b05afe5d12e9c626cf1"
     }
    },
    "8039ef2f59ee482781f325f5a91b93e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "807b39071d354a1ab7af51a05f1ef3b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc6b1e6a0e254b82b6c7277f10a5d542",
      "placeholder": "​",
      "style": "IPY_MODEL_5e02a09e9fe24718a8f1f4167c42d099",
      "value": " 112/112 [00:00&lt;00:00, 2.56kB/s]"
     }
    },
    "8a60b779e7d749d284b791b9e5126a62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c234fac6d10482089dacd2c03a5bbde",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70f68856bdb64c30aa57e6046468b3d6",
      "value": 231508
     }
    },
    "8a798f3e801d47df8771840991f7cfa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_047bcb706b304be09200793be7524708",
      "placeholder": "​",
      "style": "IPY_MODEL_c4792815ec0d4591bcaea2e7a0539e6b",
      "value": " 790/790 [00:00&lt;00:00, 14.6kB/s]"
     }
    },
    "8aa487d37b284b2ba88903923a0086d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee76f1517ed64f4fa49d998d2448f9c2",
      "placeholder": "​",
      "style": "IPY_MODEL_e88a61936e0949c490366d0619869b6c",
      "value": "Downloading: 100%"
     }
    },
    "971c955528914b05afe5d12e9c626cf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98efd1135c4f438c8b8dd5c130cc667c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b575b556bb9445ceb5c662b9d224e171",
      "placeholder": "​",
      "style": "IPY_MODEL_acd4639a73904507b7884adc96512dc5",
      "value": "Downloading: 100%"
     }
    },
    "9aca8f0c4013472c8514d2d57f9ea3e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2803d4a8a794a83a2ebcf61ce3097ff",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9a30d0d10744d14a47b500251c1973c",
      "value": 112
     }
    },
    "9e9b4804607046678d3d132528486b0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab8f5f020c76459aad12d4cab6a36a72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acd4639a73904507b7884adc96512dc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3ba42a7365d418f9cbf7f68ede3b65a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d12cbe52662546d1be82cfd4536dfdfc",
      "max": 437996231,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45b7612393254fe19709bdae7d7bbbe6",
      "value": 437996231
     }
    },
    "b473e96d36604d71ae5d3d8e69cc01c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b575b556bb9445ceb5c662b9d224e171": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8b44bed109443fd9bba63a7039f3c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf38f0560d3e493ca2b97fd974d00462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feb0fac998144444bfd9373ce537bbc3",
      "placeholder": "​",
      "style": "IPY_MODEL_7d3ff64481b64406aadb34439d2ad02b",
      "value": "Downloading: 100%"
     }
    },
    "c26d9b9e910a43febfd588927c3e7756": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3df12951362451685bea68b7091c69f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4792815ec0d4591bcaea2e7a0539e6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c64b940afcc94ee3b2b88c582b54d97f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e35113cc44f34a1fbb22f109f49f7bdd",
      "max": 790,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dfc3ee445f2403a8ed7b4e6f5a8b3d3",
      "value": 790
     }
    },
    "c7e4cea875eb41c8950f97350c237730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7abb004da9d42b787717cfdb3657f4e",
      "placeholder": "​",
      "style": "IPY_MODEL_ee89c9881c75441fbc9ec827d623134e",
      "value": " 418M/418M [00:11&lt;00:00, 37.0MB/s]"
     }
    },
    "d12cbe52662546d1be82cfd4536dfdfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2803d4a8a794a83a2ebcf61ce3097ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d57bc505733b4c738cf84db24feba360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7abb004da9d42b787717cfdb3657f4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e35113cc44f34a1fbb22f109f49f7bdd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e567a77fb29d47c98fe19c440b2d31e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e67ba177d3744ea4bcc652774cd13abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e567a77fb29d47c98fe19c440b2d31e8",
      "placeholder": "​",
      "style": "IPY_MODEL_9e9b4804607046678d3d132528486b0b",
      "value": "Downloading: 100%"
     }
    },
    "e88a61936e0949c490366d0619869b6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee76f1517ed64f4fa49d998d2448f9c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee89c9881c75441fbc9ec827d623134e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9a30d0d10744d14a47b500251c1973c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc6b1e6a0e254b82b6c7277f10a5d542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "feb0fac998144444bfd9373ce537bbc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
